<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">
    <title>E資格クエスト RPG</title>
    <style>
        @import url('https://fonts.googleapis.com/css2?family=DotGothic16&display=swap');

        :root {
            --bg-color: #050505;
            --win-bg: #111;
            --text-color: #e0e0e0;
            --accent-color: #4db8ff;
            --danger-color: #ff4444;
            --sage-color: #ffd700;
            --base-font-size: 16px;
            --btn-padding: 12px;
            --window-width: 750px;
            --char-size: 220px;
        }

        @media (max-width: 600px) {
            :root {
                --base-font-size: 14px;
                --btn-padding: 16px;
                --window-width: 100%;
                --char-size: 130px;
            }
            .game-window { height: 100dvh; border-radius: 0 !important; border:none !important;}
            .stage-grid { grid-template-columns: 1fr 1fr !important; }
        }

        body {
            background-color: var(--bg-color); color: var(--text-color);
            font-family: 'DotGothic16', sans-serif; font-size: var(--base-font-size);
            display: flex; flex-direction: column; align-items: center; justify-content: flex-start;
            height: 100vh; margin: 0; overflow: hidden; touch-action: none;
        }

        /* ゲーム画面 */
        #game-wrapper {
            position: relative; width: 100%; max-width: 480px; aspect-ratio: 1 / 1;
            border: 2px solid #fff; background-color: #000; margin-bottom: 10px;
        }
        canvas { display: block; width: 100%; height: 100%; }

        /* コントローラー */
        #controller {
            width: 100%; max-width: 480px; height: 180px;
            display: grid; grid-template-columns: 1fr 1fr; padding: 10px;
            box-sizing: border-box; background: #222; border-top: 2px solid #555;
        }
        .d-pad {
            display: grid; grid-template-areas: ". up ." "left . right" ". down .";
            gap: 5px; width: 150px; height: 150px; justify-self: center; align-self: center;
        }
        .d-btn {
            width: 50px; height: 50px; background: rgba(255, 255, 255, 0.15);
            border: 2px solid rgba(255, 255, 255, 0.5); border-radius: 8px;
            display: flex; justify-content: center; align-items: center;
            font-size: 1.5rem; user-select: none; cursor: pointer;
        }
        .d-btn:active { background: rgba(255, 255, 255, 0.5); }
        .action-pad { display: flex; justify-content: center; align-items: center; }
        .a-btn {
            width: 80px; height: 80px; background: rgba(255, 100, 100, 0.3);
            border: 4px solid rgba(255, 100, 100, 0.8); border-radius: 50%;
            display: flex; justify-content: center; align-items: center;
            font-size: 1.5rem; font-weight: bold; user-select: none; cursor: pointer;
        }
        .a-btn:active { background: rgba(255, 100, 100, 0.6); }

        /* UIオーバーレイ */
        .overlay {
            position: absolute; bottom: 10px; left: 10px; right: 10px;
            background: rgba(0, 0, 0, 0.9); border: 2px solid #fff; border-radius: 8px;
            padding: 15px; display: none; font-size: 1rem; line-height: 1.5; z-index: 10;
        }
        #battle-ui { top: 10px; bottom: 10px; display: none; flex-direction: column; justify-content: space-between; }
        .hp-bar-frame { width: 100%; height: 10px; background: #333; border: 1px solid #fff; margin-bottom: 5px; }
        .hp-bar-fill { height: 100%; width: 100%; transition: width 0.2s; }
        .hp-green { background: #0f0; } .hp-red { background: #f00; }
        .enemy-display { flex-grow: 1; display: flex; flex-direction: column; align-items: center; justify-content: center; }
        .enemy-img-large { width: 120px; height: 120px; object-fit: contain; image-rendering: pixelated; filter: drop-shadow(0 0 10px red); }
        .quiz-options { display: grid; grid-template-columns: 1fr 1fr; gap: 8px; margin-top: 10px; }
        .btn { background: #222; color: white; border: 2px solid #fff; padding: 10px; font-family: inherit; cursor: pointer; text-align: left; }
        .btn.correct { background: #050; border-color: #0f0; } .btn.wrong { background: #500; border-color: #f00; }

        /* スタート画面 */
        #start-screen {
            position: absolute; inset: 0; background: #000; z-index: 100;
            display: flex; flex-direction: column; align-items: center; justify-content: center;
        }
        #start-btn { padding: 20px 40px; font-size: 1.5rem; border: 2px solid #fff; background: #222; color: #fff; cursor: pointer; }

    </style>
</head>
<body>

<div id="game-wrapper">
    <canvas id="gameCanvas" width="480" height="480"></canvas>

    <div id="start-screen">
        <h1 style="color:#4db8ff; margin-bottom:20px;">E資格クエスト</h1>
        <button id="start-btn" onclick="startGame()">GAME START</button>
        <p style="color:#888; margin-top:10px;">(音が出ます)</p>
    </div>

    <div id="dialogue-box" class="overlay">
        <div id="dialogue-text">...</div>
        <div style="text-align: right; font-size: 0.8rem; color: #aaa; margin-top:5px;">▼ 進む(Aボタン)</div>
    </div>

    <div id="battle-ui" class="overlay">
        <div>
            <div id="enemy-name">スライム</div>
            <div class="hp-bar-frame"><div id="enemy-hp" class="hp-bar-fill hp-red"></div></div>
        </div>
        <div class="enemy-display">
            <img id="battle-enemy-img" src="" alt="ENEMY" class="enemy-img-large">
            <div id="battle-msg" style="margin-top: 10px; min-height: 1.5em; text-align: center;">現れた！</div>
        </div>
        <div>
            <div style="display: flex; justify-content: space-between;"><span>勇者</span><span id="player-hp-text">HP: 100</span></div>
            <div class="hp-bar-frame"><div id="player-hp" class="hp-bar-fill hp-green"></div></div>
            <div id="quiz-area" style="display:none; margin-top: 10px;">
                <div id="quiz-text" style="margin-bottom:5px; font-size:0.95rem;">問題</div>
                <div id="quiz-options" class="quiz-options"></div>
            </div>
            <button id="battle-next-btn" class="btn" style="width:100%; display:none; text-align:center;" onclick="Battle.next()">次へ</button>
        </div>
    </div>
</div>

<div id="controller">
    <div class="d-pad">
        <div class="d-btn" style="grid-area: up;" ontouchstart="Input.startMove(0, -1)" onmousedown="Input.startMove(0, -1)" ontouchend="Input.stopMove()" onmouseup="Input.stopMove()">↑</div>
        <div class="d-btn" style="grid-area: left;" ontouchstart="Input.startMove(-1, 0)" onmousedown="Input.startMove(-1, 0)" ontouchend="Input.stopMove()" onmouseup="Input.stopMove()">←</div>
        <div class="d-btn" style="grid-area: right;" ontouchstart="Input.startMove(1, 0)" onmousedown="Input.startMove(1, 0)" ontouchend="Input.stopMove()" onmouseup="Input.stopMove()">→</div>
        <div class="d-btn" style="grid-area: down;" ontouchstart="Input.startMove(0, 1)" onmousedown="Input.startMove(0, 1)" ontouchend="Input.stopMove()" onmouseup="Input.stopMove()">↓</div>
    </div>
    <div class="action-pad">
        <div class="a-btn" onclick="Input.triggerAction()">A</div>
    </div>
</div>

<script>
// --- 画像設定 (4方向に対応) ---
const IMAGES = {
    // 勇者の4方向
    hero_down: "hero_down.png",
    hero_up: "hero_up.png",
    hero_left: "hero_left.png",
    hero_right: "hero_right.png",
    
    // その他
    villager: "sage.png",
    slime: "slime.png",
    boss: "boss.png",
    floor: "floor.png",
    wall: "wall.png"
};

// --- 問題データ (前回のデータをコピペしてください) ---
const DB = [
    // --- 1: 線形代数 ---
  {
    "sid": 1,
    "q": '行列Aの固有値をλ、固有ベクトルをxとした時、成り立つ式は？',
    "a": ['Ax = λx', 'Ax = x + λ', 'A = λx', 'x = Aλ'],
    "exp": '固有値定義の基本です。'
  },
  {
    "sid": 1,
    "q": '特異値分解(SVD)によって得られる行列Σの特徴は？',
    "a": ['対角行列である', '正方行列である', '全ての要素が1', '対称行列である'],
    "exp": '特異値が対角成分に並びます。'
  },
  {
    "sid": 1,
    "q": "m×n行列Aとn×p行列Bの積ABの結果として得られる行列のサイズはどれか。",
    "a": ["m×p", "n×m", "n×n", "p×m"],
    "exp": "行列の積では、左側の行列の列数と右側の行列の行数が一致している必要があり、結果は「左の行数×右の列数」のサイズになります。"
  },
  {
    "sid": 1,
    "q": "一般に、行列の積ABとBAの関係として正しいものはどれか。",
    "a": ["AB ≠ BA（一般に可換ではない）", "AB = BA（常に可換である）", "AB = -BA（反可換である）", "AB = 1（逆数の関係にある）"],
    "exp": "行列の積は一般に交換法則が成り立ちません（非可換）。ただし、特殊な場合（互いに逆行列など）には成り立つこともあります。"
  },
  {
    "sid": 1,
    "q": "単位行列Iと任意の正方行列Aの積について正しいものはどれか。",
    "a": ["AI = IA = A", "AI = -A", "AI = I", "AI = 0"],
    "exp": "単位行列Iは、数における「1」のような役割を果たし、任意の正方行列Aに対して掛け合わせてもAのまま変化しません。"
  },
  {
    "sid": 1,
    "q": "行列の積(AB)の転置行列(AB)^Tと等しいものはどれか。",
    "a": ["B^T A^T", "A^T B^T", "A^T B", "B A^T"],
    "exp": "積の転置は、順序が逆になり、それぞれの転置行列の積となります。(AB)^T = B^T A^T。"
  },
  {
    "sid": 1,
    "q": "正則な行列A, Bの積(AB)の逆行列(AB)^-1と等しいものはどれか。",
    "a": ["B^-1 A^-1", "A^-1 B^-1", "A^-1 B", "B A^-1"],
    "exp": "積の逆行列も転置と同様に順序が逆になります。(AB)^-1 = B^-1 A^-1。"
  },
  {
    "sid": 1,
    "q": "行列の各要素同士を掛け合わせる演算（要素ごとの積）を何と呼ぶか。",
    "a": ["アダマール積", "ドット積", "クロス積", "外積"],
    "exp": "ディープラーニングで頻出する要素ごとの積は「アダマール積」と呼ばれ、記号では⊙などで表されます。"
  },
  {
    "sid": 1,
    "q": "行列Aが逆行列を持つための必要十分条件はどれか。",
    "a": ["det(A) ≠ 0", "det(A) = 0", "trace(A) = 0", "Aが対称行列であること"],
    "exp": "行列式（det）が0でない場合、その行列は正則であり、逆行列を持ちます。"
  },
  {
    "sid": 1,
    "q": "行列の「トレース（対角和）」の定義として正しいものはどれか。",
    "a": ["対角成分の総和", "全成分の総和", "各行の最大値の和", "固有値の積"],
    "exp": "トレース（Trace）は、正方行列の対角成分（左上から右下への成分）をすべて足し合わせた値です。"
  },
  {
    "sid": 1,
    "q": "トレースの性質として正しい式はどれか。",
    "a": ["Tr(AB) = Tr(BA)", "Tr(AB) = Tr(A)Tr(B)", "Tr(A+B) = Tr(A) - Tr(B)", "Tr(A^T) = -Tr(A)"],
    "exp": "トレースは巡回不変性という性質を持ち、Tr(AB) = Tr(BA)が成り立ちます。"
  },
  {
    "sid": 1,
    "q": "L1ノルム（マンハッタン距離）の定義を表す式はどれか（ベクトルxの成分をx_iとする）。",
    "a": ["Σ|x_i|", "√(Σx_i^2)", "max(|x_i|)", "Σ(x_i)"],
    "exp": "L1ノルムは各成分の絶対値の和です。ラッソ回帰（L1正則化）などで使用されます。"
  },
  {
    "sid": 1,
    "q": "L2ノルム（ユークリッド距離）の定義を表す式はどれか。",
    "a": ["√(Σx_i^2)", "Σ|x_i|", "Σx_i^2", "max(x_i)"],
    "exp": "L2ノルムは各成分の二乗和の平方根です。一般的な「距離」の概念に相当します。"
  },
  {
    "sid": 1,
    "q": "2つのベクトルa, bのコサイン類似度を求める式はどれか。",
    "a": ["(a・b) / (||a|| ||b||)", "||a - b||", "(a・b)", "||a|| / ||b||"],
    "exp": "コサイン類似度は、内積をそれぞれのノルムの積で割ることで、ベクトルのなす角のcosθを求めたものです。"
  },
  {
    "sid": 1,
    "q": "正方行列Aが直交行列であるとき、成立する等式はどれか（Iは単位行列）。",
    "a": ["A^T A = A A^T = I", "A = A^T", "A^2 = I", "det(A) = 0"],
    "exp": "直交行列の定義は、転置行列が逆行列になること、つまりA^T A = Iとなることです。"
  },
  {
    "sid": 1,
    "q": "正方行列A、スカラーλ、非ゼロベクトルxに対して「Ax = λx」が成り立つとき、xを何と呼ぶか。",
    "a": ["固有ベクトル", "固有値", "特異ベクトル", "基底ベクトル"],
    "exp": "Ax = λxを満たす非ゼロベクトルxを固有ベクトル、λを固有値と呼びます。"
  },
  {
    "sid": 1,
    "q": "固有値を求めるために解く方程式「det(A - λI) = 0」を何と呼ぶか。",
    "a": ["特性方程式（固有多項式）", "正規方程式", "線形方程式", "状態方程式"],
    "exp": "行列式det(A - λI)を0とおいた方程式を特性方程式と呼び、これを解くことで固有値λが得られます。"
  },
  {
    "sid": 1,
    "q": "行列Aの全ての固有値の「総和」は何と等しいか。",
    "a": ["トレース（対角和）", "行列式", "ランク", "最大特異値"],
    "exp": "固有値の和は、元の行列の対角成分の和（トレース）と一致するという重要な性質があります。"
  },
  {
    "sid": 1,
    "q": "行列Aの全ての固有値の「積」は何と等しいか。",
    "a": ["行列式", "トレース", "ランク", "最小特異値"],
    "exp": "固有値の積は、元の行列の行列式（determinant）と一致します。"
  },
  {
    "sid": 1,
    "q": "行列Aが「A = P Λ P^-1」（Λは対角行列）と分解できるとき、この操作を何と呼ぶか。",
    "a": ["対角化（固有値分解）", "特異値分解", "LU分解", "QR分解"],
    "exp": "正方行列を固有ベクトルを並べた行列Pを用いて対角行列に変形することを対角化と呼びます。"
  },
  {
    "sid": 1,
    "q": "実対称行列（A = A^T）の固有値に関する性質として正しいものはどれか。",
    "a": ["全ての固有値は実数である", "全ての固有値は虚数である", "全ての固有値は1である", "全ての固有値は0である"],
    "exp": "実対称行列は非常に性質が良く、その固有値はすべて実数となり、異なる固有値に対応する固有ベクトルは直交します。"
  },
  {
    "sid": 1,
    "q": "任意の非ゼロベクトルxに対して「x^T A x > 0」となる行列Aを何と呼ぶか。",
    "a": ["正定値行列", "半正定値行列", "直交行列", "特異行列"],
    "exp": "二次形式が常に正になる行列を正定値行列と呼びます。固有値がすべて正であることと同値です。"
  },
  {
    "sid": 1,
    "q": "特異値分解（SVD）において、行列Aはどのように分解されるか（U, Vは直交行列、Σは対角行列）。",
    "a": ["A = U Σ V^T", "A = U Σ U^T", "A = V Σ V^T", "A = P Σ P^-1"],
    "exp": "特異値分解は任意の行列に対して適用可能で、A = U Σ V^T（またはV^*）の形に分解されます。"
  },
  {
    "sid": 1,
    "q": "行列Aの特異値（σ）と、行列A^T Aの固有値（λ）の関係として正しいものはどれか（σ, λ ≧ 0）。",
    "a": ["σ = √λ", "σ = λ", "σ = λ^2", "σ = 1/λ"],
    "exp": "特異値は、A^T A（あるいは A A^T）の固有値の正の平方根として定義されます。"
  },
  {
    "sid": 1,
    "q": "行列の「ランク（階数）」の定義として適切なものはどれか。",
    "a": ["線形独立な行（または列）ベクトルの最大数", "行列の要素の個数", "非ゼロ要素の数", "固有値の個数"],
    "exp": "ランクは、行列の中で互いに線形独立（一次独立）な行または列がいくつあるかを表す指標です。"
  },
  {
    "sid": 1,
    "q": "正方行列でない行列など、逆行列が存在しない場合に、逆行列に似た性質を持つように定義された行列を何と呼ぶか。",
    "a": ["擬似逆行列（ムーア・ペンローズ）", "転置行列", "随伴行列", "余因子行列"],
    "exp": "擬似逆行列は、逆行列の概念を長方形行列や特異行列に一般化したもので、最小二乗法などで利用されます。"
  },
  {
    "sid": 1,
    "q": "ベクトルの集合が「線形独立（一次独立）」であるとはどういう状態か。",
    "a": ["あるベクトルを他のベクトルの線形結合で表せない", "全てのベクトルが直交している", "全てのベクトルの長さが1である", "ベクトルの和が0になる"],
    "exp": "線形独立とは、どのベクトルも「他のベクトルの足し合わせ（スカラー倍含む）」で表現できない状態を指します。"
  },
  {
    "sid": 1,
    "q": "行列A = [[1, 2], [3, 4]] の行列式(det)の値はいくらか。",
    "a": ["-2", "2", "10", "-10"],
    "exp": "2×2行列の行列式は ad - bc で求められます。1*4 - 2*3 = 4 - 6 = -2。"
  },
  {
    "sid": 1,
    "q": "numpyにおいて、形状の異なる配列同士を算術演算できるように自動的に拡張する機能を何と呼ぶか。",
    "a": ["ブロードキャスト", "ベクトル化", "正規化", "スタッキング"],
    "exp": "ブロードキャストは、要素数が異なる配列同士の計算を行う際に、小さい方の配列を自動的に繰り返してサイズを合わせる機能です。"
  },
  {
    "sid": 1,
    "q": "スカラー、ベクトル、行列を一般化した概念で、0階をスカラー、1階をベクトルとするものを何と呼ぶか。",
    "a": ["テンソル", "マトリックス", "スピノル", "ファクター"],
    "exp": "テンソルは多次元配列の数学的な一般化で、スカラーは0階テンソル、ベクトルは1階テンソル、行列は2階テンソルと見なせます。"
  },
  {
    "sid": 1,
    "q": "「固有値分解」が適用できる行列の条件はどれか。",
    "a": ["正方行列であること", "任意の行列", "対称行列のみ", "正定値行列のみ"],
    "exp": "固有値分解は正方行列に対して定義されます（ただし、常に対角化可能とは限りません）。特異値分解は非正方行列にも適用可能です。"
  },
  {
    "sid": 1,
    "q": "データ分散が最大となる方向へ軸を取り直す次元削減手法で、計算に共分散行列の固有値分解を用いるものはどれか。",
    "a": ["主成分分析 (PCA)", "線形判別分析 (LDA)", "t-SNE", "特異値分解 (SVD)"],
    "exp": "主成分分析（PCA）は、データの共分散行列を固有値分解し、固有値が大きい順に固有ベクトル（主成分）を採用して次元圧縮を行います。"
  },
  {
    "sid": 1,
    "q": 'PyTorchでテンソルの形状を変更する（NumPyのreshapeに相当）際、メモリ配置が連続であることを前提によく使われるメソッドは？<br><span style="font-family:monospace; background:#333; padding:2px;">x = torch.randn(4, 4)<br>y = x.[ ? ](16)</span>',
    "a": ['view', 'reshape', 'resize', 'permute'],
    "exp": '「view」はデータをコピーせず形状だけ変えるため頻出です。メモリが不連続な場合は「reshape」を使うか「contiguous().view()」とします。'
  },
  {
    "sid": 1,
    "q": 'テンソルの次元を入れ替える（転置の一般化）メソッドは？（例：(N, H, W, C) → (N, C, H, W)）<br><span style="font-family:monospace; background:#333; padding:2px;">x = x.[ ? ](0, 3, 1, 2)</span>',
    "a": ['permute', 'transpose', 'view', 'swapdims'],
    "exp": '「permute」は全次元の順番を自由に入れ替えます。「transpose」は2つの次元の交換のみです。'
  },
  {
    "sid": 1,
    "q": 'テンソルをGPUに転送する正しいコードは？<br><span style="font-family:monospace; background:#333; padding:2px;">device = torch.device("cuda")<br>x = x.[ ? ](device)</span>',
    "a": ['to', 'cuda', 'gpu', 'move'],
    "exp": '「.to(device)」が最も汎用的な書き方です。「.cuda()」も動きますが、デバイス指定ができるtoが推奨されます。'
  },
  {
    "sid": 1,
    "q": '勾配計算を追跡するためにテンソル作成時に指定する引数は？<br><span style="font-family:monospace; background:#333; padding:2px;">w = torch.randn(10, 10, [ ? ]=True)</span>',
    "a": ['requires_grad', 'gradient', 'trainable', 'with_grad'],
    "exp": '「requires_grad=True」にすることで、計算グラフが構築され、backward時に勾配が計算されます。'
  },
  {
    "sid": 1,
    "q": 'NumPyで行列AとBの「行列積」を計算するコードとして正しいものは？<br><span style="font-family:monospace; background:#333; padding:2px;">A = np.array([[1,2],[3,4]])<br>B = np.array([[5,6],[7,8]])<br>print([ ? ])</span>',
    "a": ['np.dot(A, B)', 'A * B', 'np.multiply(A, B)', 'np.sum(A, B)'],
    "exp": '「*」や「np.multiply」は要素ごとの積（アダマール積）になります。行列積は「np.dot」または「@」演算子を使います。'
  },
  {
    "sid": 1,
    "q": '行列Aの「転置行列」を取得する属性は？<br><span style="font-family:monospace; background:#333; padding:2px;">A = np.array([[1, 2], [3, 4]])<br>print([ ? ])</span>',
    "a": ['A.T', 'A.t', 'A.transpose', 'A.inverse'],
    "exp": 'NumPyのndarrayでは「.T」属性で転置行列を取得できます。'
  },

    // --- 2: 確率・統計 ---
  {
    "sid": 2,
    "q": 'ベイズの定理における事後確率は？',
    "a": ['尤度 × 事前確率', '尤度 ÷ 事前確率', '尤度 + 事前確率', '尤度 - 事前確率'],
    "exp": '正確には(尤度×事前確率)/周辺尤度です。'
  },
  {
    "sid": 2,
    "q": 'ベルヌーイ分布の期待値は？(確率はp)',
    "a": ['p', '1-p', 'p(1-p)', '1'],
    "exp": '0*(1-p) + 1*p = p となります。'
  },
  {
    "sid": 2,
    "q": "確率変数 $X$ の期待値が $E[X]=\\mu$、分散が $V[X]=\\sigma^2$ であるとき、定数 $a, b$ を用いた式 $E[aX+b]$ の結果として正しいものはどれか。",
    "a": ["$a\\mu + b$", "$a\\mu$", "$a^2\\mu + b$", "$a\\mu + b^2$"],
    "exp": "期待値の線形性により、$E[aX+b] = aE[X] + b = a\\mu + b$ となる。"
  },
  {
    "sid": 2,
    "q": "確率変数 $X$ の分散 $V[X]$ を、期待値 $E[X]$ を用いて表した式として正しいものはどれか。",
    "a": ["$E[X^2] - (E[X])^2$", "$E[X^2] + (E[X])^2$", "$(E[X])^2 - E[X^2]$", "$E[(X - E[X])]$"],
    "exp": "分散の公式 $V[X] = E[(X-\\mu)^2]$ を展開すると、$V[X] = E[X^2] - (E[X])^2$ となる。"
  },
  {
    "sid": 2,
    "q": "コインを投げて表が出るか裏が出るかのように、試行結果が2通りしかない試行に従う確率分布はどれか。",
    "a": ["ベルヌーイ分布", "マルチヌーイ分布（カテゴリカル分布）", "ポアソン分布", "正規分布"],
    "exp": "結果が2値（成功/失敗など）の試行をベルヌーイ試行と呼び、それに従うのがベルヌーイ分布である。"
  },
  {
    "sid": 2,
    "q": "確率変数 $X, Y$ が互いに独立であるとき、分散の性質として正しいものはどれか。",
    "a": ["$V[X+Y] = V[X] + V[Y]$", "$V[X+Y] = V[X] + V[Y] + 2Cov[X,Y]$", "$V[X+Y] = V[X] - V[Y]$", "$V[X+Y] = V[X] \\times V[Y]$"],
    "exp": "独立である場合、共分散 $Cov[X,Y]=0$ となるため、$V[X+Y] = V[X] + V[Y]$ が成り立つ。"
  },
  {
    "sid": 2,
    "q": "ベイズの定理を表す式として正しいものはどれか。ただし $P(B) \\neq 0$ とする。",
    "a": ["$P(A|B) = \\frac{P(B|A)P(A)}{P(B)}$", "$P(A|B) = \\frac{P(A|B)P(B)}{P(A)}$", "$P(A|B) = P(B|A)P(B)$", "$P(A|B) = \\frac{P(A)P(B)}{P(B|A)}$"],
    "exp": "ベイズの定理は事後確率 $P(A|B)$ を尤度 $P(B|A)$ と事前確率 $P(A)$ を用いて計算する式である。"
  },
  {
    "sid": 2,
    "q": "ある事象 $x$ の生起確率を $P(x)$ とするとき、自己情報量 $I(x)$ の定義として正しいものはどれか（対数の底は2とする）。",
    "a": ["$- \\log_2 P(x)$", "$\\log_2 P(x)$", "$- P(x) \\log_2 P(x)$", "$1 - P(x)$"],
    "exp": "自己情報量は、確率の逆数の対数、つまり負の対数確率 $- \\log P(x)$ で定義される。確率が低いほど情報量は大きくなる。"
  },
  {
    "sid": 2,
    "q": "確率分布 $P$ のシャノンエントロピー $H(P)$ の定義式として正しいものはどれか。",
    "a": ["$- \\sum P(x) \\log P(x)$", "$\\sum P(x) \\log P(x)$", "$\\sum \\log P(x)$", "$- \\sum P(x)$"],
    "exp": "エントロピーは自己情報量の期待値であり、$- \\sum P(x) \\log P(x)$ で定義される。"
  },
  {
    "sid": 2,
    "q": "2つの確率分布 $P$ と $Q$ の違いを測る指標である「KLダイバージェンス（カルバック・ライブラー情報量）」の性質として、**誤っている**ものはどれか。",
    "a": ["$D_{KL}(P||Q) = D_{KL}(Q||P)$ が常に成り立つ", "$D_{KL}(P||Q) \\ge 0$ である", "$P=Q$ のとき、値は0になる", "非対称な指標である"],
    "exp": "KLダイバージェンスは距離の概念に似ているが、対称性が成り立たない（$D_{KL}(P||Q) \\neq D_{KL}(Q||P)$）ため、正解は「常に成り立つ」という記述。"
  },
  {
    "sid": 2,
    "q": "機械学習の分類問題において、損失関数としてよく用いられる「交差エントロピー（Cross Entropy）」の定義式はどれか。真の分布を $P$、推定分布を $Q$ とする。",
    "a": ["$- \\sum P(x) \\log Q(x)$", "$- \\sum Q(x) \\log P(x)$", "$\\sum P(x) \\log Q(x)$", "$- \\sum P(x) \\log \\frac{P(x)}{Q(x)}$"],
    "exp": "交差エントロピーは、真の分布 $P$ の重みで、推定分布 $Q$ の情報量を平均したもので、$- \\sum P(x) \\log Q(x)$ となる。"
  },
  {
    "sid": 2,
    "q": "確率変数 $X$ が正規分布 $N(\\mu, \\sigma^2)$ に従うとき、標準化（$Z$変換）を行う式はどれか。",
    "a": ["$Z = \\frac{X - \\mu}{\\sigma}$", "$Z = \\frac{X - \\mu}{\\sigma^2}$", "$Z = \\frac{\\mu - X}{\\sigma}$", "$Z = (X - \\mu)\\sigma$"],
    "exp": "標準化とは平均を0、分散を1に変換する操作であり、平均を引き標準偏差で割ることで得られる。"
  },
  {
    "sid": 2,
    "q": "「尤度（Likelihood）」の定義として最も適切な説明はどれか。",
    "a": ["ある観測データが得られた条件下で、パラメータがその値である確からしさ", "あるパラメータの条件下で、そのデータが得られる確率", "データが得られる前のパラメータの確率分布", "データが得られた後のパラメータの確率分布"],
    "exp": "尤度は、あるパラメータ $\\theta$ を仮定したときに、観測データ $D$ が得られる確率 $P(D|\\theta)$ を、$\\theta$ の関数とみなしたものである。"
  },
  {
    "sid": 2,
    "q": "最尤推定（Maximum Likelihood Estimation）において、対数尤度関数を最大化することと等価な処理はどれか。",
    "a": ["負の対数尤度関数を最小化する", "尤度関数を最小化する", "事後確率を最大化する", "事前確率を最大化する"],
    "exp": "最大化問題を最小化問題に置き換えるため、一般的に負の対数尤度（Negative Log Likelihood）の最小化が行われる。"
  },
  {
    "sid": 2,
    "q": "ベイズ推定におけるMAP推定（最大事後確率推定）が最尤推定と異なる点はどこか。",
    "a": ["事前分布を考慮し、事後確率を最大化する点", "尤度関数のみを最大化する点", "常に正規分布を仮定する点", "計算コストが最尤推定より低い点"],
    "exp": "MAP推定は $P(\\theta|D) \\propto P(D|\\theta)P(\\theta)$ を最大化するため、尤度 $P(D|\\theta)$ に加えて事前分布 $P(\\theta)$ の影響を考慮する。"
  },
  {
    "sid": 2,
    "q": "ポアソン分布はどのような事象のモデル化に適しているか。",
    "a": ["単位時間あたりに平均 $\\lambda$ 回起こる稀な事象の発生回数", "成功確率 $p$ の試行を $n$ 回行ったときの成功回数", "連続的な値をとる左右対称な事象", "2つのカテゴリのどちらかに分類される事象"],
    "exp": "ポアソン分布は、特定の期間や面積中で稀に発生する事象の回数（例：1時間のアクセス数、単位面積あたりの欠陥数）を表すのに適している。"
  },
  {
    "sid": 2,
    "q": "確率密度関数 $f(x)$ の全区間における積分値 $\\int_{-\\infty}^{\\infty} f(x) dx$ はいくつになるか。",
    "a": ["1", "0", "平均値 $\\mu$", "分散 $\\sigma^2$"],
    "exp": "確率密度関数の定義より、全事象の確率は1となるため、全区間の積分値は1である。"
  },
  {
    "sid": 2,
    "q": "共分散 $Cov[X,Y]$ が正の値をとるとき、2つの変数 $X, Y$ の関係として正しいものはどれか。",
    "a": ["正の相関がある（片方が増えればもう片方も増える傾向）", "負の相関がある（片方が増えればもう片方は減る傾向）", "無相関である", "独立である"],
    "exp": "共分散が正であれば、Xが大きいときにYも大きい傾向があるため、正の相関がある。"
  },
  {
    "sid": 2,
    "q": "相関係数 $\\rho$ の取りうる値の範囲はどれか。",
    "a": ["$-1 \\le \\rho \\le 1$", "$0 \\le \\rho \\le 1$", "$-\\infty < \\rho < \\infty$", "$-1 < \\rho < 1$（両端を含まない）"],
    "exp": "ピアソンの積率相関係数は、-1（完全な負の相関）から1（完全な正の相関）の範囲をとる。"
  },
  {
    "sid": 2,
    "q": "標本平均の分布が、サンプルサイズ $n$ が大きくなるにつれて正規分布に近づくという定理を何というか。",
    "a": ["中心極限定理", "大数の法則", "ベイズの定理", "チェビシェフの不等式"],
    "exp": "中心極限定理（CLT）は、母集団の分布によらず、サンプルサイズが十分大きければ標本平均の分布は正規分布に近似できるという定理。"
  },
  {
    "sid": 2,
    "q": "イェンセンの不等式（Jensen's Inequality）に関する記述として、$f(x)$ が凸関数であるとき正しい式はどれか。",
    "a": ["$E[f(x)] \\ge f(E[x])$", "$E[f(x)] \\le f(E[x])$", "$E[f(x)] = f(E[x])$", "$E[f(x)] \\times f(E[x]) = 1$"],
    "exp": "下に凸な関数（convex）の場合、期待値の関数値よりも、関数値の期待値の方が大きくなる（または等しい）。"
  },
  {
    "sid": 2,
    "q": "多クラス分類（3クラス以上）の出力層で使用され、出力を確率分布として扱えるようにする活性化関数はどれか。",
    "a": ["ソフトマックス関数", "シグモイド関数", "ReLU関数", "tanh関数"],
    "exp": "ソフトマックス関数は出力を0から1の間に正規化し、総和が1になるように変換するため、カテゴリカル分布（マルチヌーイ分布）のパラメータとして扱える。"
  },
  {
    "sid": 2,
    "q": "ベルヌーイ分布における分散を表す式はどれか。確率変数を $x \\in \\{0,1\\}$、確率を $\\mu$ とする。",
    "a": ["$\\mu(1-\\mu)$", "$\\mu^2$", "$1-\\mu$", "$\\mu$"],
    "exp": "ベルヌーイ分布の分散は $V[x] = \\mu(1-\\mu)$ である。"
  },
  {
    "sid": 2,
    "q": "ベイズ推定において、事前分布と事後分布が同じ確率分布族になるような事前分布を何と呼ぶか。",
    "a": ["共役事前分布", "一様分布", "無情報事前分布", "正規分布"],
    "exp": "尤度関数に対して共役事前分布（Conjugate Prior）を選ぶと、事後分布も同じ種類の分布となり、解析的な計算が容易になる。"
  },
  {
    "sid": 2,
    "q": "2つの変数 $X, Y$ が独立であるための必要十分条件を確率密度関数で表したものはどれか。",
    "a": ["$P(X, Y) = P(X)P(Y)$", "$P(X, Y) = P(X) + P(Y)$", "$P(X|Y) = P(Y|X)$", "$P(X, Y) = 0$"],
    "exp": "同時確率分布が周辺確率分布の積で表せるとき、2つの変数は統計的に独立である。"
  },
  {
    "sid": 2,
    "q": "ロジスティック回帰は、出力変数がどのような分布に従うことを仮定しているか。",
    "a": ["ベルヌーイ分布", "正規分布", "一様分布", "t分布"],
    "exp": "ロジスティック回帰は2値分類であり、目的変数がベルヌーイ分布に従うと仮定してモデル化している。"
  },
  {
    "sid": 2,
    "q": "期待値が0、分散が1の正規分布を特に何と呼ぶか。",
    "a": ["標準正規分布", "多変量正規分布", "一様分布", "ベルヌーイ分布"],
    "exp": "$N(0, 1)$ の正規分布は標準正規分布と呼ばれる。"
  },
  {
    "sid": 2,
    "q": "正規分布に従う確率変数の定数倍 $aX+b$ の分散 $V[aX+b]$ はどうなるか。（元の分散を $\\sigma^2$ とする）",
    "a": ["$a^2 \\sigma^2$", "$a \\sigma^2$", "$a \\sigma^2 + b$", "$a^2 \\sigma^2 + b$"],
    "exp": "分散の性質 $V[aX+b] = a^2 V[X]$ より、定数項 $b$ は分散に影響せず、係数 $a$ は2乗倍される。"
  },
  {
    "sid": 2,
    "q": "情報理論において、エントロピーが最大となる確率分布はどれか（離散分布で定義域が有限の場合）。",
    "a": ["一様分布", "正規分布", "二項分布", "ディラックのデルタ分布"],
    "exp": "事象の不確実性が最も高い状態、つまりすべての事象が等確率で起こる一様分布のときにエントロピーは最大となる。"
  },
  {
    "sid": 2,
    "q": "確率の乗法定理 $P(X, Y) = P(Y|X)P(X)$ を一般化し、変数が連鎖的に依存する場合の式（連鎖律）として正しい考え方はどれか。",
    "a": ["$P(X_1,...X_n) = P(X_1)P(X_2|X_1)...P(X_n|X_1...X_{n-1})$", "$P(X_1,...X_n) = P(X_1)P(X_2)...P(X_n)$", "$P(X_1,...X_n) = P(X_1) + P(X_2|X_1) + ...$", "$P(X_1,...X_n) = P(X_n|X_1)$"],
    "exp": "確率の連鎖律（Chain Rule）により、同時確率は条件付き確率の積に分解できる。"
  },
  {
    "sid": 2,
    "q": "機械学習において、訓練データ数が少ない場合に最尤推定を行うと発生しやすい問題はどれか。",
    "a": ["過学習（Overfitting）", "勾配消失", "アンダーフィッティング", "計算量の増大"],
    "exp": "最尤推定は観測データに最もフィットするパラメータを探すため、データ数が少ないとノイズまで学習してしまい、過学習を起こしやすい（これを防ぐためにMAP推定や正則化を用いる）。"
  },
  {
    "sid": 2,
    "q": "分散共分散行列（Covariance Matrix）の対角成分は何を表しているか。",
    "a": ["各変数の分散", "各変数の期待値", "各変数の標準偏差", "各変数間の相関係数"],
    "exp": "分散共分散行列 $\\Sigma$ の成分 $\\Sigma_{ij}$ において、$i=j$ の対角成分は $Cov[X_i, X_i] = V[X_i]$ となり、各変数の分散を表す。"
  },

    // --- 3: 情報理論 ---
  {
    "sid": 3,
    "q": '自己情報量 I(x) の定義式は？',
    "a": ['-log P(x)', 'log P(x)', '-P(x)log P(x)', '1/P(x)'],
    "exp": '確率が低いほど情報量は大きくなります。'
  },
  {
    "sid": 3,
    "q": 'KLダイバージェンスの特徴は？',
    "a": ['非対称である', '常に負の値をとる', '距離の公理を満たす', '最大値が1'],
    "exp": 'Aから見たBと、Bから見たAの距離は異なります。'
  },
  {
    "sid": 3,
    "q": "ある事象xが起こる確率をP(x)としたとき、自己情報量I(x)の定義として正しいものはどれか。",
    "a": ["- log P(x)", "log P(x)", "- P(x) log P(x)", "P(x) log P(x)"],
    "exp": "自己情報量は確率の対数の符号を反転させたものです。確率が低いほど情報量は大きくなります。"
  },
  {
    "sid": 3,
    "q": "確率変数が2つの値（0か1など）をとり、それぞれの確率が0.5であるとき、この確率分布のエントロピー（対数の底は2）はいくつか。",
    "a": ["1 bit", "0.5 bit", "0 bit", "2 bit"],
    "exp": "-(0.5 log2 0.5 + 0.5 log2 0.5) = -(-0.5 - 0.5) = 1 となります。"
  },
  {
    "sid": 3,
    "q": "シャノンエントロピー（平均情報量）の定義式として正しいものはどれか（離散確率分布Pの場合）。",
    "a": ["- Σ P(x) log P(x)", "Σ P(x) log P(x)", "- Σ P(x) log Q(x)", "Σ P(x) log (P(x)/Q(x))"],
    "exp": "エントロピーは自己情報量の期待値であり、確率は常に1以下なので全体にマイナスをつけて正の値にします。"
  },
  {
    "sid": 3,
    "q": "KLダイバージェンス（カルバック・ライブラー情報量）の性質として、一般に正しい記述はどれか。",
    "a": ["非対称であり、D(P||Q)とD(Q||P)は等しくない", "常に対称であり、距離の公理を満たす", "値は常に負になる", "PとQが等しいとき、値は1になる"],
    "exp": "KLダイバージェンスは「距離」のような概念ですが、対称性が成り立たないため厳密な距離ではありません。"
  },
  {
    "sid": 3,
    "q": "交差エントロピー H(P, Q) を、エントロピー H(P) と KLダイバージェンス D_KL(P||Q) を用いて表した式はどれか。",
    "a": ["H(P) + D_KL(P||Q)", "H(P) - D_KL(P||Q)", "D_KL(P||Q) - H(P)", "H(P) × D_KL(P||Q)"],
    "exp": "交差エントロピーは、真の分布のエントロピーと、分布間の乖離（KL）の和に分解できます。"
  },
  {
    "sid": 3,
    "q": "深層学習の分類問題において、損失関数として交差エントロピーを最小化することは、数学的に何を最小化することと等価か。",
    "a": ["真の分布Pと予測分布QのKLダイバージェンス", "真の分布Pのエントロピー", "予測分布Qのエントロピー", "相互情報量"],
    "exp": "H(P,Q) = H(P) + D_KL(P||Q) において、教師データ（真の分布P）は固定されているため、H(P)は定数となります。よってKLの最小化と等価です。"
  },
  {
    "sid": 3,
    "q": "ある事象の確率が 1/8 であるとき、その自己情報量（底は2）はいくつか。",
    "a": ["3 bit", "8 bit", "0.125 bit", "2 bit"],
    "exp": "- log2 (1/8) = - log2 (2^-3) = 3 となります。"
  },
  {
    "sid": 3,
    "q": "2つの確率変数XとYが互いに独立であるとき、結合エントロピー H(X, Y) はどうなるか。",
    "a": ["H(X) + H(Y)", "H(X) - H(Y)", "H(X) × H(Y)", "0"],
    "exp": "独立であれば、相互の情報に関係性がないため、それぞれのエントロピーの単純な和になります。"
  },
  {
    "sid": 3,
    "q": "相互情報量 I(X;Y) の定義として、エントロピーHを用いた正しい式はどれか。",
    "a": ["H(X) - H(X|Y)", "H(X) + H(X|Y)", "H(X|Y) - H(X)", "H(X) + H(Y)"],
    "exp": "相互情報量は、Yを知ることでXの不確実性がどれだけ減ったか（H(X)から条件付きエントロピーを引いたもの）を表します。"
  },
  {
    "sid": 3,
    "q": "情報理論において、対数の底にネイピア数 e を用いた場合の単位は何か。",
    "a": ["nat (ナット)", "bit (ビット)", "hartley (ハートレー)", "ban (バン)"],
    "exp": "底が2の場合はbit、底が10の場合はhartley、底がeの場合はnatを用います。"
  },
  {
    "sid": 3,
    "q": "連続確率分布におけるエントロピー（微分エントロピー）の性質として、離散の場合と異なる点はどれか。",
    "a": ["負の値をとることがある", "常に正の値である", "確率密度関数の最大値に等しい", "常に0になる"],
    "exp": "離散エントロピーは常に非負ですが、連続変数の微分エントロピーは確率密度が1を超えると対数値が正になり、全体として負になる可能性があります。"
  },
  {
    "sid": 3,
    "q": "条件付きエントロピー H(Y|X) と結合エントロピー H(X,Y) の関係を示す連鎖律（Chain Rule）はどれか。",
    "a": ["H(X,Y) = H(X) + H(Y|X)", "H(X,Y) = H(X) - H(Y|X)", "H(X,Y) = H(X) × H(Y|X)", "H(X,Y) = H(X) / H(Y|X)"],
    "exp": "結合エントロピーは、Xの不確実性と、Xを知った上でのYの不確実性の和に分解できます。"
  },
  {
    "sid": 3,
    "q": "KLダイバージェンス D_KL(P||Q) が 0 になるのはどのような時か。",
    "a": ["分布Pと分布Qが完全に一致するとき", "分布Pと分布Qが独立のとき", "分布Pが一様分布のとき", "分布Qが一様分布のとき"],
    "exp": "KLダイバージェンスは分布間の相違度を表すため、分布が同一であれば 0 となります。"
  },
  {
    "sid": 3,
    "q": "ギブスの不等式が示している事実はどれか。",
    "a": ["KLダイバージェンスは常に0以上である", "交差エントロピーは常に0である", "エントロピーは常に1以下である", "相互情報量は負になることがある"],
    "exp": "ギブスの不等式は D_KL(P||Q) ≧ 0 を保証するもので、情報理論の重要な基礎不等式です。"
  },
  {
    "sid": 3,
    "q": "ある確率変数が確定的に起こる（確率が1である）場合、そのエントロピーはいくつか。",
    "a": ["0", "1", "無限大", "未定義"],
    "exp": "確率1の事象は不確実性がないため、情報量（エントロピー）は0になります。"
  },
  {
    "sid": 3,
    "q": "相互情報量 I(X;Y) と KLダイバージェンスの関係として正しい式はどれか。",
    "a": ["I(X;Y) = D_KL( P(X,Y) || P(X)P(Y) )", "I(X;Y) = D_KL( P(X) || P(Y) )", "I(X;Y) = D_KL( P(X)P(Y) || P(X,Y) )", "I(X;Y) = H(X) + D_KL(X||Y)"],
    "exp": "相互情報量は、「結合分布」と「独立を仮定した積分布」との間のKLダイバージェンスとして定義できます。"
  },
  {
    "sid": 3,
    "q": "離散確率変数において、とりうる値の数がN個であるとき、エントロピーが最大になるのはどのような分布か。",
    "a": ["一様分布", "正規分布", "ベルヌーイ分布", "ポアソン分布"],
    "exp": "離散分布では、すべての事象が等確率（1/N）で起こる一様分布のときに不確実性が最大となり、エントロピーも最大化されます。"
  },
  {
    "sid": 3,
    "q": "交差エントロピー誤差関数を用いる際、ニューラルネットワークの最終層（出力層）によく用いられる活性化関数はどれか（多クラス分類の場合）。",
    "a": ["ソフトマックス関数", "シグモイド関数", "ReLU関数", "tanh関数"],
    "exp": "出力を確率分布として扱うために、総和が1になるソフトマックス関数を用い、その出力と正解ラベル（one-hot）との交差エントロピーを計算します。"
  },
  {
    "sid": 3,
    "q": "次のうち、エントロピーの性質として誤っているものはどれか。",
    "a": ["確率変数の値そのものの大きさに依存する", "非負である（離散の場合）", "事象の不確実性を表す尺度である", "確率分布が一点に集中すると最小値をとる"],
    "exp": "エントロピーは「確率分布の形状」に依存するものであり、確率変数そのものの値（ラベルの数字の大きさなど）には依存しません。"
  },
  {
    "sid": 3,
    "q": "イェンセンの不等式（Jensen's inequality）が情報理論の証明でよく使われるのはなぜか。",
    "a": ["対数関数（log）が凸関数（上に凸）であるため", "指数関数が線形であるため", "確率変数が常に正だから", "エントロピーが微分可能だから"],
    "exp": "KLダイバージェンスの非負性などを証明する際、対数関数の凹凸性を利用したイェンセンの不等式が用いられます。"
  },
  {
    "sid": 3,
    "q": "相互情報量の対称性に関する記述として正しいものはどれか。",
    "a": ["I(X;Y) = I(Y;X)", "I(X;Y) > I(Y;X)", "I(X;Y) < I(Y;X)", "一般に対称性は成り立たない"],
    "exp": "XがYについて持つ情報量と、YがXについて持つ情報量は等しく、相互情報量は対称です。"
  },
  {
    "sid": 3,
    "q": "X -> Y -> Z というマルコフ連鎖が成り立つとき、データ処理不等式が示す関係はどれか。",
    "a": ["I(X;Y) ≧ I(X;Z)", "I(X;Y) ≦ I(X;Z)", "I(X;Y) = I(X;Z)", "H(X) < H(Z)"],
    "exp": "加工（Y->Z）によって情報が増えることはないため、直接の観測Yとの相互情報量は、加工後Zとの相互情報量以上になります。"
  },
  {
    "sid": 3,
    "q": "ロジスティック回帰を用いた2値分類において、損失関数に使用されるのはどれか。",
    "a": ["バイナリ交差エントロピー", "平均二乗誤差", "ヒンジ損失", "KLダイバージェンス（直接）"],
    "exp": "2値分類（確率pと1-p）の場合の交差エントロピーは、特にバイナリ交差エントロピー（Log Loss）と呼ばれます。"
  },
  {
    "sid": 3,
    "q": "自己情報量の加法性とはどのような性質か。",
    "a": ["独立した事象の同時確率は積になるため、情報量は和になる", "独立した事象の同時確率は和になるため、情報量は積になる", "情報量は常に足し算できる", "情報量は確率の和に等しい"],
    "exp": "log(P(x)P(y)) = log P(x) + log P(y) の性質により、独立事象が同時に起こる情報量は、個々の情報量の和になります。"
  },
  {
    "sid": 3,
    "q": "真の分布Pが [1, 0]、予測分布Qが [0.8, 0.2] のとき、交差エントロピー（底e）の計算式として正しいのはどれか。",
    "a": ["- (1 * log 0.8 + 0 * log 0.2)", "- (0.8 * log 1 + 0.2 * log 0)", "- (1 * log 1 + 0 * log 0)", "- log(0.8 / 1)"],
    "exp": "交差エントロピーの定義 -Σ P(x) log Q(x) に従い、P(x)=1の項だけが残ります。"
  },
  {
    "sid": 3,
    "q": "エントロピー H(X) が最大となるのは、事象の予測がどのような状態のときか。",
    "a": ["最も困難（完全にランダム）なとき", "最も容易なとき", "事象が2つのとき", "確率が0に近いとき"],
    "exp": "エントロピーは不確実性の尺度であるため、予測が最もつかない（ランダム性が高い）ときに最大となります。"
  },
  {
    "sid": 3,
    "q": "条件付きエントロピー H(X|Y) が 0 になるのはどのような場合か。",
    "a": ["Yが決まればXが一意に定まる場合", "XとYが独立の場合", "XとYが同一分布の場合", "Xが一様分布の場合"],
    "exp": "Yを知ったときにXの不確実性がなくなる（決定論的になる）場合、条件付きエントロピーは0になります。"
  },
  {
    "sid": 3,
    "q": "KLダイバージェンスは別名何と呼ばれるか。",
    "a": ["相対エントロピー", "絶対エントロピー", "条件付き情報量", "結合情報量"],
    "exp": "KLダイバージェンスは、ある分布に対する別の分布の相対的な情報量を表すため、相対エントロピーとも呼ばれます。"
  },
  {
    "sid": 3,
    "q": "平均符号長の下界を与える定理はどれか。",
    "a": ["情報源符号化定理（シャノンの第一基本定理）", "通信路符号化定理（シャノンの第二基本定理）", "ベイズの定理", "中心極限定理"],
    "exp": "データを可逆圧縮する際、平均符号長はエントロピーよりも小さくできないことを示しています。"
  },
  {
    "sid": 3,
    "q": "確率分布 P と Q の交差エントロピーと、Pのエントロピーが等しくなるのはいつか。",
    "a": ["P = Q のとき", "PとQが独立のとき", "Qが一様分布のとき", "常に等しい"],
    "exp": "H(P,Q) = H(P) + D_KL(P||Q) なので、D_KLが0、つまりP=Qのときに両者は等しくなります。"
  },

    // --- 4: 機械学習の基礎 ---
  {
    "sid": 4,
    "q": 'バイアス・バリアンス分解において、モデルが複雑すぎるときに高くなるのは？',
    "a": ['バリアンス', 'バイアス', 'ノイズ', '正解率'],
    "exp": '複雑すぎると過学習し、バリアンスが高くなります。'
  },
  {
    "sid": 4,
    "q": "線形回帰モデルにおいて、予測値と実測値の誤差を評価するためによく用いられる損失関数はどれか。",
    "a": ["平均二乗誤差 (MSE)","交差エントロピー誤差","ヒンジ損失","対数尤度"],
    "exp": "線形回帰では、残差の二乗の平均をとるMSE（Mean Squared Error）が一般的に用いられます。"
  },
  {
    "sid": 4,
    "q": "L1正則化（Lasso）の特徴として、最も適切な記述はどれか。",
    "a": ["不要な特徴量の重みを完全に0にすることができ、スパース性が生まれる","重みを0に近づけるが完全に0にはならず、滑らかな解が得られる","複数の相関する特徴量がある場合、それら全てを均等に選択する傾向がある","L2正則化よりも計算コストが低い"],
    "exp": "L1正則化は菱形の制約領域を持つため、解が軸上に乗りやすく、結果として不要なパラメータが0になりやすい（特徴量選択の効果がある）のが特徴です。"
  },
  {
    "sid": 4,
    "q": "ロジスティック回帰において、出力値を0から1の範囲（確率）に変換するために使用される活性化関数はどれか。",
    "a": ["シグモイド関数","ReLU関数","tanh関数","ソフトマックス関数"],
    "exp": "ロジスティック回帰（二値分類）では、入力の線形結合をシグモイド関数に通すことで確率として解釈可能な値を得ます。"
  },
  {
    "sid": 4,
    "q": "サポートベクターマシン（SVM）において、クラス間の境界線から最も近いデータ点までの距離を何と呼ぶか。",
    "a": ["マージン","サポートベクター","バイアス","カーネル"],
    "exp": "SVMは、この「マージン」を最大化するように決定境界を引く手法です。"
  },
  {
    "sid": 4,
    "q": "機械学習モデルの汎化性能を評価するために、データを訓練用とテスト用に分割する方法を何と呼ぶか。",
    "a": ["ホールドアウト法","ブートストラップ法","グリッドサーチ","アンサンブル学習"],
    "exp": "データをあらかじめ訓練データとテストデータに分割し、未知のデータに対する性能を測る手法をホールドアウト法と呼びます。"
  },
  {
    "sid": 4,
    "q": "過学習（Overfitting）が起きている状態の説明として正しいものはどれか。",
    "a": ["訓練データに対する誤差は小さいが、テストデータに対する誤差が大きい","訓練データに対してもテストデータに対しても誤差が大きい","バイアスが高く、バリアンスが低い状態である","モデルが単純すぎてデータのパターンを捉えきれていない"],
    "exp": "過学習は、訓練データに過剰に適応してしまい、未知のデータ（テストデータ）に対する予測性能が落ちる現象です。これは高バリアンスの状態です。"
  },
  {
    "sid": 4,
    "q": "k-means法（k-平均法）に関する記述として正しいものはどれか。",
    "a": ["教師なし学習の一種であり、データをk個のクラスタに分類する","教師あり学習の一種であり、正解ラベルを用いて学習する","階層型クラスタリングの一種である","外れ値の影響を受けにくい堅牢な手法である"],
    "exp": "k-means法は代表的な非階層型クラスタリング手法（教師なし学習）です。初期値依存や外れ値に弱いという特徴があります。"
  },
  {
    "sid": 4,
    "q": "決定木において、分割の良さを評価する指標として用いられる「ジニ不純度」が0になるのはどのような状態か。",
    "a": ["そのノード内の全てのデータが同じクラスに属している","そのノード内のクラスが完全に均等に混ざっている","そのノード内のデータ数が0である","そのノードの深さが最大に達している"],
    "exp": "ジニ不純度はクラスの混ざり具合を表し、単一クラスのみで構成される（純度が高い）場合に最小値0を取ります。"
  },
  {
    "sid": 4,
    "q": "二値分類の評価指標において、「正解が正のデータのうち、正しく正と予測できた割合」を示すものはどれか。",
    "a": ["再現率 (Recall)","適合率 (Precision)","正解率 (Accuracy)","特異度 (Specificity)"],
    "exp": "Recall = TP / (TP + FN)。見逃しを少なくしたい場合に重視される指標です。"
  },
  {
    "sid": 4,
    "q": "k-近傍法（k-NN）において、ハイパーパラメータkの値を非常に小さくした場合（例：k=1）に起こりやすい現象はどれか。",
    "a": ["決定境界が複雑になり、過学習しやすくなる","決定境界が滑らかになり、未学習になりやすくなる","計算コストが大幅に増加する","全てのアウトライヤーが無視される"],
    "exp": "kが小さいと局所的なデータ配置（ノイズ含む）に鋭敏に反応するため、決定境界が複雑になり過学習のリスクが高まります。"
  },
  {
    "sid": 4,
    "q": "ランダムフォレストの説明として正しいものはどれか。",
    "a": ["バギングを用いたアンサンブル学習であり、並列に決定木を作成する","ブースティングを用いたアンサンブル学習であり、直列に決定木を作成する","主成分分析を用いて特徴量を削減してから決定木を作成する","全データを使い、深さ1の決定木（スタンプ）を多数作成する"],
    "exp": "ランダムフォレストは、ブートストラップサンプリングと特徴量のランダム選択を組み合わせたバギングの一種です。"
  },
  {
    "sid": 4,
    "q": "主成分分析（PCA）の目的として最も適切なものはどれか。",
    "a": ["分散が最大となる方向を見つけ、次元圧縮を行う","クラス間の分離が最大となる方向を見つけ、分類を行う","データ間の距離を保存したまま非線形写像を行う","教師あり学習により特徴量を選択する"],
    "exp": "PCAはデータの分散が最大になる方向を主成分とし、情報をなるべく損なわずに次元を削減する教師なし学習手法です。"
  },
  {
    "sid": 4,
    "q": "ROC曲線において、横軸と縦軸の組み合わせとして正しいものはどれか。",
    "a": ["横軸：偽陽性率 (FPR)、縦軸：真陽性率 (TPR)","横軸：適合率 (Precision)、縦軸：再現率 (Recall)","横軸：真陽性率 (TPR)、縦軸：偽陽性率 (FPR)","横軸：閾値、縦軸：正解率 (Accuracy)"],
    "exp": "ROC曲線は、閾値を変化させたときのFPR（1-特異度）を横軸、TPR（再現率）を縦軸にプロットしたものです。"
  },
  {
    "sid": 4,
    "q": "勾配ブースティング決定木（GBDT）の基本的な考え方はどれか。",
    "a": ["前の弱学習器の残差（誤差）を次の弱学習器が学習して修正していく","互いに独立した弱学習器を多数作成し、多数決で予測する","データをクラスタリングし、各クラスタごとに決定木を作る","ニューラルネットワークの重みを決定木で初期化する"],
    "exp": "ブースティングは、前のモデルが上手く予測できなかった部分（残差）を次のモデルが補うように学習を進める手法です。"
  },
  {
    "sid": 4,
    "q": "L2正則化（Ridge）を加えた線形回帰の損失関数はどのように表されるか（Wは重みベクトル）。",
    "a": ["MSE + λ||W||₂²","MSE + λ||W||₁","MSE + λ log(W)","MSE - λ||W||₂²"],
    "exp": "L2正則化は、重みの二乗ノルム（ユークリッド距離の二乗）をペナルティ項として損失関数に加えます。"
  },
  {
    "sid": 4,
    "q": "分類問題において、データセットのクラスバランスが極端に偏っている（不均衡データ）場合、評価指標として不適切なものはどれか。",
    "a": ["正解率 (Accuracy)","F1スコア","AUC (Area Under the Curve)","混合行列 (Confusion Matrix)"],
    "exp": "不均衡データでは、多数派クラスを全て予測するだけで高いAccuracyが出てしまうため、モデルの実用性を測る指標として不適切です。"
  },
  {
    "sid": 4,
    "q": "ナイーブベイズ分類器が置いている「ナイーブ（単純）」な仮定とは何か。",
    "a": ["特徴量同士が互いに独立である","データが正規分布に従う","決定境界が線形である","すべてのクラスの事前確率が等しい"],
    "exp": "ナイーブベイズは、目的変数が与えられた条件下で、各特徴量が独立である（条件付き独立）と仮定することで計算を単純化しています。"
  },
  {
    "sid": 4,
    "q": "SVMにおいて、線形分離不可能なデータを扱うために、データを高次元空間へ写像した内積計算を効率的に行う手法を何と呼ぶか。",
    "a": ["カーネルトリック","ヒンジ損失最小化","ソフトマージン","次元の呪い"],
    "exp": "カーネルトリックを用いることで、高次元への明示的な写像を行わずに、高次元空間での内積（類似度）を計算し、非線形分離を可能にします。"
  },
  {
    "sid": 4,
    "q": "k-分割交差検証（k-fold cross-validation）の説明として正しいものはどれか。",
    "a": ["データをk個に分割し、1つをテスト用、残りを訓練用としてk回検証を行う","データをk個に分割し、k個の異なるモデルで学習を行う","k個のハイパーパラメータを同時に探索する手法である","学習データをk倍に拡張して学習を行う手法である"],
    "exp": "データの偏りによる評価のブレを防ぎ、全データをテストに使用できるため、汎化性能をより信頼性高く評価できます。"
  },
  {
    "sid": 4,
    "q": "決定木における「剪定（Pruning）」の主な目的は何か。",
    "a": ["木の複雑さを抑え、過学習を防ぐ","木の深さを深くして、訓練誤差を0にする","計算速度を上げるために、特徴量を減らす","欠損値を補完する"],
    "exp": "決定木は深く成長させすぎると過学習するため、不要な枝（ノード）を削除する剪定を行い、汎化性能を向上させます。"
  },
  {
    "sid": 4,
    "q": "標準化（Standardization）の処理内容として正しいものはどれか。",
    "a": ["平均を0、分散（標準偏差）を1にする変換","最小値を0、最大値を1にする変換","ベクトルを単位ベクトル（長さ1）にする変換","対数変換を行って分布を正規分布に近づける"],
    "exp": "標準化は (x - mean) / std で計算され、特徴量のスケールを揃えるために行われます。0-1にするのは正規化（Min-Maxスケーリング）です。"
  },
  {
    "sid": 4,
    "q": "F1スコアは、適合率（Precision）と再現率（Recall）のどのような平均か。",
    "a": ["調和平均","算術平均","幾何平均","加重平均"],
    "exp": "F1 = 2 * (Precision * Recall) / (Precision + Recall)。極端に低い値がある場合、そちらに引きずられる調和平均を用います。"
  },
  {
    "sid": 4,
    "q": "バイアス・バリアンス分解において、モデルが単純すぎてデータ構造を捉えられていない（未学習）状態は、どう表現されるか。",
    "a": ["高バイアス・低バリアンス","低バイアス・高バリアンス","高バイアス・高バリアンス","低バイアス・低バリアンス"],
    "exp": "単純すぎるモデルは、どの訓練データセットでも似たような間違った予測をするため、バイアスが高く、バリアンス（変動）は低くなります。"
  },
  {
    "sid": 4,
    "q": "エラスティックネット（Elastic Net）の特徴はどれか。",
    "a": ["L1正則化とL2正則化の両方の項を持つ","ニューラルネットワークの重みを共有する手法である","回帰木と線形回帰を組み合わせた手法である","正則化項を持たず、データ数を増やす手法である"],
    "exp": "Elastic NetはL1（Lasso）による変数選択と、L2（Ridge）による係数の安定化の利点を併せ持つ手法です。"
  },
  {
    "sid": 4,
    "q": "ロジスティック回帰における損失関数「交差エントロピー誤差」の式（二値分類、yは正解{0,1}、pは予測確率）として正しい形はどれか（符号は最小化として考える）。",
    "a": ["- (y log(p) + (1-y) log(1-p))","(y - p)^2","y log(p)","- p log(y)"],
    "exp": "これは対数尤度の符号を反転させたもので、正解ラベルの確率を最大化することと同義です。"
  },
  {
    "sid": 4,
    "q": "SVMにおける「ソフトマージン」の説明として正しいものはどれか。",
    "a": ["一部のデータがマージンの内側や誤分類されることを許容する","マージンを0に設定する","カーネル関数にソフトマックス関数を使用する","決定境界を曲線にする"],
    "exp": "データが線形分離不可能な場合やノイズがある場合に、ペナルティパラメータCを用いて誤分類をある程度許容してマージンを決定する手法です。"
  },
  {
    "sid": 4,
    "q": "階層型クラスタリングの結果を可視化するために用いられる樹形図を何と呼ぶか。",
    "a": ["デンドログラム","ヒストグラム","スキャッタープロット","ヒートマップ"],
    "exp": "デンドログラムは、クラスタが結合されていく過程（距離や類似度）を木構造で可視化したものです。"
  },
  {
    "sid": 4,
    "q": "多重共線性（マルチコ）が発生している場合の問題点として適切なものはどれか。",
    "a": ["回帰係数の分散が大きくなり、推定値が不安定になる","モデルが必ず過学習を起こす","決定係数が必ず1になる","計算不能になりエラーで停止する"],
    "exp": "相関の高い特徴量が複数あると、回帰係数の推定が不安定になり、解釈が困難になります（標準誤差が増大する）。"
  },
  {
    "sid": 4,
    "q": "k-means++法の初期化手法の特徴はどれか。",
    "a": ["既に選ばれた中心点から距離が遠いデータ点ほど、次の中心点に選ばれやすくする","全ての中心点を完全にランダムに選ぶ","データ密度の高い領域から中心点を選ぶ","主成分分析の結果に基づいて中心点を選ぶ"],
    "exp": "k-meansは初期値に依存するため、k-means++では初期の中心同士が離れるように選択確率を調整し、安定性を向上させます。"
  },
  {
    "sid": 4,
    "q": "次元削減手法の一つであるt-SNE（t-distributed Stochastic Neighbor Embedding）の主な用途はどれか。",
    "a": ["高次元データの可視化（2次元や3次元への圧縮）","線形回帰の前処理としての特徴量選択","画像データのノイズ除去","欠損値の補完"],
    "exp": "t-SNEは、高次元空間でのデータ点間の近傍関係を低次元空間でも保つように配置する、非線形の次元削減手法で、主に可視化に使われます。"
  },

    // --- 5: 前処理・特徴・指標 ---
  {
    "sid": 5,
    "q": '平均を0、分散を1にする変換は？',
    "a": ['標準化(Standardization)', '正規化(Normalization)', '白色化', '対数変換'],
    "exp": '正規化は最小0・最大1にする場合を指すことが多いです。'
  },
  {
    "sid": 5,
    "q": 'F値(F1-score)の計算式は？',
    "a": ['2×Recall×Precision / (Recall+Precision)', 'Recall+Precision / 2', 'TP / (TP+FP)', 'TP / (TP+FN)'],
    "exp": '適合率と再現率の調和平均です。'
  },
  {
    "sid": 5,
    "q": "データセットの各特徴量を、平均が0、分散が1になるように変換する処理の名称として、最も適切なものを選べ。",
    "a": ["標準化 (Standardization)", "正規化 (Normalization)", "白色化 (Whitening)", "主成分分析 (PCA)"],
    "exp": "平均0、分散1に変換する処理は標準化（Standardization）と呼ばれる。正規化は主に0〜1の範囲に収める処理を指す。"
  },
  {
    "sid": 5,
    "q": "Min-Max正規化を行うための数式として、正しいものを選べ（xは元の値、minは最小値、maxは最大値とする）。",
    "a": ["(x - min) / (max - min)", "(x - mean) / std", "(x - min) / (max + min)", "x / max"],
    "exp": "Min-Max正規化は、データを[0, 1]の範囲にスケーリングする手法であり、(x - min) / (max - min) で計算される。"
  },
  {
    "sid": 5,
    "q": "特徴量間の相関を無くし（無相関化）、さらに分散を1に揃える処理の名称を選べ。",
    "a": ["白色化 (Whitening)", "正則化 (Regularization)", "バッチ正規化 (Batch Normalization)", "局所コントラスト正規化"],
    "exp": "白色化（Whitening）は、データの成分間の相関をなくし、かつ各成分の分散を1にする処理である。"
  },
  {
    "sid": 5,
    "q": "欠損値の処理手法において、欠損していないデータを用いてモデルを構築し、そのモデルで欠損値を予測して補完する手法はどれか。",
    "a": ["モデルベース補完（回帰代入等）", "リストワイズ削除", "平均値代入法", "最頻値代入法"],
    "exp": "他の変数から欠損値を予測するモデルを作成し、その予測値で埋める手法を指す。平均値や最頻値代入よりも精度が高い場合がある。"
  },
  {
    "sid": 5,
    "q": "過学習を防ぐために、訓練データに対してランダムにノイズを加えたり、画像を回転・反転させたりしてデータ数を擬似的に増やす手法はどれか。",
    "a": ["Data Augmentation", "Dropout", "Ensemble Learning", "Early Stopping"],
    "exp": "Data Augmentation（データ拡張）は、既存のデータに変換を加えてデータを水増しし、モデルの汎化性能を向上させる手法である。"
  },
  {
    "sid": 5,
    "q": "特徴選択（Feature Selection）の手法において、特徴量と目的変数との統計的な関連度（相関係数やカイ二乗検定など）に基づいてスコアリングし、上位の特徴量を選択する手法はどれか。",
    "a": ["Filter Method", "Wrapper Method", "Embedded Method", "Ensemble Method"],
    "exp": "Filter Methodは、学習モデルを使用せず、統計的指標のみで特徴量を評価・選択する手法。計算コストが低いのが特徴。"
  },
  {
    "sid": 5,
    "q": "特徴選択の手法において、実際に学習モデルを使用して特徴量のサブセットを評価し、最適な組み合わせを探索する手法（例：再帰的特徴消去 RFE）はどれか。",
    "a": ["Wrapper Method", "Filter Method", "Embedded Method", "Kernel Method"],
    "exp": "Wrapper Methodは、特定のモデルを使って特徴量の組み合わせを評価する。精度は高くなりやすいが、計算コストが高い。"
  },
  {
    "sid": 5,
    "q": "Lasso回帰のように、モデルの学習プロセス自体に特徴選択の機能（係数を0にするなど）が組み込まれている手法はどれか。",
    "a": ["Embedded Method", "Filter Method", "Wrapper Method", "Boosting"],
    "exp": "Embedded Method（埋め込み法）は、L1正則化(Lasso)のように、学習の過程で自動的に特徴選択が行われる手法である。"
  },
  {
    "sid": 5,
    "q": "主成分分析（PCA）の説明として、最も適切なものを選べ。",
    "a": ["データの分散が最大になる方向を主成分として次元圧縮を行う教師なし学習", "クラス間の分散を最大にし、クラス内の分散を最小にする教師あり学習", "非線形な構造を保ちながら次元圧縮を行う手法", "ニューラルネットワークを用いて恒等写像を学習する手法"],
    "exp": "PCAは、データの分散が最大になる直交基底（主成分）を見つけ、そこへデータを射影することで次元圧縮を行う教師なし学習である。"
  },
  {
    "sid": 5,
    "q": "線形判別分析（LDA）の説明として、最も適切なものを選べ。",
    "a": ["クラス間分散を最大化し、クラス内分散を最小化する射影軸を見つける教師あり学習", "データの分散が最大になる方向を見つける教師なし学習", "高次元空間での近傍関係を低次元でも保つように配置する手法", "ランダムな射影行列を用いて次元を削減する手法"],
    "exp": "LDAは、異なるクラスを最もよく分離できる軸を見つける教師あり学習の手法である。"
  },
  {
    "sid": 5,
    "q": "高次元データの可視化によく用いられ、高次元空間での点同士の類似度分布と、低次元空間での類似度分布のカルバック・ライブラー情報量（KLダイバージェンス）を最小化する非線形な次元圧縮手法はどれか。",
    "a": ["t-SNE", "PCA", "SVD", "LDA"],
    "exp": "t-SNE（t-Distributed Stochastic Neighbor Embedding）は、高次元データの局所的な構造を保ちながら低次元に埋め込む手法で、可視化に優れている。"
  },
  {
    "sid": 5,
    "q": "二値分類問題における混同行列（Confusion Matrix）において、実際に正であるものを正と予測できた件数を何と呼ぶか。",
    "a": ["True Positive (TP)", "True Negative (TN)", "False Positive (FP)", "False Negative (FN)"],
    "exp": "実際がPositiveで、予測もPositiveだった場合はTrue Positive（真陽性）と呼ばれる。"
  },
  {
    "sid": 5,
    "q": "混同行列において、「実際は負（Negative）であるものを、誤って正（Positive）と予測してしまった」件数を何と呼ぶか。",
    "a": ["False Positive (FP)", "False Negative (FN)", "True Positive (TP)", "True Negative (TN)"],
    "exp": "予測がPositive（陽性）だが、それが誤り（False）であるため、False Positive（偽陽性）と呼ばれる。"
  },
  {
    "sid": 5,
    "q": "正解率（Accuracy）を計算する式として正しいものを選べ（TP, TN, FP, FNを使用）。",
    "a": ["(TP + TN) / (TP + TN + FP + FN)", "TP / (TP + FP)", "TP / (TP + FN)", "2TP / (2TP + FP + FN)"],
    "exp": "Accuracyは全データのうち、正しく予測できたもの（TPとTN）の割合である。"
  },
  {
    "sid": 5,
    "q": "適合率（Precision）の説明として正しいものを選べ。",
    "a": ["正と予測したもののうち、実際に正であった割合", "実際に正であるもののうち、正と予測できた割合", "正と予測したもののうち、実際は負であった割合", "全データのうち、正しく予測できた割合"],
    "exp": "Precision = TP / (TP + FP)。「予測の正確さ」を表す指標であり、誤検知（FP）を減らしたい場合に重視される。"
  },
  {
    "sid": 5,
    "q": "再現率（Recall）の説明として正しいものを選べ。",
    "a": ["実際に正であるもののうち、正と予測できた割合", "正と予測したもののうち、実際に正であった割合", "全データのうち、正しく予測できた割合", "実際に負であるもののうち、負と予測できた割合"],
    "exp": "Recall = TP / (TP + FN)。「取りこぼしの少なさ」を表す指標であり、見逃し（FN）を避けたい場合（病気の診断など）に重視される。"
  },
  {
    "sid": 5,
    "q": "F値（F1-score）の定義として正しいものを選べ。",
    "a": ["適合率と再現率の調和平均", "適合率と再現率の相加平均", "適合率と再現率の相乗平均", "適合率と再現率の差の絶対値"],
    "exp": "F値はPrecisionとRecallのバランスを見る指標で、2 * (Precision * Recall) / (Precision + Recall) で計算される調和平均である。"
  },
  {
    "sid": 5,
    "q": "多クラス分類の評価指標において、各クラスごとに指標を計算してから単純平均を取る（クラスごとのサンプル数を考慮しない）平均化手法はどれか。",
    "a": ["Macro-average", "Micro-average", "Weighted-average", "Harmonic-average"],
    "exp": "Macro-averageは各クラスの値を単純に平均するため、サンプル数の少ないクラスの影響も大きく反映される。"
  },
  {
    "sid": 5,
    "q": "ROC曲線の縦軸と横軸の組み合わせとして正しいものを選べ。",
    "a": ["縦軸：真陽性率 (TPR)、横軸：偽陽性率 (FPR)", "縦軸：適合率 (Precision)、横軸：再現率 (Recall)", "縦軸：真陽性率 (TPR)、横軸：真陰性率 (TNR)", "縦軸：正解率 (Accuracy)、横軸：閾値"],
    "exp": "ROC曲線は、閾値を変動させたときのTPR（Recall）とFPR（1 - Specificity）の軌跡を描いたものである。"
  },
  {
    "sid": 5,
    "q": "AUC（Area Under the Curve）の値が0.5であるモデルの性能として、最も適切な解釈はどれか。",
    "a": ["ランダムな予測と同等の性能（性能が低い）", "完璧に分類できている（最高の性能）", "全てのデータを負と予測している", "全てのデータを正と予測している"],
    "exp": "AUCは0.5〜1の範囲をとり、1に近いほど性能が良い。0.5はランダム予測（コイントス）と同等の性能であることを意味する。"
  },
  {
    "sid": 5,
    "q": "データセットにおいて、正例（Positive）の数が負例（Negative）に比べて極端に少ない「不均衡データ」の場合、ROC曲線よりも重視すべきとされる曲線はどれか。",
    "a": ["PR曲線 (Precision-Recall Curve)", "ロジスティック曲線", "回帰直線", "シグモイド曲線"],
    "exp": "不均衡データでは、TN（真陰性）が大量になりFPRが小さくなりやすいため、ROC曲線では性能を過大評価する場合がある。そのためPR曲線が推奨される。"
  },
  {
    "sid": 5,
    "q": "物体検出（Object Detection）の評価指標として用いられるIoU（Intersection over Union）の計算式において、分母に来るものは何か。",
    "a": ["予測バウンディングボックスと正解バウンディングボックスの和集合の面積", "予測バウンディングボックスと正解バウンディングボックスの積集合（重なり）の面積", "正解バウンディングボックスの面積のみ", "画像全体の面積"],
    "exp": "IoU = (Area of Overlap) / (Area of Union)。分母は予測と正解の「和集合（Union）」の面積である。"
  },
  {
    "sid": 5,
    "q": "物体検出におけるmAP（mean Average Precision）の説明として正しいものを選べ。",
    "a": ["各クラスごとのAP（Average Precision）を計算し、全クラスで平均したもの", "全ての検出ボックスのIoUを平均したもの", "最も確信度の高いクラスのPrecision", "全てのクラスのRecallの平均値"],
    "exp": "mAPは、クラスごとにPR曲線の下側面積（AP）を計算し、それを全クラスについて平均した指標である。"
  },
  {
    "sid": 5,
    "q": "回帰問題の評価指標において、外れ値の影響を強く受けやすい指標はどれか。",
    "a": ["MSE (Mean Squared Error)", "MAE (Mean Absolute Error)", "R2 (決定係数)", "MSLE (Mean Squared Logarithmic Error)"],
    "exp": "MSEは誤差を二乗して平均するため、誤差が大きい（外れ値）場合、その値が極端に大きくなり、影響を強く受ける。"
  },
  {
    "sid": 5,
    "q": "回帰問題の評価指標であるRMSE（Root Mean Squared Error）の説明として正しいものはどれか。",
    "a": ["MSEの平方根をとったもので、元のデータと同じ単位で評価できる", "誤差の絶対値の平均をとったもの", "予測値と実測値の相関係数の二乗", "対数変換した誤差の二乗平均"],
    "exp": "RMSEはMSEの平方根（Root）であるため、目的変数と同じ単位（スケール）で誤差を解釈できる利点がある。"
  },
  {
    "sid": 5,
    "q": "機械翻訳や文章生成のタスクでよく用いられる評価指標で、生成された文と参照文とのn-gramの一致率に基づくものはどれか。",
    "a": ["BLEU", "ROUGE", "Perplexity", "Inception Score"],
    "exp": "BLEU（Bilingual Evaluation Understudy）は、n-gramの適合率（Precision）を基にした幾何平均に、短すぎる文へのペナルティを加えた指標である。"
  },
  {
    "sid": 5,
    "q": "セマンティックセグメンテーションの評価指標として最も一般的に用いられる、クラスごとのIoUの平均値は何か。",
    "a": ["mIoU (mean Intersection over Union)", "Pixel Accuracy", "Dice Coefficient", "Boundary F1"],
    "exp": "mIoUは、各クラスについてIoUを計算し、その平均をとったもので、セグメンテーションの標準的な評価指標である。"
  },
  {
    "sid": 5,
    "q": "交差検証（Cross Validation）の一つで、データセットをK個に分割し、そのうち1つをテストデータ、残りを学習データとしてK回評価を繰り返す手法はどれか。",
    "a": ["k-分割交差検証 (k-fold Cross Validation)", "ホールドアウト法", "リーブワンアウト交差検証", "層化k-分割交差検証"],
    "exp": "k-分割交差検証は、データをK個のサブセットに分け、全てのデータが1回ずつテストデータになるように検証を行う手法。"
  },
  {
    "sid": 5,
    "q": "分類問題において、交差検証を行う際に、各分割データ内のクラス比率が元のデータ全体の比率と等しくなるように分割する手法はどれか。",
    "a": ["層化k-分割交差検証 (Stratified k-fold)", "グループ付き交差検証 (Group k-fold)", "時系列分割交差検証 (Time Series Split)", "シャッフル分割交差検証"],
    "exp": "Stratified k-foldは、クラスの不均衡がある場合などに、学習・検証セット間でクラス分布が偏らないようにする手法。"
  },
  {
    "sid": 5,
    "q": "機械学習において「次元の呪い」が引き起こす現象として、最も不適切なもの（起こりにくいこと）を選べ。",
    "a": ["データが十分にあれば、次元が増えるほど計算効率が指数関数的に良くなる", "空間が疎になり、データ間の距離が遠くなることでモデルの学習が困難になる", "距離に基づくアルゴリズム（k-近傍法など）の性能が低下する", "必要なデータ量が指数関数的に増加する"],
    "exp": "次元の呪いとは、次元が増加すると空間の体積が急速に増大し、データが疎になる現象などを指す。計算効率が良くなることはなく、むしろ計算量は増大し学習は困難になる。"
  },
  {
    "sid": 5,
    "q": 'データの「標準化（平均0, 分散1）」を行うコードの空欄[ ? ]に入るのは？<br><span style="font-family:monospace; background:#333; padding:2px;">mean = np.mean(x)<br>std = np.std(x)<br>z = [ ? ]</span>',
    "a": ['(x - mean) / std', '(x - mean) / (std ** 2)', '(x - min) / (max - min)', 'x / std'],
    "exp": '標準化（Standardization）は、データから平均を引き、標準偏差で割ることで行います。'
  },

    // --- 6: 評価・正則化・探索 ---
  {
    "sid": 6,
    "q": 'L1正則化(Lasso)の主な特徴は？',
    "a": ['重みが0になりやすい(スパース性)', '重みが一様に小さくなる', '微分可能で計算しやすい', 'L2より過学習しやすい'],
    "exp": '不要な特徴量を削除する効果があります。'
  },
  {
    "sid": 6,
    "q": 'グリッドサーチと比較したランダムサーチの利点は？',
    "a": ['計算コストを抑えつつ良い解が見つかりやすい', '必ず最適解が見つかる', '全通り試すので精度が高い', '実装が簡単'],
    "exp": '重要なパラメータとそうでないパラメータがある場合に効率的です。'
  },
  {
    "sid": 6,
    "q": "混同行列において、実際は正例であるものを、モデルが正例と予測した数を表す指標はどれか。",
    "a": ["TP (True Positive)", "TN (True Negative)", "FP (False Positive)", "FN (False Negative)"],
    "exp": "TP (真陽性) は、正解がPositiveで予測もPositiveだった場合を指します。"
  },
  {
    "sid": 6,
    "q": "適合率(Precision)を求める式として正しいものはどれか。",
    "a": ["TP / (TP + FP)", "TP / (TP + FN)", "(TP + TN) / (TP + FP + FN + TN)", "2TP / (2TP + FP + FN)"],
    "exp": "Precisionは、モデルが正例と予測したもののうち、実際に正例だった割合です。"
  },
  {
    "sid": 6,
    "q": "再現率(Recall)を求める式として正しいものはどれか。",
    "a": ["TP / (TP + FN)", "TP / (TP + FP)", "(TP + TN) / (TP + FP + FN + TN)", "TP / (TP + TN)"],
    "exp": "Recallは、実際に正例であるもののうち、モデルが正例と予測できた割合です。"
  },
  {
    "sid": 6,
    "q": "F値(F1-score)の説明として適切なものはどれか。",
    "a": ["適合率と再現率の調和平均である", "適合率と再現率の算術平均である", "適合率と再現率の幾何平均である", "適合率と正解率の調和平均である"],
    "exp": "F値は適合率と再現率のバランスを見る指標で、調和平均 2PR/(P+R) で計算されます。"
  },
  {
    "sid": 6,
    "q": "ROC曲線において、横軸にとられる指標はどれか。",
    "a": ["FPR (False Positive Rate)", "TPR (True Positive Rate)", "Precision", "Recall"],
    "exp": "ROC曲線は、横軸にFPR（偽陽性率）、縦軸にTPR（真陽性率）をとってプロットします。"
  },
  {
    "sid": 6,
    "q": "モデルが過学習（Overfitting）している状態の説明として最も適切なものはどれか。",
    "a": ["訓練誤差は小さいが、テスト誤差が大きい", "訓練誤差もテスト誤差も大きい", "訓練誤差は大きいが、テスト誤差は小さい", "訓練誤差とテスト誤差が共に小さい"],
    "exp": "過学習は、訓練データに適合しすぎて未知のデータへの汎化性能が低い状態です。"
  },
  {
    "sid": 6,
    "q": "L1正則化（Lasso）の特徴として正しいものはどれか。",
    "a": ["重みの一部を0にしやすく、特徴選択の効果がある", "重みの値を全体的に小さくするが、0にはなりにくい", "重みの二乗和を損失関数に加える", "微分不可能であるため勾配降下法が使えない"],
    "exp": "L1正則化はスパース性を生み出し、不要な特徴量の重みを0にする傾向があります。"
  },
  {
    "sid": 6,
    "q": "L2正則化（Ridge）の正則化項として正しいものはどれか（λは正則化係数、wは重み）。",
    "a": ["λ * Σ(w^2)", "λ * Σ|w|", "λ * Σ(w)", "λ * Σ(log(w))"],
    "exp": "L2正則化は重みの二乗和（L2ノルムの二乗）に係数を掛けたものを損失関数に加えます。"
  },
  {
    "sid": 6,
    "q": "ドロップアウト（Dropout）の説明として正しいものはどれか。",
    "a": ["学習時にランダムにニューロンを無効化して学習する", "テスト時にランダムにニューロンを無効化して推論する", "学習時に重みの値をランダムに0にする", "勾配消失を防ぐために活性化関数を変更する手法"],
    "exp": "ドロップアウトは学習時に確率的にニューロンを不活性化させ、アンサンブル学習のような効果を得る手法です。"
  },
  {
    "sid": 6,
    "q": "ドロップアウトを用いた場合、テスト時（推論時）に行う処理はどれか。",
    "a": ["全てのニューロンを使用し、出力に学習時のドロップ率(1-p)を掛ける", "学習時と同じ確率でニューロンを無効化する", "全てのニューロンを使用し、重みを変更しない", "全てのニューロンを使用し、出力を2倍にする"],
    "exp": "テスト時は全ニューロンを使いますが、学習時と期待値を合わせるため、出力を生存確率倍（または重みをスケーリング）します。"
  },
  {
    "sid": 6,
    "q": "交差検証（Cross Validation）のうち、データをK個に分割し、そのうち1つをテスト用、残りを学習用としてK回評価を行う手法はどれか。",
    "a": ["K-分割交差検証 (K-fold CV)", "ホールドアウト法", "Leave-One-Out交差検証 (LOOCV)", "ストラティファイド抽出法"],
    "exp": "K-fold Cross Validationの定義そのものです。"
  },
  {
    "sid": 6,
    "q": "Leave-One-Out交差検証 (LOOCV) の特徴として正しいものはどれか。",
    "a": ["データ数と同じ回数の学習を行うため計算コストが高い", "データを半分ずつに分けて学習と評価を行う", "ハイパーパラメータの探索には使用できない", "K-分割交差検証よりもバイアスが大きくなる傾向がある"],
    "exp": "LOOCVはデータ数Nに対し、N個のモデルを作成するため計算コストが非常に高くなります。"
  },
  {
    "sid": 6,
    "q": "グリッドサーチ（Grid Search）の説明として正しいものはどれか。",
    "a": ["指定したパラメータの組み合わせを全て試す方法", "パラメータをランダムに選んで試す方法", "ベイズ最適化を用いて効率的にパラメータを探索する方法", "勾配法を用いてパラメータを最適化する方法"],
    "exp": "グリッドサーチは候補となる値を格子状に全通り試す、しらみつぶしの探索手法です。"
  },
  {
    "sid": 6,
    "q": "ランダムサーチ（Random Search）がグリッドサーチより有効とされる主な理由はどれか。",
    "a": ["重要なパラメータが少数である場合、効率よく最適解付近を見つけやすい", "すべての組み合わせを網羅するため確実である", "計算コストが常に低いとは限らない", "局所解に陥りにくいことが保証されている"],
    "exp": "高次元空間において、重要度の低いパラメータを無駄に探索せず、重要なパラメータの多様な値を試せるため効率が良いとされます。"
  },
  {
    "sid": 6,
    "q": "ベイズ最適化（Bayesian Optimization）において、次に探索すべき点を決めるために用いられる関数はどれか。",
    "a": ["獲得関数（Acquisition Function）", "損失関数（Loss Function）", "活性化関数（Activation Function）", "カーネル関数（Kernel Function）"],
    "exp": "ガウス過程などでモデル化した事後分布に基づき、獲得関数（EIなど）を最大化する点を次の探索点とします。"
  },
  {
    "sid": 6,
    "q": "バイアス・バリアンス分解において、「バイアスが高い」状態が示唆するものはどれか。",
    "a": ["モデルが単純すぎて学習不足（Underfitting）である", "モデルが複雑すぎて過学習（Overfitting）している", "データセットにノイズが多い", "特徴量の数が多すぎる"],
    "exp": "高バイアスはモデルの表現力が不足しており、正解との乖離が大きい（未学習）状態を指します。"
  },
  {
    "sid": 6,
    "q": "Early Stopping（早期終了）の実施基準として一般的に用いられるものはどれか。",
    "a": ["検証データの誤差が下がらなくなった（上がり始めた）時点", "訓練データの誤差が0になった時点", "訓練データの誤差が下がらなくなった時点", "一定のエポック数を消化した時点"],
    "exp": "過学習が始まる直前（検証誤差が最小となる点）で学習を止めるのがEarly Stoppingです。"
  },
  {
    "sid": 6,
    "q": "回帰問題の評価指標として用いられないものはどれか。",
    "a": ["Accuracy（正解率）", "MSE（平均二乗誤差）", "RMSE（二乗平均平方根誤差）", "MAE（平均絶対誤差）"],
    "exp": "Accuracyは分類問題の指標であり、連続値を予測する回帰問題では使用しません。"
  },
  {
    "sid": 6,
    "q": "MSE（平均二乗誤差）の特徴として正しいものはどれか。",
    "a": ["外れ値の影響を強く受ける", "外れ値の影響を受けにくい", "誤差の絶対値を用いるため計算が複雑である", "0から1の範囲の値をとる"],
    "exp": "誤差を二乗するため、大きな誤差（外れ値）の影響が極端に大きくなります。"
  },
  {
    "sid": 6,
    "q": "AUC (Area Under the Curve) の値が0.5に近い場合、そのモデルの性能はどう評価できるか。",
    "a": ["ランダムな予測と同程度で性能が低い", "分類性能が非常に高い", "全てを正例と予測している", "全てを負例と予測している"],
    "exp": "ROC曲線のAUCが0.5というのは、対角線（ランダム推測）上に位置することを意味します。"
  },
  {
    "sid": 6,
    "q": "多クラス分類の評価において、クラスごとの指標を計算してから平均を取る方法を何と呼ぶか。",
    "a": ["マクロ平均（Macro Average）", "マイクロ平均（Micro Average）", "加重平均（Weighted Average）", "調和平均（Harmonic Mean）"],
    "exp": "マクロ平均は各クラスの指標を平等に扱って平均します（サンプル数の偏りを考慮しない）。"
  },
  {
    "sid": 6,
    "q": "データ拡張（Data Augmentation）を行う主な目的はどれか。",
    "a": ["過学習を抑制し、汎化性能を向上させる", "学習データのサイズを減らし、計算を高速化する", "特徴量を減らし、モデルを単純化する", "損失関数の計算を簡単にする"],
    "exp": "データを擬似的に増やすことで、バリエーションを持たせ、過学習を防ぐ正則化の効果があります。"
  },
  {
    "sid": 6,
    "q": "バッチ正規化（Batch Normalization）の副次的な効果として正しいものはどれか。",
    "a": ["正則化の効果があり、ドロップアウトの必要性を減らせる", "学習率を小さく設定する必要がある", "初期値への依存度が高まる", "推論時の計算コストが増大する"],
    "exp": "各層の分布を安定させることで学習が加速するほか、ノイズが含まれることで軽い正則化効果も持ちます。"
  },
  {
    "sid": 6,
    "q": "アンサンブル学習のバギング（Bagging）が主に低減させる誤差の成分はどれか。",
    "a": ["バリアンス（Variance）", "バイアス（Bias）", "ノイズ（Noise）", "正則化項"],
    "exp": "バギングは複数のモデルの平均を取ることで、分散（バリアンス）を小さくし過学習を抑える効果があります。"
  },
  {
    "sid": 6,
    "q": "不均衡データ（Imbalanced Data）の評価において、最も信頼性が低い指標はどれか。",
    "a": ["Accuracy（正解率）", "Precision（適合率）", "Recall（再現率）", "F1-score"],
    "exp": "正例が極端に少ない場合、全て負例と予測するだけでAccuracyは高くなるため、性能評価として不適切です。"
  },
  {
    "sid": 6,
    "q": "正則化項を加えた損失関数 J(w) = E(w) + λR(w) において、λを大きくしすぎた場合に起こる現象はどれか。",
    "a": ["Underfitting（未学習）", "Overfitting（過学習）", "勾配消失", "局所解への収束"],
    "exp": "正則化のペナルティが強すぎると、重みが0に近づきすぎてモデルが単純になりすぎ、未学習を引き起こします。"
  },
  {
    "sid": 6,
    "q": "IoU (Intersection over Union) が主に使用されるタスクはどれか。",
    "a": ["物体検出（Object Detection）", "画像分類（Image Classification）", "自然言語処理（NLP）", "音声認識（Speech Recognition）"],
    "exp": "IoUは予測したバウンディングボックスと正解領域の重なり具合を評価する指標です。"
  },
  {
    "sid": 6,
    "q": "ホールドアウト法において、学習データ、検証データ、テストデータの一般的な使い分けとして正しいものはどれか。",
    "a": ["学習データでモデル更新、検証データでハイパーパラメータ調整、テストデータで最終性能評価", "学習データでハイパーパラメータ調整、検証データでモデル更新、テストデータで最終性能評価", "学習データでモデル更新、検証データとテストデータは同じものを使用", "学習データと検証データでモデル更新、テストデータでハイパーパラメータ調整"],
    "exp": "検証データ(Validation data)は学習中のモデル選択やパラメータ調整に使い、テストデータは最終評価のみに使います。"
  },
  {
    "sid": 6,
    "q": "スパースモデリングに関連が深い正則化手法はどれか。",
    "a": ["L1正則化", "L2正則化", "ドロップアウト", "バッチ正規化"],
    "exp": "スパース性（多くの要素が0になる性質）をもたらすのはL1正則化（Lasso）です。"
  },
  {
    "sid": 6,
    "q": "学習曲線（Learning Curve）において、訓練スコアが高く、検証スコアが低いまま乖離しているグラフが示す状態はどれか。",
    "a": ["過学習（Overfitting）", "未学習（Underfitting）", "適切な学習状態", "データ不足"],
    "exp": "訓練データには適応できているが検証データには適応できていない、典型的な過学習のグラフです。"
  },
  {
    "sid": 6,
    "q": 'Dropoutの実装において、学習時にニューロンを無効化するマスク(mask)を作成する正しいコードは？（dropout_ratio=0.5）<br><span style="font-family:monospace; background:#333; padding:2px;">mask = np.random.rand(*x.shape) > [ ? ]</span>',
    "a": ['dropout_ratio', '1 - dropout_ratio', '0.5', '1.0'],
    "exp": 'ランダム生成した値が「dropout_ratio」より大きい場合をTrue（通過）、小さい場合をFalse（遮断）とします。'
  },

    // --- 7: 教師ありアルゴリズム ---
  {
    "sid": 7,
    "q": 'ランダムフォレストが利用している手法は？',
    "a": ['バギング', 'ブースティング', 'スタッキング', 'クラスタリング'],
    "exp": 'ブートストラップサンプリングと決定木を組み合わせます。'
  },
  { 
    "sid": 7,
    "q": 'サポートベクターマシン(SVM)が最大化するものは？',
    "a": ['マージン', '正解率', '特徴量の数', 'サポートベクターの数'],
    "exp": '決定境界とデータの距離（マージン）を最大化します。'
  },
  {
    "sid": 7,
    "q": "線形回帰モデルにおいて、L1正則化項を加えたものを何と呼ぶか。",
    "a": ["Lasso回帰","Ridge回帰","Elastic Net","ロジスティック回帰"],
    "exp": "L1正則化を用いるのはLasso回帰です。不要な特徴量の係数を0にする性質があり、変数選択の効果があります。"
  },
  {
    "sid": 7,
    "q": "線形回帰モデルにおいて、L2正則化項を加えたものを何と呼ぶか。",
    "a": ["Ridge回帰","Lasso回帰","サポートベクターマシン","決定木"],
    "exp": "L2正則化を用いるのはRidge回帰です。係数の大きさを抑え、過学習を防ぐ効果がありますが、係数を完全に0にはしません。"
  },
  {
    "sid": 7,
    "q": "ロジスティック回帰で使用される活性化関数で、出力を0から1の範囲に収めるものはどれか。",
    "a": ["シグモイド関数","ReLU関数","tanh関数","恒等写像"],
    "exp": "ロジスティック回帰では、線形結合の結果をシグモイド関数に入力し、確率として解釈可能な0〜1の値を得ます。"
  },
  {
    "sid": 7,
    "q": "サポートベクターマシン（SVM）において、識別境界と最も近いデータ点との距離を最大化する考え方を何と呼ぶか。",
    "a": ["マージン最大化","尤度最大化","エントロピー最大化","分散最大化"],
    "exp": "SVMは、クラス間のマージン（境界と最も近いデータ点＝サポートベクターとの距離）を最大化するように境界を決定します。"
  },
  {
    "sid": 7,
    "q": "SVMにおいて、線形分離不可能なデータを高次元空間に写像して線形分離可能にする手法を何と呼ぶか。",
    "a": ["カーネルトリック","バギング","ブースティング","スタッキング"],
    "exp": "カーネルトリック（カーネル法）を用いることで、高次元への写像を明示的に計算することなく、非線形な識別境界を構築できます。"
  },
  {
    "sid": 7,
    "q": "決定木の分割基準として用いられる「ジニ不純度」に関する説明として正しいものはどれか。",
    "a": ["クラスの混ざり具合を表す指標で、値が小さいほど純度が高い","値が大きいほど純度が高い","常に0から無限大の値をとる","回帰木でのみ使用される指標である"],
    "exp": "ジニ不純度は不純度（混ざり具合）を表し、0に近いほど一つのクラスにデータが偏っている（純度が高い）ことを示します。"
  },
  {
    "sid": 7,
    "q": "ランダムフォレストの特徴として最も適切なものはどれか。",
    "a": ["バギングと特徴量のランダム選択を組み合わせている","前のモデルの誤りを次のモデルが修正するブースティングを用いている","単一の深い決定木を作成し、過学習を防ぐ","全データと全特徴量を常に使用して決定木を作る"],
    "exp": "ランダムフォレストは、ブートストラップサンプリング（バギング）に加え、ノード分割時に特徴量をランダムに選択することで多様性を確保します。"
  },
  {
    "sid": 7,
    "q": "k-近傍法（k-NN）において、kの値を小さくしすぎた場合（例: k=1）に発生しやすい問題はどれか。",
    "a": ["過学習（ノイズに敏感になる）","学習不足（未学習）","計算量が指数関数的に増大する","決定境界が直線になる"],
    "exp": "kが小さいと近傍の少数のデータ（ノイズ含む）に強く影響されるため、決定境界が複雑になり過学習しやすくなります。"
  },
  {
    "sid": 7,
    "q": "k-近傍法（k-NN）について正しい説明はどれか。",
    "a": ["怠惰学習（Lazy Learning）の一種であり、学習フェーズでモデル構築を行わない","学習フェーズでパラメータを最適化するため、推論が非常に高速である","線形モデルの一種である","教師なし学習のアルゴリズムである"],
    "exp": "k-NNは学習データを単に保持し、推論時に距離計算を行うため、明示的な学習フェーズがない怠惰学習に分類されます。"
  },
  {
    "sid": 7,
    "q": "単純ベイズ（Naive Bayes）分類器が前提としている「単純」な仮定とは何か。",
    "a": ["特徴量同士が互いに独立である","データが正規分布に従う","クラス間の境界が線形である","全ての特徴量が2値である"],
    "exp": "Naive Bayesは、目的変数が与えられた下で、各特徴量が互いに条件付き独立であるという強い仮定を置いています。"
  },
  {
    "sid": 7,
    "q": "アンサンブル学習において、複数のモデルを並列に学習させ、その結果を平均（または多数決）する手法はどれか。",
    "a": ["バギング","ブースティング","スタッキング","プルーニング"],
    "exp": "バギング（Bagging）は、ブートストラップサンプリングで作成した複数のデータセットで並列にモデルを学習させ、分散を低減させます。"
  },
  {
    "sid": 7,
    "q": "勾配ブースティング決定木（GBDT）の説明として正しいものはどれか。",
    "a": ["前の決定木の予測残差（誤差）を次の決定木が学習する","複数の決定木を独立に並列学習させる","決定木ではなくSVMを弱学習器として用いる","ランダムフォレストと同じアルゴリズムである"],
    "exp": "GBDTなどのブースティング手法は、前のモデルがうまく予測できなかった残差を次のモデルが学習することで精度を高めます。"
  },
  {
    "sid": 7,
    "q": "二値分類の評価指標において、「正解データがPositiveであるもののうち、正しくPositiveと予測できた割合」を何と呼ぶか。",
    "a": ["再現率（Recall）","適合率（Precision）","正解率（Accuracy）","F値（F-measure）"],
    "exp": "再現率（Recall）は、実際にPositiveなもの全体の中で、どれだけ漏れなくPositiveとして検出できたかを示します。"
  },
  {
    "sid": 7,
    "q": "適合率（Precision）と再現率（Recall）の調和平均で計算される指標はどれか。",
    "a": ["F値（F1スコア）","Accuracy","AUC","LogLoss"],
    "exp": "F値はPrecisionとRecallのトレードオフを考慮した総合的な指標で、両者の調和平均で求められます。"
  },
  {
    "sid": 7,
    "q": "ROC曲線の横軸と縦軸の組み合わせとして正しいものはどれか。",
    "a": ["横軸：偽陽性率（FPR）、縦軸：真陽性率（TPR）","横軸：適合率、縦軸：再現率","横軸：閾値、縦軸：正解率","横軸：真陽性率（TPR）、縦軸：偽陽性率（FPR）"],
    "exp": "ROC曲線は、閾値を変化させたときのFPR（1-特異度）を横軸、TPR（再現率）を縦軸にプロットしたものです。"
  },
  {
    "sid": 7,
    "q": "LightGBMの特徴的な決定木の成長手法（探索手法）はどれか。",
    "a": ["Leaf-wise（葉ごとの分割）","Level-wise（深さごとの分割）","Depth-first（深さ優先）","Breadth-first（幅優先）"],
    "exp": "LightGBMはLeaf-wiseを採用しており、損失が最も減少する葉を選んで分割するため、XGBoost等のLevel-wiseより収束が早いです。"
  },
  {
    "sid": 7,
    "q": "XGBoostの特徴として、正則化項が目的関数に含まれていることが挙げられるが、これにより何が期待できるか。",
    "a": [
      "過学習の抑制",
      "学習速度の向上",
      "欠損値の自動補完",
      "メモリ使用量の削減"
    ],
    "exp": "XGBoostは目的関数にモデルの複雑さに対するペナルティ（正則化項）を含んでおり、過学習を防ぐ効果があります。"
  },
  {
    "sid": 7,
    "q": "不均衡データ（Imbalanced Data）を扱う際のアプローチとして、一般的に不適切なものはどれか。",
    "a": ["評価指標として正解率（Accuracy）のみを使用する","ダウンサンプリングを行う","アップサンプリング（SMOTE等）を行う","クラス重み（class_weight）を調整する"],
    "exp": "不均衡データでは、多数派クラスを全て予測するだけで高い正解率が出るため、Accuracyのみでの評価は不適切です。"
  },
  {
    "sid": 7,
    "q": "決定木において、過学習を防ぐために木の成長を途中で止める操作を何と呼ぶか。",
    "a": ["剪定（Pruning）","正規化","ドロップアウト","プーリング"],
    "exp": "剪定（Pruning）には、学習中に停止する事前剪定と、学習後に不要な枝を刈る事後剪定があります。"
  },
  {
    "sid": 7,
    "q": "混同行列（Confusion Matrix）において、実際はNegativeだが、誤ってPositiveと予測してしまったケースを何と呼ぶか。",
    "a": ["FP（False Positive）","FN（False Negative）","TP（True Positive）","TN（True Negative）"],
    "exp": "False Positive（偽陽性）は、実際は負例なのに正例と誤って（False）予測（Positive）したことを指します。"
  },
  {
    "sid": 7,
    "q": "回帰問題の評価指標として用いられるRMSEの説明として正しいものはどれか。",
    "a": ["二乗誤差の平均の平方根をとったもので、外れ値の影響を大きく受ける","絶対値誤差の平均であり、外れ値の影響を受けにくい","決定係数と同じ値になる","0から1の範囲に収まる確率値である"],
    "exp": "RMSE（二乗平均平方根誤差）は誤差を二乗するため、大きな誤差（外れ値）の影響を強く受けます。"
  },
  {
    "sid": 7,
    "q": "スタッキング（Stacking）の説明として正しいものはどれか。",
    "a": ["複数のモデルの予測値を入力として、最終的な予測を行う別のモデル（メタモデル）を学習させる","学習データをランダムに分割し、それぞれのデータで同じモデルを学習させる","前のモデルの残差を次のモデルが学習する","特徴量をランダムに選択して複数の決定木を作成する"],
    "exp": "スタッキングは2段階以上の構成を持ち、1段目のモデル群の出力を2段目のメタモデルの入力として学習させます。"
  },
  {
    "sid": 7,
    "q": "ロジスティック回帰の損失関数として用いられるものはどれか。",
    "a": ["交差エントロピー誤差（Log Loss）","平均二乗誤差（MSE）","ヒンジ損失","ジニ不純度"],
    "exp": "ロジスティック回帰では、尤度最大化に基づいて導出される交差エントロピー誤差（対数損失）を最小化します。"
  },
  {
    "sid": 7,
    "q": "ハードマージンSVMとソフトマージンSVMの違いは何か。",
    "a": ["誤分類を許容するかどうか","カーネル関数を使用するかどうか","回帰に使用できるかどうか","多クラス分類が可能かどうか"],
    "exp": "ハードマージンは誤分類を一切許しませんが、ソフトマージンはスラック変数を導入し、一定の誤分類を許容してマージンを決定します。"
  },
  {
    "sid": 7,
    "q": "k-NNにおける「次元の呪い」の影響として正しいものはどれか。",
    "a": ["次元が増えるとデータ間の距離の差がなくなり、近傍の探索が困難になる","次元が増えると計算量が減少し、精度が向上する","次元が増えると特徴量の重要度が均一になる","次元が増えると常に過学習が抑制される"],
    "exp": "高次元空間ではデータが疎になり、どの点も等しく遠くなるため、距離に基づく手法（k-NN等）の性能が低下します。"
  },
  {
    "sid": 7,
    "q": "多クラス分類において、One-vs-Rest（OvR）法とはどのような手法か。",
    "a": ["ある1つのクラスとそれ以外の全クラスを分ける分類器を、クラス数分だけ作成する","全てのペアの組み合わせについて分類器を作成し、多数決をとる","多クラスを一度に分類できる単一のニューラルネットワークを作成する","クラスを階層的に分割していく"],
    "exp": "One-vs-Restは「クラスA vs その他」「クラスB vs その他」のように、クラス数分の2値分類器を作る手法です。"
  },
  {
    "sid": 7,
    "q": "ランダムフォレストにおけるOOB（Out-of-Bag）エラーとは何か。",
    "a": ["ブートストラップサンプリングで選ばれなかったデータを用いて計算した評価誤差","学習データ全体に対するトレーニング誤差","テストデータに対する予測誤差","決定木の剪定によって発生する誤差"],
    "exp": "バギングでは約36.8%のデータが使用されずに残ります（OOB）。これらを検証用データとして使うことで、交差検証なしで汎化性能を推定できます。"
  },
  {
    "sid": 7,
    "q": "決定係数（R^2）の最大値はいくつか。",
    "a": ["1","0","無限大","100"],
    "exp": "決定係数は予測が観測値と完全に一致する場合に最大値1をとります。当て推量より悪い場合は負になることもあります。"
  },
  {
    "sid": 7,
    "q": "グリッドサーチ（Grid Search）の説明として正しいものはどれか。",
    "a": ["指定されたハイパーパラメータの全ての組み合わせを試行して最適解を探す","ハイパーパラメータをランダムに選択して試行する","ベイズ最適化を用いて効率的にパラメータを探索する","勾配降下法を用いてハイパーパラメータを最適化する"],
    "exp": "グリッドサーチは、候補となるパラメータ値をあらかじめ設定し、その全ての組み合わせをしらみつぶしに探索する手法です。"
  },
  {
    "sid": 7,
    "q": "バイアスとバリアンスのトレードオフにおいて、モデルが複雑すぎる（過学習している）状態はどのように表現されるか。",
    "a": ["低バイアス・高バリアンス","高バイアス・低バリアンス","低バイアス・低バリアンス","高バイアス・高バリアンス"],
    "exp": "複雑なモデルは学習データによく適合するためバイアスは低いですが、データの変動に過敏になるためバリアンス（分散）が高くなります。"
  },

    // --- 8: 教師なしアルゴリズム ---
  {
    "sid": 8,
    "q": 'k-means法の「k」とは何？',
    "a": ['クラスタ数', '次元数', 'データ数', '繰り返し回数'],
    "exp": 'あらかじめいくつのグループに分けるか決める必要があります。'
  },
  {
    "sid": 8,
    "q": '主成分分析(PCA)の目的は？',
    "a": ['次元削減', 'クラスタリング', '教師あり分類', '回帰分析'],
    "exp": '分散が最大になる方向を探し、データを低次元に圧縮します。'
  },
  {
    "sid": 8,
    "q": "k-means法における「クラスタ重心の初期値依存」の問題を軽減するために提案された手法はどれか。",
    "a": [
      "k-means++",
      "k-medoids",
      "Mini-batch k-means",
      "X-means"
    ],
    "exp": "k-means++は、初期のクラスタ中心を互いに離れた位置に確率的に選ぶことで、初期値依存の問題を改善し、収束を早める手法です。"
  },
  {
    "sid": 8,
    "q": "主成分分析（PCA）において、第一主成分が最大化しようとする統計量はどれか。",
    "a": [
      "データの分散",
      "データ間の共分散",
      "特徴量間の相関係数",
      "クラスタ間の距離"
    ],
    "exp": "PCAは、データを射影した後の「分散」が最大になるような軸（主成分）を探索する次元削減手法です。"
  },
  {
    "sid": 8,
    "q": "階層的クラスタリングの「ウォード法」において、クラスタを併合する際に最小化する指標はどれか。",
    "a": [
      "クラスタ内の偏差平方和の増加量",
      "クラスタ重心間のユークリッド距離",
      "クラスタ内の最遠点間距離",
      "クラスタ間の最短距離"
    ],
    "exp": "ウォード法は、クラスタ併合時の「クラスタ内偏差平方和（SSE）」の増加量が最小になるペアを選んで併合する方法です。"
  },
  {
    "sid": 8,
    "q": "t-SNE（t-Distributed Stochastic Neighbor Embedding）の主な用途として最も適切なものはどれか。",
    "a": [
      "高次元データの可視化",
      "データのクラスタリング",
      "欠損値の補完",
      "教師あり学習の分類器"
    ],
    "exp": "t-SNEは高次元空間におけるデータ間の局所的な構造を保ちながら低次元（主に2次元や3次元）に圧縮することに優れており、可視化によく用いられます。"
  },
  {
    "sid": 8,
    "q": "混合ガウスモデル（GMM）のパラメータ推定に一般的に用いられるアルゴリズムはどれか。",
    "a": [
      "EMアルゴリズム",
      "誤差逆伝播法",
      "勾配降下法",
      "最小二乗法"
    ],
    "exp": "GMMは潜在変数を持つ確率モデルであり、その尤度最大化にはEステップ（期待値計算）とMステップ（最大化）を繰り返すEMアルゴリズムが用いられます。"
  },
  {
    "sid": 8,
    "q": "k-means法の最適なクラスタ数$k$を決定するためのヒューリスティックな手法として、クラスタ数ごとのSSE（残差平方和）をプロットし、傾きが急変する点を探す方法を何と呼ぶか。",
    "a": [
      "エルボー法",
      "シルエット法",
      "グリッドサーチ",
      "交差検証法"
    ],
    "exp": "エルボー法は、クラスタ数を増やした際のSSEの減少率が鈍化する点（肘のように見える点）を最適なクラスタ数とする手法です。"
  },
  {
    "sid": 8,
    "q": "PCAを行う前の前処理として、各特徴量の平均を0、分散を1に揃える操作を何と呼ぶか。",
    "a": [
      "標準化",
      "正規化",
      "白色化",
      "正則化"
    ],
    "exp": "特徴量間のスケールが異なると分散の計算に影響するため、PCAの前には一般的に平均0、分散1にする「標準化（Standardization）」を行います。"
  },
  {
    "sid": 8,
    "q": "オートエンコーダにおいて、入力層の次元数よりも隠れ層（中間層）の次元数を小さくすることで、データの特徴的な情報を抽出する構造を何と呼ぶか。",
    "a": [
      "ボトルネック",
      "スキップ接続",
      "ドロップアウト",
      "プーリング"
    ],
    "exp": "入力より次元の低い中間層を設けることで情報の「ボトルネック」を作り、データを圧縮・復元する過程で重要な特徴を獲得させます。"
  },
  {
    "sid": 8,
    "q": "主成分分析（PCA）における「寄与率」の説明として正しいものはどれか。",
    "a": [
      "ある主成分がデータ全体の分散のどれだけを説明しているかの割合",
      "ある主成分と元の特徴量との相関係数",
      "全主成分の固有値の積に対する各固有値の割合",
      "次元削減によって失われた情報量の割合"
    ],
    "exp": "寄与率は、第$m$主成分の分散（固有値）が全分散（全固有値の和）に対して占める割合を示します。"
  },
  {
    "sid": 8,
    "q": "入力データにノイズを付加してからオートエンコーダに入力し、元のノイズのないデータを復元させることでロバストな特徴学習を行う手法はどれか。",
    "a": [
      "Denoising Autoencoder",
      "Sparse Autoencoder",
      "Variational Autoencoder",
      "Contractive Autoencoder"
    ],
    "exp": "Denoising Autoencoder（DAE）は、入力に意図的にノイズを加え、出力で元のクリーンなデータを復元するように学習させる手法です。"
  },
  {
    "sid": 8,
    "q": "k-means法と混合ガウスモデル（GMM）の違いに関する記述として正しいものはどれか。",
    "a": [
      "k-meansはハードクラスタリングだが、GMMはソフトクラスタリングが可能である",
      "k-meansは確率モデルだが、GMMは距離ベースのモデルである",
      "k-meansは計算コストが高いが、GMMは非常に高速である",
      "k-meansは非凸形状のクラスタに対応できるが、GMMは対応できない"
    ],
    "exp": "k-meansは各データが1つのクラスタにのみ属するハードクラスタリングですが、GMMは各クラスタへの所属確率を持つソフトクラスタリングを行います。"
  },
  {
    "sid": 8,
    "q": "PCAにおける「白色化（Whitening）」の処理内容として正しいものはどれか。",
    "a": [
      "特徴量間の無相関化を行い、さらに分散を1に揃える",
      "特徴量の最大値を1、最小値を0にする",
      "データ全体の平均を引くだけの処理",
      "共分散行列の対角成分を0にする"
    ],
    "exp": "白色化は、データを無相関化した上で、各成分の分散が1になるようにスケーリングする処理です。"
  },
  {
    "sid": 8,
    "q": "t-SNEにおいて、確率分布の広がりを調整するハイパーパラメータであり、近傍点の数に影響を与えるものはどれか。",
    "a": [
      "Perplexity",
      "Learning rate",
      "Early exaggeration",
      "Iteration"
    ],
    "exp": "Perplexity（パープレキシティ）は、各データ点において局所的な構造と見なす近傍点の有効数に関連するパラメータです。"
  },
  {
    "sid": 8,
    "q": "特異値分解（SVD）において、行列$A$を$U \\Sigma V^T$と分解したとき、$\\Sigma$はどのような行列か。",
    "a": [
      "特異値を対角成分に持つ対角行列",
      "正定値対称行列",
      "直交行列",
      "単位行列"
    ],
    "exp": "SVDにおける$\\Sigma$は、特異値（非負の実数）を対角成分に並べた対角行列（またはそれに準ずる形状）です。"
  },
  {
    "sid": 8,
    "q": "階層的クラスタリングの結果を樹形図として可視化したものを何と呼ぶか。",
    "a": [
      "デンドログラム",
      "ヒストグラム",
      "スキャッタープロット",
      "ヒートマップ"
    ],
    "exp": "デンドログラムは、クラスタがどのような順序で結合されていったか（または分割されたか）を階層的に示す樹形図です。"
  },
  {
    "sid": 8,
    "q": "変分オートエンコーダ（VAE）において、潜在変数の確率分布を学習可能にするために用いられるテクニックはどれか。",
    "a": [
      "Reparameterization Trick",
      "Batch Normalization",
      "Kernel Trick",
      "Gradient Clipping"
    ],
    "exp": "VAEでは、確率的なサンプリング操作を含むネットワークで誤差逆伝播を可能にするため、乱数項を分離するReparameterization Trickを用います。"
  },
  {
    "sid": 8,
    "q": "教師なし学習における「次元の呪い」の影響として、最も不適切な記述はどれか。",
    "a": [
      "次元が増えるとデータ間の距離の差がなくなり、近傍の概念が意味をなさなくなる",
      "必要なデータ数が指数関数的に増加する",
      "空間が疎になり、過学習のリスクが高まる",
      "次元が増えるほど計算量が減少し、収束が早くなる"
    ],
    "exp": "次元の呪いは計算量やデータ量の増大、距離の無意味化などの悪影響を指す言葉であり、計算量が減少することはありません。"
  },
  {
    "sid": 8,
    "q": "クラスタリングの評価指標の一つで、クラスタ内の凝集度とクラスタ間の乖離度をもとに算出され、-1から1の値をとるものはどれか。",
    "a": [
      "シルエット係数",
      "純度 (Purity)",
      "F値 (F-measure)",
      "ランド指数 (Rand Index)"
    ],
    "exp": "シルエット係数は、データ点が自身のクラスタにどれだけ近く、隣接クラスタからどれだけ離れているかを評価する指標です。"
  },
  {
    "sid": 8,
    "q": "PCAは、データの分散共分散行列の何計算に帰着できるか。",
    "a": [
      "固有値分解",
      "LU分解",
      "QR分解",
      "コレスキー分解"
    ],
    "exp": "PCAの主成分は、分散共分散行列の固有ベクトルに対応しており、固有値分解によって求めることができます。"
  },
  {
    "sid": 8,
    "q": "自己組織化マップ（SOM）の特徴として正しいものはどれか。",
    "a": [
      "高次元データを低次元（通常2次元）のマップ上に配置し、位相関係を保つ",
      "教師あり学習の一種であり、正解ラベルが必要である",
      "層を深くすることでディープラーニングとして扱われる",
      "確率モデルに基づき、EMアルゴリズムで学習する"
    ],
    "exp": "SOMは、入力データの位相的な関係（近さ）を保ったまま、競合学習によって低次元グリッド上に写像する教師なし学習手法です。"
  },
  {
    "sid": 8,
    "q": "GAN（敵対的生成ネットワーク）を構成する2つのネットワークはGeneratorと何か。",
    "a": [
      "Discriminator",
      "Encoder",
      "Decoder",
      "Estimator"
    ],
    "exp": "GANは、偽データを生成するGeneratorと、それが本物か偽物かを識別するDiscriminatorの2つを競わせることで学習します。"
  },
  {
    "sid": 8,
    "q": "階層的クラスタリングにおいて、クラスタ間の距離を「各クラスタに含まれる全データ点間の距離の平均」と定義する方法はどれか。",
    "a": [
      "群平均法",
      "最短距離法",
      "最長距離法",
      "ウォード法"
    ],
    "exp": "群平均法は、2つのクラスタに属するすべてのデータペアの距離の平均をクラスタ間距離とする手法です。"
  },
  {
    "sid": 8,
    "q": "k-means法が苦手とするデータの分布形状はどれか。",
    "a": [
      "三日月型のような非凸形状",
      "球状の分布",
      "各クラスタのサイズが均一な分布",
      "クラスタ同士が十分に離れている分布"
    ],
    "exp": "k-meansは重心からのユークリッド距離に基づくため、球状のクラスタを前提としており、三日月型のような複雑な非凸形状の分離は苦手です。"
  },
  {
    "sid": 8,
    "q": "LLE (Locally Linear Embedding) の特徴として適切なものはどれか。",
    "a": [
      "各データ点を近傍点の線形結合で表現し、その重みを低次元でも保存しようとする",
      "データ全体の分散が最大になるように射影する",
      "測地線距離（Geodesic distance）を保存するように埋め込む",
      "クラス間分散を最大化し、クラス内分散を最小化する"
    ],
    "exp": "LLEは流体学習の一種で、局所的な線形関係（近傍点による再構成重み）を低次元空間でも維持するように配置する手法です。"
  },
  {
    "sid": 8,
    "q": "Isomapにおいて、データ点間の距離としてユークリッド距離ではなく何を用いるか。",
    "a": [
      "測地線距離",
      "マンハッタン距離",
      "マハラノビス距離",
      "コサイン類似度"
    ],
    "exp": "Isomapは、近傍グラフ上の最短経路長（測地線距離）を用いることで、曲がった多様体（スイスロール等）の構造を捉える手法です。"
  },
  {
    "sid": 8,
    "q": "PCAの第2主成分は、第1主成分に対してどのような幾何学的関係にあるか。",
    "a": [
      "直交している",
      "平行である",
      "45度の角度をなす",
      "無関係である"
    ],
    "exp": "PCAの各主成分軸は互いに直交（無相関）するように選ばれます。"
  },
  {
    "sid": 8,
    "q": "スパースオートエンコーダにおいて、隠れ層の活性化に対してスパース性（多くのニューロンが0を出力する）を強制するために加えられる項は何か。",
    "a": [
      "KLダイバージェンスなどの正則化項",
      "ドロップアウト",
      "バッチ正規化",
      "L2正則化（Weight Decay）"
    ],
    "exp": "スパースオートエンコーダでは、隠れ層の平均活性度を小さく保つため、損失関数にKLダイバージェンスなどのペナルティ項を追加します。"
  },
  {
    "sid": 8,
    "q": "k-means法のアルゴリズムにおける2つのステップとは、「割り当てステップ」と何か。",
    "a": [
      "更新ステップ",
      "評価ステップ",
      "初期化ステップ",
      "削除ステップ"
    ],
    "exp": "k-meansは、各点を最も近い重心に割り当てるステップと、割り当てられた点に基づいて重心を再計算する「更新ステップ」を繰り返します。"
  },
  {
    "sid": 8,
    "q": "VAEの損失関数に含まれる、再構成誤差項ともう一つの項は何か。",
    "a": [
      "潜在変数の分布と事前分布とのKLダイバージェンス",
      "Discriminatorによる識別誤差",
      "L1正則化項",
      "各重みの二乗和"
    ],
    "exp": "VAEの損失関数（変分下界の最大化に対応）は、入力の再構成誤差と、エンコーダの出力分布が標準正規分布に近づくためのKLダイバージェンス項から成ります。"
  },
  {
    "sid": 8,
    "q": "教師なし学習における「協調フィルタリング」は主にどのようなタスクで用いられるか。",
    "a": [
      "レコメンデーション",
      "画像認識",
      "音声合成",
      "時系列予測"
    ],
    "exp": "協調フィルタリングは、ユーザーの過去の行動履歴（購入や評価など）の類似性に基づいて、未知のアイテムを推薦するシステムで広く使われます。"
  },

    // --- 9: 強化学習アルゴリズム ---
  {
    "sid": 9,
    "q": '方策勾配法の特徴は？',
    "a": ['方策を直接パラメータ化して学習する', '行動価値関数Qのみを学習する', 'モデルベースである', '離散行動しか扱えない'],
    "exp": '確率的な方策を直接学習するため、連続値の行動も扱えます。'
  },
  {
    "sid": 9,
    "q": 'Q学習はどのような手法に分類される？',
    "a": ['Off-policy (方策オフ)', 'On-policy (方策オン)', 'モデルベース', '教師あり学習'],
    "exp": '学習する方策と、行動を選択する方策が異なっても学習できます。'
  },
  {
    "sid": 9,
    "q": "強化学習において、エージェントが行動を選択し、その結果として環境から受け取る2つの要素は何か。",
    "a": [
      "状態と報酬",
      "状態と価値",
      "価値と方策",
      "報酬と方策"
    ],
    "exp": "エージェントは行動(Action)を行い、環境から次の状態(State)と報酬(Reward)を受け取ります。"
  },
  {
    "sid": 9,
    "q": "マルコフ決定過程(MDP)を構成する要素に含まれないものはどれか。",
    "a": [
      "学習率",
      "状態集合",
      "行動集合",
      "報酬関数"
    ],
    "exp": "MDPは状態(S)、行動(A)、遷移確率(P)、報酬(R)、割引率(γ)で定義されます。学習率はアルゴリズムのパラメータです。"
  },
  {
    "sid": 9,
    "q": "将来もらえる報酬を現在価値に換算するために使われる $0 \\le \\gamma \\le 1$ のパラメータを何と呼ぶか。",
    "a": [
      "割引率",
      "学習率",
      "探索率",
      "減衰率"
    ],
    "exp": "割引率(discount factor) $\\gamma$ は、将来の報酬をどれだけ重視するかを調整します。"
  },
  {
    "sid": 9,
    "q": "ある状態 $s$ において、方策 $\\pi$ に従ったときに得られる収益の期待値を表す関数はどれか。",
    "a": [
      "状態価値関数 $V^\\pi(s)$",
      "行動価値関数 $Q^\\pi(s, a)$",
      "アドバンテージ関数 $A^\\pi(s, a)$",
      "報酬関数 $R(s, a)$"
    ],
    "exp": "状態 $s$ 自体の価値（期待収益）を表すのが状態価値関数です。"
  },
  {
    "sid": 9,
    "q": "現在の状態 $s$ と価値関数 $V(s)$、次の状態 $s'$ とその価値 $V(s')$ の間に成り立つ再帰的な関係式を何と呼ぶか。",
    "a": [
      "ベルマン方程式",
      "オイラー方程式",
      "シュレディンガー方程式",
      "ロジスティック方程式"
    ],
    "exp": "現在の価値と未来の価値の関係を記述したものをベルマン方程式と呼びます。"
  },
  {
    "sid": 9,
    "q": "エピソードが終了するまで待ってから、得られた実際の収益を使って価値関数を更新する手法はどれか。",
    "a": [
      "モンテカルロ法",
      "TD法",
      "動的計画法",
      "方策勾配法"
    ],
    "exp": "モンテカルロ法はエピソード完了後の実際の収益(リターン)を用いて学習します。"
  },
  {
    "sid": 9,
    "q": "エピソードの終了を待たずに、次のステップの予測値を用いて現在の推定値を更新する手法はどれか。",
    "a": [
      "TD法",
      "モンテカルロ法",
      "遺伝的アルゴリズム",
      "焼きなまし法"
    ],
    "exp": "TD(Temporal Difference)法は、ブートストラップ（推測による推測の更新）を行い、ステップごとに学習可能です。"
  },
  {
    "sid": 9,
    "q": "Q学習(Q-Learning)とSARSAの主な違いとして正しいものはどれか。",
    "a": [
      "Q学習はOff-policy、SARSAはOn-policyである",
      "Q学習はOn-policy、SARSAはOff-policyである",
      "Q学習はモデルベース、SARSAはモデルフリーである",
      "Q学習は連続値行動、SARSAは離散値行動のみ扱える"
    ],
    "exp": "SARSAは実際に行った行動で更新するOn-policy、Q学習は最適な行動を仮定して更新するOff-policyです。"
  },
  {
    "sid": 9,
    "q": "行動選択において、確率 $\\varepsilon$ でランダムに行動し、それ以外は現時点で最適な行動を選ぶ手法はどれか。",
    "a": [
      "$\\varepsilon$-greedy法",
      "UCB方策",
      "ボルツマン方策",
      "ソフトマックス方策"
    ],
    "exp": "探索(Exploration)と活用(Exploitation)のバランスをとる最も基本的な手法の一つです。"
  },
  {
    "sid": 9,
    "q": "DQN(Deep Q-Network)で導入された、経験データをメモリに蓄積し、ランダムに取り出して学習する仕組みは何か。",
    "a": [
      "Experience Replay",
      "Fixed Target Q-Network",
      "Prioritized Experience Replay",
      "Dueling Network"
    ],
    "exp": "データの相関を断ち切り、学習を安定させるためにExperience Replayが導入されました。"
  },
  {
    "sid": 9,
    "q": "DQNにおいて、正解ラベルとなる教師信号を作成するためのネットワークを一定期間固定する手法は何か。",
    "a": [
      "Fixed Target Q-Network",
      "Double DQN",
      "Noisy Network",
      "A3C"
    ],
    "exp": "ターゲットネットワークを固定することで、学習目標が頻繁に変動するのを防ぎます。"
  },
  {
    "sid": 9,
    "q": "Q学習が行動価値を過大評価してしまう傾向を改善するために提案されたDQNの改良版はどれか。",
    "a": [
      "Double DQN",
      "Dueling DQN",
      "Categorical DQN",
      "Rainbow"
    ],
    "exp": "Double DQNは、行動選択と価値評価を行うネットワークを分けることで過大評価を抑制します。"
  },
  {
    "sid": 9,
    "q": "Dueling Networkの構造において、Q関数を構成するために分岐させた2つのストリームは何か。",
    "a": [
      "状態価値関数とアドバンテージ関数",
      "状態価値関数と方策関数",
      "報酬関数と遷移確率",
      "平均値と分散"
    ],
    "exp": "Dueling Networkは $Q(s, a) = V(s) + A(s, a)$ の関係を利用して学習効率を高めます。"
  },
  {
    "sid": 9,
    "q": "Prioritized Experience Replayにおいて、優先的にサンプリングされる経験の特徴は何か。",
    "a": [
      "TD誤差が大きい経験",
      "報酬がプラスの経験",
      "最新の経験",
      "ランダムに選ばれた経験"
    ],
    "exp": "TD誤差（予測誤差）が大きい経験ほど学習にとって重要であると考え、優先的に学習します。"
  },
  {
    "sid": 9,
    "q": "方策勾配法(Policy Gradient)の利点として適切でないものはどれか。",
    "a": [
      "大域的最適解への収束が常に保証される",
      "連続的な行動空間を扱える",
      "確率的な方策を学習できる",
      "価値関数の近似が不要な場合がある"
    ],
    "exp": "方策勾配法は局所的最適解(ローカルミニマム)に陥る可能性があり、大域的最適解の保証はありません。"
  },
  {
    "sid": 9,
    "q": "方策勾配法におけるREINFORCEアルゴリズムは、どの手法に基づいているか。",
    "a": [
      "モンテカルロ法",
      "TD法",
      "動的計画法",
      "モデルベース法"
    ],
    "exp": "REINFORCEはエピソードごとの収益を用いるため、モンテカルロ法ベースの方策勾配法です。"
  },
  {
    "sid": 9,
    "q": "方策勾配法の勾配推定において、分散を減らすために導入される、行動に依存しない関数 $b(s)$ を何と呼ぶか。",
    "a": [
      "ベースライン",
      "バイアス",
      "ペナルティ",
      "ラグランジュ乗数"
    ],
    "exp": "ベースラインを引くことで、勾配の期待値を変えずに分散を低減させることができます。"
  },
  {
    "sid": 9,
    "q": "Actor-Critic手法における「Critic」の役割は何か。",
    "a": [
      "価値関数を学習し、Actorを評価する",
      "方策に従って行動を決定する",
      "環境モデルを構築する",
      "探索パラメータを調整する"
    ],
    "exp": "Actorが行動を決め、Criticがその行動（または状態）の価値を評価してActorの学習を助けます。"
  },
  {
    "sid": 9,
    "q": "A3C (Asynchronous Advantage Actor-Critic) の特徴として正しいものはどれか。",
    "a": [
      "複数のエージェントが非同期に並列学習を行う",
      "一つのエージェントが順番に学習を行う",
      "Experience Replayが必須である",
      "GPU計算が必須でありCPUでは動作しない"
    ],
    "exp": "A3Cは複数のエージェントを非同期で並列動作させ、勾配を共有パラメータに適用する手法です。"
  },
  {
    "sid": 9,
    "q": "行動の不確実性を増やすために、ネットワークの重みにノイズを加えることで探索を促進する手法はどれか。",
    "a": [
      "Noisy Networks",
      "Dropout",
      "Batch Normalization",
      "Reward Clipping"
    ],
    "exp": "Noisy Networksは、ε-greedy法の代わりにパラメータ空間にノイズを加えて探索を行います。"
  },
  {
    "sid": 9,
    "q": "期待値だけでなく、報酬の確率分布そのものを学習しようとする手法はどれか。",
    "a": [
      "Categorical DQN (C51)",
      "Double DQN",
      "Dueling DQN",
      "A3C"
    ],
    "exp": "分布型強化学習(Distributional RL)と呼ばれ、C51などが代表的です。"
  },
  {
    "sid": 9,
    "q": "DQNに対する複数の拡張手法（Double, Dueling, PER, Multi-step, Noisy, C51等）を統合したモデルは何か。",
    "a": [
      "Rainbow",
      "AlphaGo",
      "R2D2",
      "MuZero"
    ],
    "exp": "RainbowはDQNの7つの拡張手法をすべて組み合わせ、高い性能を達成しました。"
  },
  {
    "sid": 9,
    "q": "多腕バンディット問題において、探索の回数が少ないアームの評価値を高く見積もることで探索を促すアルゴリズムはどれか。",
    "a": [
      "UCB1",
      "Softmax",
      "REINFORCE",
      "Q-Learning"
    ],
    "exp": "UCB(Upper Confidence Bound)は、信頼区間の上限を利用して、不確実性の高い行動を探索します。"
  },
  {
    "sid": 9,
    "q": "状態 $s$ において行動 $a$ を取った際のアドバンテージ関数 $A(s, a)$ の定義式はどれか。",
    "a": [
      "$Q(s, a) - V(s)$",
      "$V(s) - Q(s, a)$",
      "$Q(s, a) - R(s)$",
      "$R(s) + \\gamma V(s')$"
    ],
    "exp": "アドバンテージは、その行動が平均的な行動（状態価値）に比べてどれだけ良いかを表します。"
  },
  {
    "sid": 9,
    "q": "環境のダイナミクス（遷移確率や報酬関数）を学習し、それを使って計画(Planning)を行う手法を何と呼ぶか。",
    "a": [
      "モデルベース強化学習",
      "モデルフリー強化学習",
      "模倣学習",
      "逆強化学習"
    ],
    "exp": "環境のモデルを作成・利用するのがモデルベース、直接方策や価値を学ぶのがモデルフリーです。"
  },
  {
    "sid": 9,
    "q": "エキスパート（熟練者）の行動履歴から、その背後にある報酬関数を推定する手法は何か。",
    "a": [
      "逆強化学習",
      "模倣学習",
      "転移学習",
      "メタ学習"
    ],
    "exp": "Inverse Reinforcement Learning (IRL) は、最適な行動から報酬関数を逆推定します。"
  },
  {
    "sid": 9,
    "q": "AlphaGoの探索パートで用いられている、木探索とランダムシミュレーションを組み合わせた手法は何か。",
    "a": [
      "モンテカルロ木探索(MCTS)",
      "深さ優先探索",
      "幅優先探索",
      "A*探索"
    ],
    "exp": "MCTSは、有望な手を重点的にシミュレーションすることで巨大な探索空間を効率的に探索します。"
  },
  {
    "sid": 9,
    "q": "スパース報酬（報酬が稀にしか得られない）環境での学習が難しい問題において、有効な対策の一つはどれか。",
    "a": [
      "報酬シェイピング (Reward Shaping)",
      "学習率を下げる",
      "割引率を0にする",
      "ネットワーク層を減らす"
    ],
    "exp": "ゴールに近づくごとに報酬を与えるなど、補助的な報酬を設計することを報酬シェイピングといいます。"
  },
  {
    "sid": 9,
    "q": "マルチステップ学習（n-step TD）において、TD誤差の計算に用いる報酬の範囲はどれか。",
    "a": [
      "$n$ ステップ先までの割引報酬和と、$n$ ステップ先の価値推定値",
      "1ステップ先の即時報酬のみ",
      "エピソード終了までの全報酬",
      "ランダムに選んだステップの報酬"
    ],
    "exp": "1ステップTDとモンテカルロの中間に位置し、学習の効率とバイアスのバランスを取ります。"
  },
  {
    "sid": 9,
    "q": "DQNでは適用が難しく、Actor-Criticや方策勾配法が適しているタスクの特徴はどれか。",
    "a": [
      "行動空間が連続値である",
      "状態空間が離散値である",
      "報酬が常に正である",
      "エピソードが短い"
    ],
    "exp": "DQNは行動の最大化演算が必要なため、連続行動空間では計算コストが膨大になり不向きです。"
  },

    // --- 10: 深層学習の概要 ---
  {
    "sid": 10,
    "q": '単純パーセプトロンで解けない問題は？',
    "a": ['XOR問題', 'AND問題', 'OR問題', 'NOT問題'],
    "exp": '線形非分離な問題は解けません。'
  },
  {
    "sid": 10,
    "q": '多層パーセプトロンで、表現力を高めるために不可欠なものは？',
    "a": ['非線形な活性化関数', '多くの層', 'バッチ正規化', 'ドロップアウト'],
    "exp": '活性化関数がないと、何層重ねても線形変換のままです。'
  },
  {
    "sid": 10,
    "q": "人工知能（AI）、機械学習（ML）、深層学習（DL）の包含関係として最も適切なものはどれか。",
    "a": [
      "AI ⊃ ML ⊃ DL",
      "AI ⊃ DL ⊃ ML",
      "DL ⊃ ML ⊃ AI",
      "ML ⊃ AI ⊃ DL"
    ],
    "exp": "深層学習は機械学習の一部であり、機械学習は人工知能の一部です。"
  },
  {
    "sid": 10,
    "q": "単純パーセプトロンにおいて、原理的に学習できない問題はどれか。",
    "a": [
      "XOR（排他的論理和）",
      "AND（論理積）",
      "OR（論理和）",
      "NOT（論理否定）"
    ],
    "exp": "単純パーセプトロンは線形分離可能な問題しか解けず、線形分離不可能なXOR問題は解けません（ミンスキーとパパートの指摘）。"
  },
  {
    "sid": 10,
    "q": "多層パーセプトロンにおいて、隠れ層の活性化関数としてシグモイド関数を使用し、層を深くした際に勾配が徐々に小さくなり学習が進まなくなる現象はどれか。",
    "a": [
      "勾配消失問題",
      "勾配爆発問題",
      "過学習",
      "局所解"
    ],
    "exp": "シグモイド関数の微分の最大値は0.25であり、層を重ねるごとに誤差逆伝播される値が小さくなる現象を勾配消失問題と呼びます。"
  },
  {
    "sid": 10,
    "q": "ReLU（Rectified Linear Unit）関数の定義式として正しいものはどれか。",
    "a": [
      "f(x) = max(0, x)",
      "f(x) = 1 / (1 + exp(-x))",
      "f(x) = (exp(x) - exp(-x)) / (exp(x) + exp(-x))",
      "f(x) = x (x > 0), 0.01x (x <= 0)"
    ],
    "exp": "ReLUは入力が0以下の場合は0、0より大きい場合は入力をそのまま出力する関数です。"
  },
  {
    "sid": 10,
    "q": "多クラス分類問題において、出力層で使用され、出力の総和が1になる活性化関数はどれか。",
    "a": [
      "ソフトマックス関数",
      "シグモイド関数",
      "恒等関数",
      "Tanh関数"
    ],
    "exp": "ソフトマックス関数は出力を確率として解釈できるように正規化するため、多クラス分類の出力層に適しています。"
  },
  {
    "sid": 10,
    "q": "回帰問題において、一般的に使用される損失関数はどれか。",
    "a": [
      "平均二乗誤差（MSE）",
      "交差エントロピー誤差",
      "ヒンジ損失",
      "KLダイバージェンス"
    ],
    "exp": "回帰問題では、予測値と実測値の差の二乗平均をとる平均二乗誤差（MSE）が一般的です。"
  },
  {
    "sid": 10,
    "q": "勾配降下法において、全データではなく、ランダムに選んだ1つのデータのみを用いてパラメータを更新する手法はどれか。",
    "a": [
      "確率的勾配降下法（SGD）",
      "ミニバッチ勾配降下法",
      "バッチ勾配降下法",
      "Momentum"
    ],
    "exp": "SGD（Stochastic Gradient Descent）は、厳密にはデータ1つごとに更新を行う手法を指します。"
  },
  {
    "sid": 10,
    "q": "学習係数（学習率）が大きすぎる場合に起こりやすい現象はどれか。",
    "a": [
      "発散",
      "局所解への収束",
      "勾配消失",
      "学習速度の低下"
    ],
    "exp": "学習率が大きすぎると、最適解を飛び越えてしまい、損失関数の値が発散することがあります。"
  },
  {
    "sid": 10,
    "q": "誤差逆伝播法において、連鎖律（チェインルール）を用いて計算するものはどれか。",
    "a": [
      "各パラメータの勾配",
      "順伝播の出力値",
      "損失関数の値",
      "活性化関数の出力"
    ],
    "exp": "誤差逆伝播法は、出力層から入力層に向かって連鎖律を用いて偏微分（勾配）を効率的に計算する手法です。"
  },
  {
    "sid": 10,
    "q": "最適化手法の一つであるMomentumの特徴として正しいものはどれか。",
    "a": [
      "過去の勾配の移動平均（慣性項）を利用して振動を抑制する",
      "学習率をパラメータごとに適応的に変化させる",
      "無限大ノルムを用いて学習率を調整する",
      "二次微分（ヘッセ行列）を利用する"
    ],
    "exp": "Momentumは物理法則の慣性のような項を追加し、過去の勾配方向を維持することで学習を安定・加速させます。"
  },
  {
    "sid": 10,
    "q": "AdaGradの欠点を改善するために、過去の勾配の二乗和を指数移動平均で減衰させる手法はどれか。",
    "a": [
      "RMSprop",
      "SGD",
      "Momentum",
      "Newton法"
    ],
    "exp": "AdaGradは学習が進むにつれ学習率が0に近づきすぎる問題があり、RMSpropは過去の情報を徐々に忘れることでこれを解決しました。"
  },
  {
    "sid": 10,
    "q": "Adam（Adaptive Moment Estimation）の説明として最も適切なものはどれか。",
    "a": [
      "MomentumとRMSpropの利点を組み合わせた手法",
      "学習率を層ごとに固定する手法",
      "勾配の符号のみを利用して更新する手法",
      "正則化項を自動的に調整する手法"
    ],
    "exp": "Adamは、Momentum（勾配の平均）とRMSprop（勾配の二乗平均）の考え方を組み合わせた最適化手法です。"
  },
  {
    "sid": 10,
    "q": "過学習（Overfitting）の兆候として正しいものはどれか。",
    "a": [
      "訓練データの誤差は小さいが、検証データの誤差が大きい",
      "訓練データの誤差も検証データの誤差も大きい",
      "訓練データの誤差が大きく、検証データの誤差が小さい",
      "損失関数が負の値になる"
    ],
    "exp": "過学習は、モデルが訓練データに過剰に適応し、未知のデータ（検証データ）に対する汎化性能が低下した状態です。"
  },
  {
    "sid": 10,
    "q": "ドロップアウト（Dropout）の説明として正しいものはどれか。",
    "a": [
      "学習時にランダムにニューロンを選んで無効化（削除）する",
      "学習時に重みの値をランダムに0にする",
      "推論時にランダムにニューロンを選んで無効化する",
      "学習率をランダムに変化させる"
    ],
    "exp": "ドロップアウトは、学習のたびに異なるニューロンをランダムに無効化することで、アンサンブル学習のような効果を得て過学習を防ぎます。"
  },
  {
    "sid": 10,
    "q": "L2正則化（Weight Decay）において、損失関数に加えられる正則化項はどれか（wは重み、λは正則化係数）。",
    "a": [
      "1/2 * λ * Σ(w^2)",
      "λ * Σ|w|",
      "λ * Σ(w)",
      "1/2 * λ * Σ(w - t)^2"
    ],
    "exp": "L2正則化は重みの二乗ノルム（L2ノルム）を損失関数に加え、大きな重みを持つことにペナルティを与えます。"
  },
  {
    "sid": 10,
    "q": "L1正則化（Lasso）の特徴として正しいものはどれか。",
    "a": [
      "不要なパラメータが0になりやすく、スパースな解が得られる",
      "全てのパラメータが均一に小さくなる",
      "計算時に微分可能であるため扱いやすい",
      "外れ値の影響を強く受けやすい"
    ],
    "exp": "L1正則化は重みの絶対値の和をペナルティとするため、特徴選択の効果（一部の重みが完全に0になる）があります。"
  },
  {
    "sid": 10,
    "q": "Sigmoid関数やTanh関数を活性化関数に用いる際の、重みの初期値として推奨されるものはどれか。",
    "a": [
      "Xavierの初期値（Glorotの初期値）",
      "Heの初期値",
      "全て0で初期化",
      "標準偏差0.01のガウス分布"
    ],
    "exp": "Xavierの初期値は、前層のノード数nに対し、標準偏差が1/√nとなるように設定され、SigmoidやTanhに適しています。"
  },
  {
    "sid": 10,
    "q": "ReLU関数を活性化関数に用いる際の、重みの初期値として推奨されるものはどれか。",
    "a": [
      "Heの初期値",
      "Xavierの初期値",
      "全て1で初期化",
      "一様分布"
    ],
    "exp": "Heの初期値は、前層のノード数nに対し、標準偏差が√(2/n)となるように設定され、ReLUに適しています。"
  },
  {
    "sid": 10,
    "q": "バッチ正規化（Batch Normalization）の効果として適切でないものはどれか。",
    "a": [
      "過学習を促進する",
      "学習速度を向上させる",
      "初期値依存性を低減する",
      "ある程度の正則化効果がある"
    ],
    "exp": "バッチ正規化は過学習を抑制する効果があります（促進はしません）。"
  },
  {
    "sid": 10,
    "q": "Early Stopping（早期終了）を行う条件として正しいものはどれか。",
    "a": [
      "検証データの誤差が下がらなくなった（上がり始めた）時",
      "訓練データの誤差が0になった時",
      "勾配が完全に0になった時",
      "指定したエポック数に達した時"
    ],
    "exp": "Early Stoppingは、過学習が始まる前（検証データの性能が悪化し始めるタイミング）で学習を打ち切る手法です。"
  },
  {
    "sid": 10,
    "q": "データ拡張（Data Augmentation）の主な目的はどれか。",
    "a": [
      "データ数を擬似的に増やし、汎化性能を向上させる",
      "データの前処理時間を短縮する",
      "モデルのパラメータ数を削減する",
      "学習データの欠損値を補完する"
    ],
    "exp": "画像を回転・反転・拡大縮小させるなどしてデータを水増しし、過学習を防ぐためによく用いられます。"
  },
  {
    "sid": 10,
    "q": "勾配爆発（Exploding Gradient）への対策として有効な手法はどれか。",
    "a": [
      "勾配クリッピング（Gradient Clipping）",
      "ReLU関数の使用",
      "学習率を大きくする",
      "モーメンタムの係数を増やす"
    ],
    "exp": "勾配クリッピングは、勾配のノルムがある閾値を超えた場合に、勾配を修正して大きさを制限する手法です。"
  },
  {
    "sid": 10,
    "q": "「任意の連続関数は、隠れ層が1層以上あるニューラルネットワークで近似できる」という定理はどれか。",
    "a": [
      "万能近似定理（Universal Approximation Theorem）",
      "ノーフリーランチ定理",
      "中心極限定理",
      "ベイズの定理"
    ],
    "exp": "万能近似定理は、十分な数のニューロンがあれば、2層（入力+隠れ+出力）のNNで任意の関数を表現できることを示しています。"
  },
  {
    "sid": 10,
    "q": "1エポック（Epoch）の意味として正しいものはどれか。",
    "a": [
      "訓練データセット全体を1回学習すること",
      "ミニバッチを1回更新すること",
      "検証データでの評価を1回行うこと",
      "学習が完全に収束すること"
    ],
    "exp": "1エポックは、用意した訓練データをすべて一通り学習に使用した区切りを指します。"
  },
  {
    "sid": 10,
    "q": "実装した誤差逆伝播法が正しいかを確かめるために、微小な差分を用いて近似的に勾配を求める手法はどれか。",
    "a": [
      "数値微分（勾配確認 / Gradient Checking）",
      "自動微分",
      "記号微分",
      "積分法"
    ],
    "exp": "数値微分は計算コストが高いですが実装が容易なため、複雑な誤差逆伝播法の実装ミスを確認するために使用されます。"
  },
  {
    "sid": 10,
    "q": "2値分類問題において、出力層がシグモイド関数の場合、対応する損失関数はどれか。",
    "a": [
      "バイナリ交差エントロピー誤差",
      "カテゴリカル交差エントロピー誤差",
      "平均絶対誤差（MAE）",
      "二乗和誤差"
    ],
    "exp": "2値分類（0か1か）には、バイナリ交差エントロピー（Binary Cross Entropy）が使用されます。"
  },
  {
    "sid": 10,
    "q": "ディープラーニングにおける「ハイパーパラメータ」に該当しないものはどれか。",
    "a": [
      "重みとバイアス",
      "学習率",
      "バッチサイズ",
      "隠れ層のニューロン数"
    ],
    "exp": "重みとバイアスは学習によって更新される「パラメータ」であり、人が設定する「ハイパーパラメータ」ではありません。"
  },
  {
    "sid": 10,
    "q": "ノーフリーランチ定理（No Free Lunch Theorem）の意味するところはどれか。",
    "a": [
      "あらゆる問題において他よりも優れた万能なアルゴリズムは存在しない",
      "データ量が増えれば必ず性能が向上する",
      "学習には計算コストという対価が必ず必要である",
      "層を深くすればするほど表現力は高まる"
    ],
    "exp": "特定の問題に特化したアルゴリズムは作れるが、全ての問題で常に勝てるアルゴリズムはないという定理です。"
  },
  {
    "sid": 10,
    "q": "RNN（リカレントニューラルネットワーク）などで、時間を遡って誤差を伝播させる手法はどれか。",
    "a": [
      "BPTT (Backpropagation Through Time)",
      "CNN (Convolutional Neural Network)",
      "LSTM (Long Short-Term Memory)",
      "Dropout"
    ],
    "exp": "BPTTは、時系列データを扱うRNNにおいて、時間方向に展開したネットワーク上で誤差逆伝播を行う手法です。"
  },
  {
    "sid": 10,
    "q": "アンサンブル学習の一種で、複数のモデルの予測値の平均をとる等の方法で最終的な出力を決定することを何と呼ぶか。",
    "a": [
      "モデル平均（Model Averaging）",
      "バッチ正規化",
      "蒸留（Distillation）",
      "転移学習"
    ],
    "exp": "同じ問題に対して複数の異なるモデルを学習させ、その平均をとることで汎化性能を高める手法です。"
  },
  {
    "sid": 10,
    "q": 'ReLU関数の実装として正しいものは？<br><span style="font-family:monospace; background:#333; padding:2px;">def relu(x):<br>    return [ ? ]</span>',
    "a": ['np.maximum(0, x)', 'np.minimum(0, x)', 'x if x > 0 else 1', 'np.max(0, x)'],
    "exp": 'ReLUは入力が0以下の場合は0、正の場合はそのまま出力するため、np.maximum(0, x) を使います。'
  },
  {
    "sid": 10,
    "q": 'Softmax関数の実装で、オーバーフローを防ぐための一般的な対策は？<br><span style="font-family:monospace; background:#333; padding:2px;">def softmax(x):<br>    c = [ ? ]<br>    exp_x = np.exp(x - c)<br>    return exp_x / np.sum(exp_x)</span>',
    "a": ['np.max(x)', 'np.min(x)', 'np.mean(x)', '0'],
    "exp": '入力の最大値(c)を引いてからexpを計算することで、値が大きくなりすぎてオーバーフローするのを防ぎます。'
  },
  {
    "sid": 10,
    "q": '全結合層（Affine）を定義するクラスは？<br><span style="font-family:monospace; background:#333; padding:2px;">layer = nn.[ ? ](in_features=100, out_features=50)</span>',
    "a": ['Linear', 'Dense', 'Affine', 'FullyConnected'],
    "exp": 'PyTorchでは全結合層は「nn.Linear」です。（Keras等の「Dense」と混同しないように注意！）'
  },
  {
    "sid": 10,
    "q": '独自モデルを定義する際、継承すべき親クラスは？<br><span style="font-family:monospace; background:#333; padding:2px;">class MyModel(nn.[ ? ]):<br>    def __init__(self): ...</span>',
    "a": ['Module', 'Model', 'Network', 'Layer'],
    "exp": 'PyTorchのニューラルネットワークはすべて「nn.Module」を継承して作ります。'
  },
  {
    "sid": 10,
    "q": '順伝播処理を記述するために、nn.Moduleでオーバーライドする必要があるメソッドは？<br><span style="font-family:monospace; background:#333; padding:2px;">def [ ? ](self, x):<br>    x = self.layer1(x)<br>    return x</span>',
    "a": ['forward', 'call', 'predict', 'run'],
    "exp": '「forward」メソッドに順伝播の処理を書きます。モデルインスタンス model(x) を呼ぶと内部で forward(x) が実行されます。'
  },

    // --- 11: 順伝播と逆伝播 ---
  { 
    "sid": 11,
    "q": '勾配消失問題の原因となりやすい活性化関数は？',
    "a": ['シグモイド関数', 'ReLU', 'Leaky ReLU', 'Swish'],
    "exp": '微分最大値が0.25のため、層が深いと勾配が消えます。'
  },
  {
    "sid": 11,
    "q": '誤差逆伝播法で連鎖律(Chain Rule)を使う理由は？',
    "a": ['合成関数の微分を計算するため', '計算を並列化するため', '過学習を防ぐため', '初期値を決めるため'],
    "exp": '各パラメータの勾配を効率的に求めるためです。'
  },
  {
    "sid": 11,
    "q": "ニューラルネットワークの学習において、数値微分ではなく「誤差逆伝播法」を用いる最大の利点は何か。",
    "a": [
      "計算効率が高く、高速に勾配を求められる",
      "実装が非常に容易である",
      "局所解に陥りにくい",
      "計算精度が数値微分より常に高い"
    ],
    "exp": "数値微分は各パラメータごとに計算が必要で時間がかかりますが、誤差逆伝播法は計算グラフ上の局所的な微分を連鎖させることで、一度の計算で効率よく勾配を求められます。"
  },
  {
    "sid": 11,
    "q": "計算グラフにおける「加算ノード（z = x + y）」の逆伝播についての説明として正しいものはどれか。",
    "a": [
      "上流から伝わってきた勾配をそのまま流す",
      "上流から伝わってきた勾配に入力を乗算して流す",
      "上流から伝わってきた勾配の符号を反転して流す",
      "上流から伝わってきた勾配に(1 - 入力)を乗算して流す"
    ],
    "exp": "加算ノードの微分は1であるため、逆伝播では上流からの勾配に1を掛けた値、つまりそのままの値を下流（入力側）へ流します。"
  },
  {
    "sid": 11,
    "q": "計算グラフにおける「乗算ノード（z = x * y）」の逆伝播についての説明として正しいものはどれか。",
    "a": [
      "順伝播時の入力をひっくり返した値を乗算して流す",
      "上流から伝わってきた勾配をそのまま流す",
      "順伝播時の入力を二乗した値を乗算して流す",
      "順伝播時の入力の符号を反転して流す"
    ],
    "exp": "乗算ノード（z=xy）のxに関する偏微分はy、yに関する偏微分はxとなります。したがって、逆伝播では「入力をひっくり返した値」を勾配に乗算します。"
  },
  {
    "sid": 11,
    "q": "合成関数の微分において、ある関数全体の微分を、それを構成する各関数の微分の積として表すことができる性質を何と呼ぶか。",
    "a": [
      "連鎖律（チェーンルール）",
      "積の法則",
      "中心極限定理",
      "大数の法則"
    ],
    "exp": "誤差逆伝播法の根幹となる理論で、合成関数の微分は構成する関数の微分の積で表せます。"
  },
  {
    "sid": 11,
    "q": "ReLU（Rectified Linear Unit）レイヤの順伝播が y = x (x > 0), 0 (x <= 0) であるとき、x > 0 における逆伝播の挙動はどれか。",
    "a": [
      "上流の勾配をそのまま流す",
      "勾配を0にして流す",
      "上流の勾配にxを乗算して流す",
      "上流の勾配の符号を反転する"
    ],
    "exp": "x > 0 のとき、ReLUの微分係数は1となるため、上流からの勾配をそのまま下流へ伝えます。"
  },
  {
    "sid": 11,
    "q": "ReLUレイヤにおいて、順伝播時の入力xが 0以下だった場合、逆伝播で下流に流れる勾配はどうなるか。",
    "a": [
      "0になる",
      "上流の勾配そのまま",
      "無限大になる",
      "1になる"
    ],
    "exp": "x <= 0 のとき、ReLUの出力は0で固定されるため、微分係数（傾き）も0になります。よって勾配信号はそこで遮断され0になります。"
  },
  {
    "sid": 11,
    "q": "シグモイド関数 y = 1 / (1 + exp(-x)) の微分を、出力 y を用いて表した式はどれか。",
    "a": [
      "y(1 - y)",
      "y(1 + y)",
      "1 - y",
      "y^2"
    ],
    "exp": "シグモイド関数の導関数は、自分自身の出力 y を使って y(1 - y) と綺麗に表すことができます。"
  },
  {
    "sid": 11,
    "q": "シグモイド関数の逆伝播において、出力yが0または1に近づくと勾配消失問題が起きやすくなる理由はどれか。",
    "a": [
      "微分値 y(1-y) が0に近づくため",
      "微分値 y(1-y) が無限大になるため",
      "計算グラフが途切れるため",
      "入力xの符号が反転するため"
    ],
    "exp": "yが0や1に近いとき、y(1-y)の値は非常に小さくなり、逆伝播で勾配を掛け合わせるうちに値が消滅してしまうためです。"
  },
  {
    "sid": 11,
    "q": "行列計算を行うAffineレイヤ（Y = X・W + B）の逆伝播において、入力Xの勾配 ∂L/∂X を求める式はどれか（∂L/∂Y を dY とする）。",
    "a": [
      "dY ・ W^T",
      "dY ・ W",
      "W ・ dY",
      "W^T ・ dY"
    ],
    "exp": "行列の形状を整合させるため、重みWの転置行列(W^T)を、上流からの勾配dYに右から掛ける必要があります（形状確認：dY(N,H)・W^T(H,D) -> dX(N,D)）。"
  },
  {
    "sid": 11,
    "q": "Affineレイヤ（Y = X・W + B）の逆伝播において、重みWの勾配 ∂L/∂W を求める式はどれか（∂L/∂Y を dY とする）。",
    "a": [
      "X^T ・ dY",
      "X ・ dY",
      "dY ・ X^T",
      "dY ・ X"
    ],
    "exp": "重みWの勾配は、入力Xの転置行列(X^T)と上流勾配dYの積で求められます（形状確認：X^T(D,N)・dY(N,H) -> dW(D,H)）。"
  },
  {
    "sid": 11,
    "q": "AffineレイヤのバイアスB（形状はベクトル）の勾配を求める際、バッチ処理を行っている場合に必要な操作はどれか。",
    "a": [
      "上流からの勾配をバッチ方向（0軸）で総和をとる",
      "上流からの勾配をバッチ方向（0軸）で平均をとる",
      "上流からの勾配をそのまま使う",
      "上流からの勾配を転置する"
    ],
    "exp": "バイアスは順伝播時にバッチ内の全てのデータに対して加算（ブロードキャスト）されているため、逆伝播ではその逆操作としてバッチ方向の勾配を総和します。"
  },
  {
    "sid": 11,
    "q": "Softmax関数が出力する各要素の値の範囲と、総和の性質として正しいものはどれか。",
    "a": [
      "0から1の間であり、総和は1になる",
      "-1から1の間であり、総和は0になる",
      "0以上であり、総和は制限がない",
      "全て負の値であり、総和は-1になる"
    ],
    "exp": "Softmax関数は出力を確率として扱えるように正規化するため、各要素は0~1になり、その総和は必ず1になります。"
  },
  {
    "sid": 11,
    "q": "多クラス分類問題において、Softmax関数の出力とセットで用いられることの多い損失関数はどれか。",
    "a": [
      "交差エントロピー誤差（Cross Entropy Error）",
      "二乗和誤差（Mean Squared Error）",
      "絶対値誤差（Mean Absolute Error）",
      "ヒンジ損失（Hinge Loss）"
    ],
    "exp": "確率分布の比較に適しているため、多クラス分類ではSoftmaxと交差エントロピー誤差の組み合わせが標準的です。"
  },
  {
    "sid": 11,
    "q": "「Softmax-with-Loss」レイヤ（Softmaxと交差エントロピー誤差の複合レイヤ）の逆伝播の出力として正しいものはどれか（出力y, 教師データtとする）。",
    "a": [
      "y - t",
      "y + t",
      "y * t",
      "y / t"
    ],
    "exp": "SoftmaxとCross Entropy Errorを組み合わせると、逆伝播は「出力(y)と正解(t)の差分」という非常に単純な形になります。"
  },
  {
    "sid": 11,
    "q": "回帰問題において、恒等関数とセットで用いられる一般的な損失関数はどれか。",
    "a": [
      "二乗和誤差（Mean Squared Error）",
      "交差エントロピー誤差",
      "KLダイバージェンス",
      "0-1損失"
    ],
    "exp": "回帰問題（連続値の予測）では、出力層に恒等関数（入力をそのまま出力）を用い、損失関数には二乗和誤差を用いるのが一般的です。"
  },
  {
    "sid": 11,
    "q": "双曲線正接関数（tanh）の微分式として正しいものはどれか（出力 y = tanh(x) とする）。",
    "a": [
      "1 - y^2",
      "1 + y^2",
      "y(1 - y)",
      "2y"
    ],
    "exp": "tanh(x)の導関数は 1 - {tanh(x)}^2 となり、出力yを用いて 1 - y^2 と表せます。"
  },
  {
    "sid": 11,
    "q": "計算グラフ上で、あるノードからの出力が2つのノードに分岐して流れた場合、逆伝播においてそのノードに戻ってくる勾配はどうなるか。",
    "a": [
      "分岐先からの勾配の総和となる",
      "分岐先からの勾配の積となる",
      "分岐先からの勾配の平均となる",
      "分岐先からの勾配のうち最大のものとなる"
    ],
    "exp": "順伝播で分岐（複製）された場合、逆伝播ではそれぞれの経路から戻ってきた勾配を「加算（sum）」します。"
  },
  {
    "sid": 11,
    "q": "計算グラフ上で「Repeatノード（N個に複製）」の逆伝播操作に対応するものはどれか。",
    "a": [
      "Sumノード（N個の勾配の総和をとる）",
      "Meanノード（N個の勾配の平均をとる）",
      "Mulノード（勾配同士を掛け合わせる）",
      "None（何もしない）"
    ],
    "exp": "順伝播での複製（Repeat）の逆操作は、逆伝播では勾配の集約（Sum）になります。"
  },
  {
    "sid": 11,
    "q": "計算グラフ上で「Sumノード（総和をとる）」の逆伝播操作に対応するものはどれか。",
    "a": [
      "Repeatノード（勾配を分配・複製する）",
      "Addノード（勾配を足す）",
      "Divノード（勾配を割る）",
      "Subノード（勾配を引く）"
    ],
    "exp": "順伝播での総和（Sum）は、影響が全要素に及ぶため、逆伝播では勾配を元の形状に合わせて分配（Repeat）します。"
  },
  {
    "sid": 11,
    "q": "Dropoutレイヤの逆伝播において、順伝播時に消去（0に）されたニューロンに対応する勾配はどうなるか。",
    "a": [
      "遮断される（0になる）",
      "そのまま伝わる",
      "増幅される",
      "反転される"
    ],
    "exp": "Dropoutは順伝播で信号を通さなかったニューロンについては、逆伝播でも勾配を通しません（ReLUのx<=0と同様の動作）。"
  },
  {
    "sid": 11,
    "q": "勾配確認（Gradient Check）の主な目的は何か。",
    "a": [
      "実装した誤差逆伝播法の勾配が正しいか、数値微分との比較で検証する",
      "学習率の最適値を自動決定する",
      "過学習が起きていないか確認する",
      "データセットに外れ値がないか確認する"
    ],
    "exp": "誤差逆伝播法の実装はバグが入りやすいため、計算コストは高いが実装が単純な数値微分の結果と比較し、一致するかを確認します。"
  },
  {
    "sid": 11,
    "q": "数値微分において、前方差分（(f(x+h)-f(x))/h）よりも中心差分（(f(x+h)-f(x-h))/2h）が推奨される理由は何か。",
    "a": [
      "誤差が小さくなり精度が良いから",
      "計算回数が少なくて済むから",
      "hを大きく取れるから",
      "負の値でも計算できるから"
    ],
    "exp": "中心差分はテイラー展開の性質上、誤差のオーダーが前方差分よりも小さくなり、より真の微分値に近い近似が得られます。"
  },
  {
    "sid": 11,
    "q": "ニューラルネットワークの学習ステップの正しい順序はどれか。",
    "a": [
      "ミニバッチ選出 -> 順伝播 -> 逆伝播(勾配算出) -> パラメータ更新",
      "順伝播 -> ミニバッチ選出 -> パラメータ更新 -> 逆伝播(勾配算出)",
      "ミニバッチ選出 -> 逆伝播(勾配算出) -> 順伝播 -> パラメータ更新",
      "パラメータ更新 -> ミニバッチ選出 -> 順伝播 -> 逆伝播(勾配算出)"
    ],
    "exp": "まずはデータを流し（順伝播）、損失を計算してから勾配を求め（逆伝播）、その勾配を使って重みを更新します。"
  },
  {
    "sid": 11,
    "q": "Leaky ReLU（f(x) = x if x>0 else ax）の特徴として正しいものはどれか。",
    "a": [
      "x <= 0 の領域でもわずかに勾配を流すため、ニューロンが死ぬのを防げる",
      "出力が常に正の値になる",
      "x > 0 の領域で勾配が徐々に小さくなる",
      "指数関数的な計算が必要である"
    ],
    "exp": "通常のReLUは負の入力で勾配が0になりますが、Leaky ReLUは負の入力にも小さな傾き(a)を持たせることで学習を進行させます。"
  },
  {
    "sid": 11,
    "q": "バッチ正規化（Batch Normalization）レイヤの逆伝播で行われる処理として不適切なものはどれか。",
    "a": [
      "活性化関数の微分の計算",
      "正規化された入力に対する勾配の計算",
      "平均と分散に対する勾配の計算",
      "入力データへの勾配の計算"
    ],
    "exp": "バッチ正規化は活性化関数の『前』または『後』に挿入される独立したレイヤであり、バッチ正規化レイヤ自体の中で活性化関数の微分計算は行いません（それはActivationレイヤの仕事です）。"
  },
  {
    "sid": 11,
    "q": "逆伝播計算の実装において、一般的に順伝播時の入力値などを保持しておく必要がある。その主な理由は何か。",
    "a": [
      "逆伝播の計算式で、順伝播時の入力値を使用する場合が多いから",
      "次のエポックの順伝播で使用するから",
      "損失関数の計算に必要だから",
      "学習率の調整に使うから"
    ],
    "exp": "例えばSigmoidレイヤではy(1-y)、ReLUではx>0の判定、Affineでは入力Xの転置など、逆伝播計算には順伝播時の情報が必須となるため、キャッシュ（保持）しておきます。"
  },
  {
    "sid": 11,
    "q": "「勾配消失」に対して「勾配爆発」という問題もある。これが起きやすい場面の例はどれか。",
    "a": [
      "RNNなどで層が非常に深くなり、1より大きい重みが繰り返しかけられた場合",
      "ReLU関数のみを使用した浅いネットワークの場合",
      "学習率を極端に小さく設定した場合",
      "入力データが全て0の場合"
    ],
    "exp": "逆伝播で勾配が層を遡る際、1より大きな係数が乗算され続けると値が指数関数的に増大し、オーバーフローなどを引き起こします。"
  },
  {
    "sid": 11,
    "q": "3層ニューラルネットワークの実装において、パラメータ（重みW、バイアスb）の初期値を全て0にした場合の問題点は何か。",
    "a": [
      "全てのニューロンが同じ値を計算し、同じ勾配を持つため、多様な特徴を学習できない",
      "初期値が0だと計算エラーが発生する",
      "学習が急速に進みすぎて過学習する",
      "逆伝播が全く動作しなくなる"
    ],
    "exp": "重みが対称的な状態（全て同じ）だと、逆伝播しても更新量が全て同じになり、実質的に1つのニューロンがあるのと変わらなくなってしまいます（重みの対称性の破壊が必要）。"
  },
  {
    "sid": 11,
    "q": "Softmax関数を適用する際、入力値の最大値を引いてから指数計算を行う（exp(x_i - max(x))）定石があるが、その理由は何か。",
    "a": [
      "指数関数のオーバーフローを防ぐため",
      "計算速度を上げるため",
      "微分しやすくするため",
      "負の値を正にするため"
    ],
    "exp": "指数関数 exp(x) はxが大きくなると容易に巨大な値になり、コンピュータで扱える数値を数を超えてオーバーフロー（Inf）するのを防ぐための実装上のテクニックです。"
  },
  {
    "sid": 11,
    "q": "連鎖律（チェーンルール）の式として正しいものはどれか（z = f(y), y = g(x) とする）。",
    "a": [
      "∂z/∂x = ∂z/∂y * ∂y/∂x",
      "∂z/∂x = ∂z/∂y + ∂y/∂x",
      "∂z/∂x = ∂z/∂y / ∂y/∂x",
      "∂z/∂x = ∂y/∂x - ∂z/∂y"
    ],
    "exp": "連鎖律により、ある変数に対する微分は、局所的な微分の積として連結して求めることができます。"
  },
  {
    "sid": 11,
    "q": 'Affineレイヤ（Y = XW + B）の逆伝播で、入力Xの勾配(dx)を求める式は？（doutは出力側の勾配）<br><span style="font-family:monospace; background:#333; padding:2px;">dx = np.dot([ ? ], W.T)</span>',
    "a": ['dout', 'dout.T', 'W', 'X'],
    "exp": '形状を確認しましょう。Y=XWの逆伝播では、dx = dot(dout, W.T) となります。'
　},
　{
    "sid": 11,
    "q": '逆伝播を実行し、勾配を計算するメソッドは？<br><span style="font-family:monospace; background:#333; padding:2px;">loss = criterion(output, target)<br>loss.[ ? ]()</span>',
    "a": ['backward', 'backprop', 'gradient', 'step'],
    "exp": '「loss.backward()」を呼ぶことで、計算グラフを遡って各パラメータの .grad 属性に勾配が格納されます。'
　},
　{
    "sid": 11,
    "q": '推論時など、勾配計算を無効化してメモリを節約するためのコンテキストマネージャは？<br><span style="font-family:monospace; background:#333; padding:2px;">with torch.[ ? ]():<br>    output = model(x)</span>',
    "a": ['no_grad', 'grad_off', 'eval', 'inference'],
    "exp": '「with torch.no_grad():」ブロック内では勾配計算が行われません。検証・テスト時に必須です。'
　},

    // --- 12: 最適化手法 ---
  {
    "sid": 12,
    "q": '過去の勾配の二乗和を利用して学習率を調整する手法は？',
    "a": ['AdaGrad', 'SGD', 'Momentum', 'Adam'],
    "exp": '学習が進むにつれ学習率が小さくなります。'
  },
  {
    "sid": 12,
    "q": 'Adamの計算に使われるのは？',
    "a": ['勾配の一次モーメントと二次モーメント', '勾配のみ', '勾配の二乗のみ', 'ヘッセ行列'],
    "exp": 'MomentumとRMSPropの考え方を組み合わせています。'
  },
  {
    "sid": 12,
    "q": "勾配降下法において、学習データセット全体を一度に計算に使用してパラメータ更新を行う手法はどれか。",
    "a": [
      "バッチ勾配降下法",
      "確率的勾配降下法 (SGD)",
      "ミニバッチ勾配降下法",
      "ニュートン法"
    ],
    "exp": "バッチ勾配降下法は全データの勾配平均を使って更新します。計算は安定しますが、データ量が多いと1回の更新に時間がかかります。"
  },
  {
    "sid": 12,
    "q": "確率的勾配降下法 (SGD) の主な特徴として正しいものはどれか。",
    "a": [
      "1つのサンプル毎にパラメータを更新するため、更新の軌跡がジグザグに振動しやすい",
      "全データを一度に使うため、計算コストが非常に高い",
      "学習率を自動で調整する機能が組み込まれている",
      "過去の勾配の二乗和を蓄積して学習率を減衰させる"
    ],
    "exp": "SGDはランダムに選んだ1つのデータで更新を行うため、計算は高速ですが、ノイズが多く最適解への収束経路が振動しやすくなります。"
  },
  {
    "sid": 12,
    "q": "SGDの振動を抑制し、慣性項を導入することで加速させる手法はどれか。",
    "a": [
      "Momentum",
      "Adagrad",
      "RMSprop",
      "Newton Method"
    ],
    "exp": "Momentum（モーメンタム）は、物理的な慣性の考えを取り入れ、過去の移動方向（速度ベクトル）を加算することで振動を抑えつつ加速します。"
  },
  {
    "sid": 12,
    "q": "Momentum SGDの更新式において、過去の勾配の影響度合いを調整するハイパーパラメータは一般的に何と呼ばれるか。",
    "a": [
      "慣性係数 (momentum coefficient)",
      "学習率 (learning rate)",
      "減衰率 (decay rate)",
      "正則化項 (regularization term)"
    ],
    "exp": "慣性係数（通常0.9などが使われる）は、前のステップの更新量をどれだけ現在の更新に反映させるかを決定します。"
  },
  {
    "sid": 12,
    "q": "パラメータごとに個別の学習率を適応的に調整する手法の先駆けであり、過去の勾配の二乗和を用いて学習率を減衰させる手法はどれか。",
    "a": [
      "Adagrad",
      "Momentum",
      "SGD",
      "Nesterov Momentum"
    ],
    "exp": "Adagradは、頻繁に更新されるパラメータの学習率を下げ、更新が少ないパラメータの学習率を相対的に保つことで、スパースなデータに適応します。"
  },
  {
    "sid": 12,
    "q": "Adagradの欠点である「学習が進むにつれて学習率が過度に小さくなり、更新が止まってしまう」問題を解決するために提案された手法はどれか。",
    "a": [
      "RMSprop",
      "Momentum",
      "SGD",
      "Newton Method"
    ],
    "exp": "RMSpropは、過去の勾配情報を指数移動平均で管理することで、過去の情報を徐々に忘れさせ、学習率が極端に0に近づくのを防ぎます。"
  },
  {
    "sid": 12,
    "q": "RMSpropと同様の考え方を用いつつ、学習率のハイパーパラメータを不要にすることを目指した手法はどれか。",
    "a": [
      "Adadelta",
      "Adam",
      "Nesterov Momentum",
      "AdaBound"
    ],
    "exp": "Adadeltaは学習率の設定を不要にするために、更新量の単位（次元）をパラメータと一致させる工夫などが盛り込まれています。"
  },
  {
    "sid": 12,
    "q": "MomentumとRMSpropの利点を組み合わせたような手法で、勾配の平均（1次モーメント）と分散（2次モーメント）を推定して利用するものはどれか。",
    "a": [
      "Adam",
      "Adagrad",
      "SGD",
      "Nesterov"
    ],
    "exp": "Adam (Adaptive Moment Estimation) は、Momentumのような慣性項とRMSpropのような適応的な学習率調整を組み合わせた、現在最も広く使われる手法の一つです。"
  },
  {
    "sid": 12,
    "q": "Adamにおいて、学習初期に勾配の推定値が0の方に偏ってしまうバイアスを補正する処理を何と呼ぶか。",
    "a": [
      "バイアス補正 (Bias Correction)",
      "重み減衰 (Weight Decay)",
      "勾配クリッピング (Gradient Clipping)",
      "バッチ正規化 (Batch Normalization)"
    ],
    "exp": "Adamでは移動平均の初期値が0であるため、学習初期に値が小さくなりすぎるのを防ぐためにバイアス補正を行います。"
  },
  {
    "sid": 12,
    "q": "ディープラーニングの最適化において、勾配が0になるが極小値ではなく、ある方向では極大、別の方向では極小となっている点を何と呼ぶか。",
    "a": [
      "鞍点 (Saddle Point)",
      "局所解 (Local Minima)",
      "大域解 (Global Minima)",
      "特異点 (Singular Point)"
    ],
    "exp": "高次元空間では局所解よりも鞍点（サドルポイント）が多く存在し、勾配法がここで停滞してしまうことが最適化の課題の一つです。"
  },
  {
    "sid": 12,
    "q": "Nesterovの加速勾配法（NAG）の特徴として正しいものはどれか。",
    "a": [
      "現在の位置ではなく、慣性で移動した「先」の位置での勾配を使って更新方向を修正する",
      "過去の勾配の二乗和の平方根で学習率を割る",
      "勾配の符号のみを利用して更新を行う",
      "2階微分（ヘッセ行列）を使用して更新幅を決定する"
    ],
    "exp": "Nesterov Momentumは、慣性項によって「移動するであろう位置」を先読みし、その地点での勾配を計算することで、Momentumよりも的確にブレーキをかけられます。"
  },
  {
    "sid": 12,
    "q": "ニュートン法などの2次の最適化手法が、大規模なディープラーニングであまり使われない主な理由は何か。",
    "a": [
      "ヘッセ行列の計算と逆行列の計算コストが膨大であるため",
      "局所解に陥りやすいため",
      "学習率の設定が難しいため",
      "勾配消失問題を引き起こしやすいため"
    ],
    "exp": "パラメータ数がNの場合、ヘッセ行列はN×Nのサイズになり、その逆行列計算はO(N^3)の計算量が必要となるため、大規模モデルでは現実的ではありません。"
  },
  {
    "sid": 12,
    "q": "Adamの改良版であり、過去の2次モーメントの最大値を保持することで学習率が不適切に増加するのを防ぐ手法はどれか。",
    "a": [
      "AMSGrad",
      "AdaBound",
      "Nadam",
      "RAdam"
    ],
    "exp": "AMSGradは、Adamが特定の条件下で収束しない可能性があるという理論的な指摘に基づいて提案された手法で、2次モーメントの最大値を利用します。"
  },
  {
    "sid": 12,
    "q": "探索の初期段階では学習率を小さく設定し、徐々に本来の学習率まで上げていくテクニックを何と呼ぶか。",
    "a": [
      "ウォームアップ (Warm-up)",
      "アニーリング (Annealing)",
      "クリッピング (Clipping)",
      "ドロップアウト (Dropout)"
    ],
    "exp": "学習初期の不安定な勾配による急激なパラメータ変化を防ぐため、最初の数エポックで学習率を徐々に上げるウォームアップがAdamなどでよく用いられます。"
  },
  {
    "sid": 12,
    "q": "最適化の過程で勾配のノルムが閾値を超えた場合に、勾配の大きさを強制的に小さくする手法は何か。",
    "a": [
      "勾配クリッピング (Gradient Clipping)",
      "勾配消失 (Gradient Vanishing)",
      "早期終了 (Early Stopping)",
      "重み減衰 (Weight Decay)"
    ],
    "exp": "RNNなどで発生しやすい勾配爆発を防ぐため、勾配のL2ノルムがある値を超えたら、その値で正規化（スケーリング）して勾配を縮小させます。"
  },
  {
    "sid": 12,
    "q": "Adagradの更新式において、分母に小さな値ε（イプシロン）を加算する主な理由は何か。",
    "a": [
      "0除算（ゼロ除算）を防ぐため",
      "学習率を大きくするため",
      "正則化の効果を持たせるため",
      "慣性項を打ち消すため"
    ],
    "exp": "過去の勾配が0の場合などに分母が0になるのを防ぐため、非常に小さな値（例: 1e-8）を加算して数値安定性を保ちます。"
  },
  {
    "sid": 12,
    "q": "損失関数の形状が「ある方向には急峻で、ある方向には緩やか」である場合（病的な曲率）、SGDで発生しやすい現象はどれか。",
    "a": [
      "谷の壁に向かってジグザグに振動し、なかなか最小値に進まない",
      "一気に最小値に到達し、通り過ぎてしまう",
      "学習率が急速に0になり、更新が停止する",
      "勾配が常に0と計算されてしまう"
    ],
    "exp": "このような形状（イルコンディション）では、SGDは急な斜面の方向へ大きく更新され、谷底を行ったり来たりする非効率な動き（ジグザグ振動）になりがちです。"
  },
  {
    "sid": 12,
    "q": "ミニバッチサイズを大きくしすぎた場合に懸念される、汎化性能への悪影響についての説明として適切なものはどれか。",
    "a": [
      "鋭い最小解（Sharp Minima）に収束しやすく、汎化性能が低下する可能性がある",
      "平坦な最小解（Flat Minima）に収束しやすく、汎化性能が向上する",
      "計算時間が短くなるため、学習不足になりやすい",
      "勾配の分散が大きくなり、収束しなくなる"
    ],
    "exp": "バッチサイズが大きいと勾配のノイズが減り正確な方向へ進みますが、その結果、訓練データに過剰適合した鋭い谷（Sharp Minima）に落ち込みやすく、汎化性能が落ちることが知られています。"
  },
  {
    "sid": 12,
    "q": "Adamのハイパーパラメータ β1（ベータ1）は、通常どの程度の値に設定されることが多いか。",
    "a": [
      "0.9",
      "0.999",
      "0.001",
      "0.5"
    ],
    "exp": "β1は1次モーメント（Momentum項）の減衰率で、通常0.9が推奨されます。β2（2次モーメント）は0.999が一般的です。"
  },
  {
    "sid": 12,
    "q": "SGDにおいて、一定のエポック数ごとに学習率を一定の割合で小さくしていく手法を何と呼ぶか。",
    "a": [
      "ステップ減衰 (Step Decay)",
      "指数減衰 (Exponential Decay)",
      "余弦アニーリング (Cosine Annealing)",
      "逆数減衰 (Inverse Time Decay)"
    ],
    "exp": "特定のタイミング（例：30エポック毎）で学習率を0.1倍にするなどの方法はステップ減衰と呼ばれ、古典的ですが効果的なスケジューリング手法です。"
  },
  {
    "sid": 12,
    "q": "SGDにL2正則化を加えた場合と、Weight Decay（重み減衰）を行った場合は数学的に等価になるが、Adamなどの適応的勾配法の場合はどうなるか。",
    "a": [
      "等価にはならず、L2正則化の効果が適応的学習率によって弱められる場合がある",
      "完全に等価である",
      "AdamではL2正則化は計算不能である",
      "Weight Decayの方が計算コストが高くなる"
    ],
    "exp": "Adam等ではパラメータ毎に学習率がスケーリングされるため、単純なL2正則化（勾配への加算）とWeight Decay（パラメータの直接減衰）は挙動が異なり、これを修正したのがAdamWです。"
  },
  {
    "sid": 12,
    "q": "AdamW（Adam with Weight Decay）が提案された主な理由は何か。",
    "a": [
      "AdamにおいてL2正則化とWeight Decayの役割を正しく分離するため",
      "Adamの計算速度を向上させるため",
      "Adamのメモリ使用量を削減するため",
      "AdamをRNNに適用可能にするため"
    ],
    "exp": "AdamではL2正則化項も適応的学習率で割られてしまうため、正則化の効果が不均一になります。AdamWは重み減衰を更新式の最後で独立して行うことでこれを修正しました。"
  },
  {
    "sid": 12,
    "q": "局所最適解（Local Minima）からの脱出を助ける要素として、確率的勾配降下法(SGD)が持っている性質はどれか。",
    "a": [
      "勾配計算に含まれるノイズ",
      "学習率の自動減衰",
      "過去の勾配の蓄積",
      "ヘッセ行列の利用"
    ],
    "exp": "SGDはランダムに選んだデータで勾配を計算するため、そのノイズによって一時的に損失が増える方向へ動くこともあり、浅い局所解から抜け出せる可能性があります。"
  },
  {
    "sid": 12,
    "q": "学習率を周期的に増減させることで、複数の局所解を探索し、アンサンブル学習のような効果を狙う手法はどれか。",
    "a": [
      "Snapshot Ensemble (Cosine Annealing with Restarts)",
      "Model Distillation",
      "Batch Normalization",
      "Early Stopping"
    ],
    "exp": "学習率を周期的にリセット（Restart）することで、モデルが一つの局所解に収束した後、別の局所解へと探索を促し、それらのモデルを組み合わせる手法です。"
  },
  {
    "sid": 12,
    "q": "次の最適化手法のうち、一般的に「スパースな解（多くのパラメータが0になる解）」を得るのには向いていない手法はどれか。（L1正則化と組み合わせた場合を除く基本的な性質として）",
    "a": [
      "標準的なSGDやAdam",
      "RDA (Regularized Dual Averaging)",
      "FTRL (Follow the Regularized Leader)",
      "L1正則化付き近接勾配法"
    ],
    "exp": "標準的なSGDやAdamなどの勾配法は、数値を少しずつ更新するため、厳密に0になる（スパース化する）ことは稀です。スパース性が必要な場合はFTRLなどが使われます。"
  },
  {
    "sid": 12,
    "q": "Adagradの更新式 $h \\leftarrow h + (\\frac{\\partial L}{\\partial w})^2$ において、$h$ は何を意味しているか。",
    "a": [
      "過去の全ての勾配の二乗和",
      "過去の全ての勾配の平均",
      "過去の全ての勾配の指数移動平均",
      "現在の勾配の大きさ"
    ],
    "exp": "Adagradの変数hは、学習開始から現在までの勾配の二乗を累積加算したものです。これが学習率の分母に来るため、単調増加し学習率を下げ続けます。"
  },
  {
    "sid": 12,
    "q": "RAdam (Rectified Adam) が解決しようとした課題は何か。",
    "a": [
      "学習初期にサンプル数が少ないため適応的学習率の分散が大きくなり、学習が不安定になる問題",
      "学習終盤に学習率が小さくなりすぎて収束しない問題",
      "鞍点からの脱出が困難である問題",
      "メモリ使用量が大きすぎる問題"
    ],
    "exp": "RAdamは、学習初期のデータが少ない段階でAdamの分散が発散してしまうのを防ぐため、動的に「整流（Rectify）」項を導入して学習率を調整します。"
  },
  {
    "sid": 12,
    "q": "最適化手法の文脈で「プラトー（Plateau）」とはどのような状態を指すか。",
    "a": [
      "勾配が非常に小さく平坦な領域が続き、学習が停滞している状態",
      "学習率が高すぎて損失が発散している状態",
      "過学習が発生してテスト誤差が増加している状態",
      "バッチサイズが大きすぎてメモリ不足になっている状態"
    ],
    "exp": "プラトーは損失関数のグラフが平地（高原）のようになっている部分で、勾配がほぼ0に近いためパラメータ更新がほとんど進まなくなる現象です。"
  },
  {
    "sid": 12,
    "q": "Lookahead Optimizerの説明として正しいものはどれか。",
    "a": [
      "「速い重み」で数ステップ先行して探索し、「遅い重み」をその方向にゆっくり更新することで安定化を図る",
      "未来の勾配を予測して現在の更新を行う",
      "画像の先読みを行ってデータロードを高速化する手法",
      "損失関数の最小値を直接推定する手法"
    ],
    "exp": "Lookaheadは、内部オプティマイザ（Adamなど）でk回更新した（Fast weights）後、元の重み（Slow weights）との間で補間を行うことで、探索の安定性と収束性能を向上させます。"
  },
  {
    "sid": 12,
    "q": "損失関数 $L(w)$ のテイラー展開において、勾配降下法は主に何次の項までを考慮した近似に基づいているか。",
    "a": [
      "1次（線形近似）",
      "2次（二次近似）",
      "0次（定数近似）",
      "無限次"
    ],
    "exp": "勾配降下法は、関数の傾き（1階微分）のみを利用して、局所的に平面（直線）で近似して下る方向を決めるため、1次の最適化手法に分類されます。"
  },
  {
    "sid": 12,
    "q": 'SGD（確率的勾配降下法）のパラメータ更新式コードの空欄は？<br><span style="font-family:monospace; background:#333; padding:2px;"># params: 重み, grads: 勾配, lr: 学習率<br>for key in params.keys():<br>    params[key] [ ? ] lr * grads[key]</span>',
    "a": ['-=', '+=', '*=', '/='],
    "exp": '勾配降下法なので、勾配の「逆方向」に進むために、学習率×勾配を「引き算」します。'
  },
  {
    "sid": 12,
    "q": 'Momentumの更新式におけるv（速度）の更新コードは？<br><span style="font-family:monospace; background:#333; padding:2px;">v[key] = momentum * v[key] - lr * grads[key]<br>params[key] [ ? ] v[key]</span>',
    "a": ['+=', '-=', '*=', '='],
    "exp": 'Momentumでは計算済みの速度ベクトル v を現在のパラメータに「加算」します（vの計算式ですでにマイナスされているため）。'
  },
  {
    "sid": 12,
    "q": 'オプティマイザの初期化コード。パラメータを渡す正しい書き方は？<br><span style="font-family:monospace; background:#333; padding:2px;">optimizer = optim.SGD([ ? ], lr=0.01)</span>',
    "a": ['model.parameters()', 'model.weights()', 'model.grads()', 'model.state_dict()'],
    "exp": 'オプティマイザには更新対象となる「model.parameters()」を渡します。'
  },
  {
    "sid": 12,
    "q": '学習ループ内で、前回のイテレーションの勾配をリセットするメソッドは？<br><span style="font-family:monospace; background:#333; padding:2px;">optimizer.[ ? ]()<br>loss.backward()<br>optimizer.step()</span>',
    "a": ['zero_grad', 'clear_grad', 'reset_grad', 'init_grad'],
    "exp": 'PyTorchは勾配を「加算（累積）」する仕様のため、毎回「zero_grad()」でリセットする必要があります。'
  },
  {
    "sid": 12,
    "q": 'パラメータを実際に更新するメソッドは？<br><span style="font-family:monospace; background:#333; padding:2px;">optimizer.zero_grad()<br>loss.backward()<br>optimizer.[ ? ]()</span>',
    "a": ['step', 'update', 'run', 'optimize'],
    "exp": '「step()」メソッドで、計算された勾配と学習率に基づいてパラメータを更新します。'
  },

    // --- 13: 畳み込みニューラルネットワーク (CNN) ---
  {
    "sid": 13,
    "q": 'CNNにおけるプーリング層の役割は？',
    "a": ['位置ズレ不変性の獲得', '特徴量の強調', 'チャネル数の変更', '非線形変換'],
    "exp": '微小な平行移動を吸収します。'
  },
  {
    "sid": 13,
    "q": '1x1畳み込みの主な用途は？',
    "a": ['チャネル数の調整(次元削減)', '受容野を広げる', '画像サイズを大きくする', 'エッジ検出'],
    "exp": 'Inceptionモジュールなどで計算量を減らすために使われます。'
  },
  {
    "sid": 13,
    "q": "畳み込みニューラルネットワーク（CNN）において、入力データの特徴を抽出するために用いられるフィルタのことを何と呼ぶか。",
    "a": [
      "カーネル",
      "ストライド",
      "パディング",
      "チャネル"
    ],
    "exp": "畳み込み演算において、画像などの入力データ上をスライドさせて積和演算を行うフィルタをカーネルと呼びます。"
  },
  {
    "sid": 13,
    "q": "入力サイズが(H, W)、カーネルサイズが(K, K)、パディングがP、ストライドがSの場合、出力される特徴マップの高さ(H_out)を求める式はどれか。",
    "a": [
      "(H + 2P - K) / S + 1",
      "(H + P - K) / S + 1",
      "(H + 2P - K) / S - 1",
      "(H - P + K) / S + 1"
    ],
    "exp": "出力サイズ = (入力サイズ + 2×パディング - カーネルサイズ) / ストライド + 1 です。"
  },
  {
    "sid": 13,
    "q": "畳み込み処理を行う際、出力サイズが入力サイズよりも小さくならないように、入力データの周囲を0などで埋める処理を何と呼ぶか。",
    "a": [
      "パディング",
      "プーリング",
      "クリッピング",
      "ドロップアウト"
    ],
    "exp": "パディングは、畳み込みによるサイズ縮小を防いだり、端の情報を活用するために周囲を埋める処理です。"
  },
  {
    "sid": 13,
    "q": "入力画像サイズが5x5、カーネルサイズが3x3、パディングが0、ストライドが1のとき、出力画像のサイズはいくつになるか。",
    "a": [
      "3x3",
      "4x4",
      "5x5",
      "2x2"
    ],
    "exp": "(5 + 2*0 - 3) / 1 + 1 = 3 となります。"
  },
  {
    "sid": 13,
    "q": "微小な位置ズレに対する不変性を高めるために導入される層で、対象領域内の最大値を取り出す処理を何と呼ぶか。",
    "a": [
      "Max Pooling",
      "Average Pooling",
      "Global Average Pooling",
      "Dilated Convolution"
    ],
    "exp": "Max Poolingは領域内の最大値を取り出す処理で、平行移動などの位置ズレに対するロバスト性を向上させます。"
  },
  {
    "sid": 13,
    "q": "畳み込み層において、カーネルを適用する間隔（ずらす幅）のことを何と呼ぶか。",
    "a": [
      "ストライド",
      "ダイレーション",
      "バイアス",
      "エポック"
    ],
    "exp": "ストライドはフィルタを適用する間隔のことで、値を大きくすると出力サイズは小さくなります。"
  },
  {
    "sid": 13,
    "q": "AlexNetで採用され、過学習を抑制するために全結合層などでランダムにニューロンを無効化する手法はどれか。",
    "a": [
      "Dropout",
      "Batch Normalization",
      "Data Augmentation",
      "Early Stopping"
    ],
    "exp": "Dropoutは学習時にランダムにニューロンを不活性化（ドロップ）させることで、アンサンブル学習のような効果を得て過学習を防ぎます。"
  },
  {
    "sid": 13,
    "q": "入力チャネル数がC_in、出力チャネル数がC_out、カーネルサイズがKxKの畳み込み層において、バイアスを含めたパラメータ数を求める式はどれか。",
    "a": [
      "K × K × C_in × C_out + C_out",
      "K × K × C_in × C_out",
      "K × K × C_out + C_out",
      "(K × K + 1) × C_in × C_out"
    ],
    "exp": "重みの数は(K×K×C_in×C_out)、バイアスの数は出力チャネル数(C_out)分あるため、これらを合計します。"
  },
  {
    "sid": 13,
    "q": "1x1の畳み込み（Pointwise Convolution）の主な利用目的として適切でないものはどれか。",
    "a": [
      "受容野（Receptive Field）を広げる",
      "チャネル数の削減（次元圧縮）",
      "チャネル数の増加",
      "非線形性の導入"
    ],
    "exp": "1x1畳み込みは空間方向のサイズを変えないため、受容野を広げる効果はありません。主にチャネル数の調整や計算量の削減に使用されます。"
  },
  {
    "sid": 13,
    "q": "VGGNetの特徴として最も適切なものはどれか。",
    "a": [
      "3x3の小さなフィルタを重ねて層を深くした",
      "Inceptionモジュールという並列構造を用いた",
      "スキップ接続（Residual Connection）を導入した",
      "Depthwise Separable Convolutionを採用した"
    ],
    "exp": "VGGNetは、5x5などの大きなフィルタの代わりに、3x3の小さなフィルタを複数回重ねることで、パラメータ数を抑えつつ非線形性を高めました。"
  },
  {
    "sid": 13,
    "q": "GoogLeNetで採用された、異なるサイズのフィルタ（1x1, 3x3, 5x5）やプーリングを並列に適用し、結合する構造を何と呼ぶか。",
    "a": [
      "Inceptionモジュール",
      "Residualブロック",
      "Denseブロック",
      "Attentionモジュール"
    ],
    "exp": "Inceptionモジュールは、複数の異なるスケールの特徴を同時に抽出するために考案された並列構造です。"
  },
  {
    "sid": 13,
    "q": "層を深くすることによる勾配消失問題や劣化問題に対処するために、ResNetで導入された構造は何か。",
    "a": [
      "スキップ接続（ショートカット接続）",
      "Auxiliary Loss",
      "Local Response Normalization",
      "Grouped Convolution"
    ],
    "exp": "ResNetでは、入力xを出力F(x)に足し合わせるスキップ接続を導入し、H(x)=F(x)+xを学習させることで、超多層化を可能にしました。"
  },
  {
    "sid": 13,
    "q": "Global Average Pooling (GAP) の説明として正しいものはどれか。",
    "a": [
      "各チャネルの平均値を計算し、1つの値にする",
      "各チャネルの最大値を計算し、1つの値にする",
      "全結合層の直前ではなく、最初の層で使われる",
      "画像の解像度を上げるために使われる"
    ],
    "exp": "GAPは、特徴マップの各チャネル（H x W）の平均を取り、1x1のサイズにする処理です。全結合層のパラメータ数を削減する目的などで使われます。"
  },
  {
    "sid": 13,
    "q": "セマンティックセグメンテーションなどで用いられる、カーネルの要素間に隙間を空けて畳み込みを行うことで、パラメータ数を増やさずに受容野を広げる手法は何か。",
    "a": [
      "Dilated Convolution",
      "Transposed Convolution",
      "Depthwise Convolution",
      "Strided Convolution"
    ],
    "exp": "Dilated Convolution（Atrous Convolution）は、フィルタを膨張（Dilate）させて適用することで、広範囲の情報を効率的に取り込みます。"
  },
  {
    "sid": 13,
    "q": "画像のアップサンプリング（解像度を上げる）に使用される畳み込み処理はどれか。",
    "a": [
      "Transposed Convolution",
      "Dilated Convolution",
      "Depthwise Convolution",
      "Pointwise Convolution"
    ],
    "exp": "Transposed Convolution（転置畳み込み）は、逆畳み込みとも呼ばれ、特徴マップのサイズを拡大する際によく用いられます。"
  },
  {
    "sid": 13,
    "q": "MobileNetなどで採用されている、計算量を大幅に削減するための畳み込み手法はどれか。",
    "a": [
      "Depthwise Separable Convolution",
      "Grouped Convolution",
      "Dilated Convolution",
      "Deformable Convolution"
    ],
    "exp": "Depthwise Separable Convolutionは、Depthwise ConvolutionとPointwise Convolutionを組み合わせることで、通常の畳み込みよりも計算量を大幅に削減します。"
  },
  {
    "sid": 13,
    "q": "入力サイズ32x32、パディング2、カーネルサイズ5x5、ストライド1の畳み込み層を通した後の出力サイズはいくつか。",
    "a": [
      "32x32",
      "28x28",
      "30x30",
      "34x34"
    ],
    "exp": "(32 + 2*2 - 5) / 1 + 1 = 32。パディングにより入力と同じサイズが維持されています。"
  },
  {
    "sid": 13,
    "q": "入力チャネル数3、出力チャネル数64、カーネルサイズ3x3の畳み込み層のパラメータ数（重み+バイアス）はいくつか。",
    "a": [
      "1792",
      "1728",
      "576",
      "67"
    ],
    "exp": "重み: 3×3×3×64 = 1728, バイアス: 64。合計 1728 + 64 = 1792。"
  },
  {
    "sid": 13,
    "q": "CNNにおいて、ある層のニューロンが出力に影響を受ける入力画像上の領域のことを何と呼ぶか。",
    "a": [
      "受容野（Receptive Field）",
      "関心領域（ROI）",
      "アンカーボックス",
      "バウンディングボックス"
    ],
    "exp": "受容野とは、出力層のあるユニットが、入力画像のどの範囲の情報を見ているかを示す領域のことです。"
  },
  {
    "sid": 13,
    "q": "ResNetの派生形であるResNeXtで採用された、入力チャネルを複数のグループに分割して畳み込みを行う手法は何か。",
    "a": [
      "Grouped Convolution",
      "Separable Convolution",
      "Dilated Convolution",
      "Shifted Convolution"
    ],
    "exp": "Grouped Convolutionは、チャネル間の結合を疎にすることで、精度を維持しつつパラメータ数と計算量を削減します。"
  },
  {
    "sid": 13,
    "q": "DenseNetの特徴的な構造として正しいものはどれか。",
    "a": [
      "前方の全層の特徴マップをチャネル方向に結合（Concat）する",
      "前方の層の特徴マップを要素ごとに加算（Add）する",
      "各層でフィルタサイズをランダムに変化させる",
      "深くなるにつれてチャネル数を減らす"
    ],
    "exp": "DenseNetは、Dense Block内で前方にあるすべての層の出力をチャネル方向（axis=1等）に結合して再利用するのが特徴です。"
  },
  {
    "sid": 13,
    "q": "SENet（Squeeze-and-Excitation Networks）が導入した、チャネル間の重要度を重み付けする機構を何と呼ぶか。",
    "a": [
      "Attention",
      "Dropout",
      "Normalization",
      "Pruning"
    ],
    "exp": "SENetは、特徴マップのチャネルごとの重要度を学習し、適応的に重み付けを行うAttentionメカニズムの一種を導入しました。"
  },
  {
    "sid": 13,
    "q": "物体検出における「IoU (Intersection over Union)」の説明として正しいものはどれか。",
    "a": [
      "予測領域と正解領域の重なり具合を示す指標",
      "検出された物体のクラス分類精度",
      "ニューラルネットワークの層の深さ",
      "学習率の減衰率"
    ],
    "exp": "IoUは、予測したバウンディングボックスと正解のボックスの「和集合に対する積集合の面積比」で、重なり具合を0〜1で表します。"
  },
  {
    "sid": 13,
    "q": "YOLO (You Only Look Once) の特徴として最も適切なものはどれか。",
    "a": [
      "画像をグリッドに分割し、End-to-Endで物体検出を行う",
      "候補領域を抽出してから、各領域を分類する（2段階）",
      "ピクセル単位でクラス分類を行う",
      "動画専用のアルゴリズムである"
    ],
    "exp": "YOLOは、領域提案とクラス分類を1つのネットワークで同時に行う（1段階）ことで、高速な処理を実現しています。"
  },
  {
    "sid": 13,
    "q": "R-CNN系の手法において、可変長の領域特徴マップを固定長に変換するために用いられる層は何か。",
    "a": [
      "RoI Pooling",
      "Max Pooling",
      "Global Average Pooling",
      "Batch Normalization"
    ],
    "exp": "RoI (Region of Interest) Poolingは、様々なサイズの候補領域を固定サイズのマップに変換し、全結合層に入力できるようにします。"
  },
  {
    "sid": 13,
    "q": "画像認識におけるData Augmentationの手法のうち、画像の一部を矩形で切り取ってマスクする（0埋めなどにする）手法はどれか。",
    "a": [
      "Cutout",
      "Mixup",
      "Random Erasing",
      "CutMix"
    ],
    "exp": "Cutoutは画像の一部をマスクする手法です。Random Erasingも類似していますが、画素値をランダム値や平均値で埋めるなどのバリエーションがあります。（選択肢的にCutoutが最も単純な定義に合致します）"
  },
  {
    "sid": 13,
    "q": "学習済みのモデル（例：ImageNetで学習したResNet）の重みを初期値として、別のタスクのために再学習することを何と呼ぶか。",
    "a": [
      "ファインチューニング",
      "蒸留",
      "事前学習",
      "正則化"
    ],
    "exp": "ファインチューニング（微調整）は、学習済みモデルの一部または全体の重みを、新しいデータセットで再学習させて最適化する手法です。"
  },
  {
    "sid": 13,
    "q": "入力画像サイズが224x224、RGBの3チャネルである場合、入力データのテンソル形状（Batch, Channel, Height, Width）は通常どう表されるか。",
    "a": [
      "(N, 3, 224, 224)",
      "(N, 224, 224, 3)",
      "(3, 224, 224, N)",
      "(224, 224, 3, N)"
    ],
    "exp": "PyTorchなどの多くのフレームワークでは(Batch, Channel, Height, Width)の順序が一般的です。TensorFlowなどでは(N, H, W, C)の場合もありますが、E資格ではNCHW形式がよく問われます。"
  },
  {
    "sid": 13,
    "q": "Local Response Normalization (LRN) はどのモデルで特徴的に使用されたか。",
    "a": [
      "AlexNet",
      "VGG",
      "ResNet",
      "MobileNet"
    ],
    "exp": "LRNはAlexNetで使用された正規化手法です。側方抑制の考え方を取り入れたものですが、現在ではBatch Normalizationの方が主流です。"
  },
  {
    "sid": 13,
    "q": "バッチ正規化（Batch Normalization）の効果として、適切でないものはどれか。",
    "a": [
      "モデルの表現力が下がり、過学習しやすくなる",
      "学習率を大きく設定でき、学習が速くなる",
      "重みの初期値依存性を軽減する",
      "過学習を抑制する効果がある"
    ],
    "exp": "バッチ正規化は学習を安定させ、過学習を抑制する正則化効果もあるため、表現力が下がって過学習しやすくなるという記述は誤りです。"
  },
  {
    "sid": 13,
    "q": 'im2col（画像を行列に展開する関数）の出力形状として正しいのは？（N:バッチ, C:ch, H,W:サイズ, FH,FW:フィルタ）<br><span style="font-family:monospace; background:#333; padding:2px;">col = im2col(input_data, FH, FW, ...)<br># col.shape = [ ? ]</span>',
    "a": ['(N*H_out*W_out, C*FH*FW)', '(N, C, H, W)', '(C*FH*FW, N*H_out*W_out)', '(N, C*FH*FW)'],
    "exp": 'im2colは、フィルタ適用領域を1行に展開するため、行数が「N×出力画素数」、列数が「フィルタの要素数」の2次元配列になります。'
  },
  {
    "sid": 13,
    "q": '2次元畳み込み層の定義。入力ch=3, 出力ch=16, フィルタサイズ3x3の場合。<br><span style="font-family:monospace; background:#333; padding:2px;">nn.Conv2d(3, 16, [ ? ])</span>',
    "a": ['kernel_size=3', 'filter_size=3', 'size=3', 'window=3'],
    "exp": 'フィルタサイズは「kernel_size」引数で指定します。'
  },
  {
    "sid": 13,
    "q": 'Maxプーリング層（2x2）の定義は？<br><span style="font-family:monospace; background:#333; padding:2px;">nn.[ ? ](kernel_size=2)</span>',
    "a": ['MaxPool2d', 'MaxPooling2d', 'Pool2d', 'Max2d'],
    "exp": 'PyTorchのクラス名は「MaxPool2d」です。（KerasのMaxPooling2Dと微妙に違うので注意）'
  },
  {
    "sid": 13,
    "q": 'モデルを「学習モード」に設定するメソッドは？（DropoutやBatchNormの挙動が変わる）<br><span style="font-family:monospace; background:#333; padding:2px;">model.[ ? ]()</span>',
    "a": ['train', 'training', 'fit', 'on'],
    "exp": '「model.train()」で学習モード、「model.eval()」で推論モードになります。'
  },

    // --- 14: 再帰型ニューラルネットワーク (RNN) ---
  {
    "sid": 14,
    "q": 'RNNのBPTTとは？',
    "a": ['時間方向に展開した誤差逆伝播', 'バッチ正規化', '事前学習', 'プーリング'],
    "exp": 'Backpropagation Through Timeの略です。'
  },
  {
    "sid": 14,
    "q": 'LSTMの「忘却ゲート」は何をする？',
    "a": ['記憶セルの情報をどれだけ残すか決める', '新しい入力を無視する', '出力を0にする', '勾配をリセットする'],
    "exp": '不要になった過去の記憶を消去する役割を持ちます。'
  },
  {
    "sid": 14,
    "q": "RNN（Recurrent Neural Network）の中間層の出力 $h_t$ を計算する式として、最も適切なものはどれか。ただし、$x_t$ は入力、$W, U$ は重み行列、$b$ はバイアス、$\\sigma$ は活性化関数とする。",
    "a": [
      "$h_t = \\sigma(W x_t + U h_{t-1} + b)$",
      "$h_t = \\sigma(W x_t + U h_{t+1} + b)$",
      "$h_t = \\sigma(W x_t + b)$",
      "$h_t = \\text{softmax}(W x_t + U h_{t-1} + b)$"
    ],
    "exp": "RNNは前時刻の中間層の状態 $h_{t-1}$ を現在の入力 $x_t$ と合わせて計算に用いることで、時間的な文脈を学習します。"
  },
  {
    "sid": 14,
    "q": "RNNの学習において用いられる、時間を遡って誤差を伝播させるアルゴリズムの名称はどれか。",
    "a": [
      "BPTT (Backpropagation Through Time)",
      "SGD (Stochastic Gradient Descent)",
      "Adam (Adaptive Moment Estimation)",
      "Dropout"
    ],
    "exp": "BPTTは、RNNを展開して通常の誤差逆伝播法を適用する手法であり、時間方向への勾配を計算します。"
  },
  {
    "sid": 14,
    "q": "単純なRNNにおいて、長い時系列データを学習する際に発生しやすい、勾配が指数関数的に小さくなり学習が進まなくなる問題を何と呼ぶか。",
    "a": [
      "勾配消失問題",
      "勾配爆発問題",
      "過学習",
      "次元の呪い"
    ],
    "exp": "層が深くなる（時間が長くなる）につれ、誤差逆伝播の際に微係数の積が繰り返され、勾配が0に近づいてしまう現象です。"
  },
  {
    "sid": 14,
    "q": "勾配爆発（Gradient Exploding）への対抗策として用いられる、勾配のノルムが閾値を超えた場合に修正を行う手法はどれか。",
    "a": [
      "Gradient Clipping",
      "Batch Normalization",
      "Weight Decay",
      "Early Stopping"
    ],
    "exp": "Gradient Clippingは、勾配のノルムが閾値を超えた場合、閾値に収まるように勾配ベクトルをスケーリングする手法です。"
  },
  {
    "sid": 14,
    "q": "LSTM（Long Short-Term Memory）において、勾配消失問題に対処するために導入された、誤差を減衰させずに伝播させる中心的な機構はどれか。",
    "a": [
      "CEC (Constant Error Carousel)",
      "Forget Gate",
      "Input Gate",
      "Output Gate"
    ],
    "exp": "CECは記憶セル内で勾配を1のまま保つ役割を果たし、長期的な依存関係の学習を可能にします。"
  },
  {
    "sid": 14,
    "q": "LSTMの「忘却ゲート（Forget Gate）」の役割として正しい記述はどれか。",
    "a": [
      "前回の記憶セル $c_{t-1}$ の情報をどれだけ保持するか（あるいは捨てるか）を決定する",
      "新しい入力 $x_t$ をどれだけ記憶セルに追加するかを決定する",
      "現在の記憶セル $c_t$ の値をどれだけ隠れ状態 $h_t$ として出力するかを決定する",
      "過去の隠れ状態 $h_{t-1}$ をリセットする"
    ],
    "exp": "忘却ゲートはシグモイド関数を用いて、過去の記憶セルの情報をどの程度残すかを0から1の間で調整します。"
  },
  {
    "sid": 14,
    "q": "LSTMのゲート制御において、一般的に使用される活性化関数はどれか。",
    "a": [
      "シグモイド関数",
      "ReLU関数",
      "ステップ関数",
      "恒等写像"
    ],
    "exp": "ゲートは情報の通過率（0〜1）を表すため、出力範囲が(0, 1)であるシグモイド関数が使用されます。"
  },
  {
    "sid": 14,
    "q": "GRU（Gated Recurrent Unit）の特徴として正しいものはどれか。",
    "a": [
      "LSTMよりパラメータ数が少なく、計算コストが低い",
      "LSTMよりパラメータ数が多く、表現力が高い",
      "記憶セル（Cell State）と隠れ状態（Hidden State）が独立して存在する",
      "ゲートが存在せず、単純なRNNと同じ構造である"
    ],
    "exp": "GRUはLSTMを簡略化したモデルで、リセットゲートと更新ゲートの2つを持ち、記憶セルを持たず隠れ状態のみで情報を伝達します。"
  },
  {
    "sid": 14,
    "q": "GRUにおいて、過去の隠れ状態をどれだけ無視するかを制御するゲートはどれか。",
    "a": [
      "リセットゲート",
      "更新ゲート",
      "忘却ゲート",
      "出力ゲート"
    ],
    "exp": "リセットゲートは、新しい候補隠れ状態を計算する際に、過去の隠れ状態をどれだけ利用するかを制御します。"
  },
  {
    "sid": 14,
    "q": "Bidirectional RNN（双方向RNN）の説明として適切なものはどれか。",
    "a": [
      "過去から未来への順方向と、未来から過去への逆方向の両方の情報を用いて学習する",
      "入力層と出力層の間で双方向に信号が流れる",
      "エンコーダとデコーダを双方向に接続する",
      "2つのRNNを並列に並べ、平均を取る"
    ],
    "exp": "双方向RNNは、文章の前後関係など、過去と未来の両方のコンテキストを考慮したい場合に有効です。"
  },
  {
    "sid": 14,
    "q": "Seq2Seq（Sequence-to-Sequence）モデルの基本構造として正しい組み合わせはどれか。",
    "a": [
      "Encoder-Decoder",
      "Generator-Discriminator",
      "Actor-Critic",
      "Convolution-Pooling"
    ],
    "exp": "Seq2Seqは、入力系列を固定長ベクトルに変換するEncoderと、そこから出力系列を生成するDecoderで構成されます。"
  },
  {
    "sid": 14,
    "q": "Seq2Seqにおける「Encoder」の最終的な役割は何か。",
    "a": [
      "入力系列の意味を集約した固定長の文脈ベクトル（Context Vector）を作成する",
      "入力系列をそのままDecoderにコピーする",
      "各時刻の出力を確率分布として出力する",
      "入力画像の主な特徴を抽出する"
    ],
    "exp": "Encoderの最後の隠れ状態（またはその変換）が、入力系列全体の情報を圧縮した文脈ベクトルとしてDecoderに渡されます。"
  },
  {
    "sid": 14,
    "q": "従来のSeq2Seqモデルが抱えていた「ボトルネック問題」とは何か。",
    "a": [
      "入力文が長くなると、固定長のベクトルに情報を圧縮しきれなくなる",
      "層を深くしすぎると勾配が消失する",
      "計算量が多すぎて学習が終わらない",
      "語彙数が増えるとソフトマックス関数の計算が遅くなる"
    ],
    "exp": "固定長の文脈ベクトルですべての情報を表現しようとするため、長い文章では初期の情報が失われやすくなります。"
  },
  {
    "sid": 14,
    "q": "Seq2Seqのボトルネック問題を解決するために導入された、Decoderが各時刻でEncoderの「どこに注目すべきか」を学習する機構はどれか。",
    "a": [
      "Attention（注意機構）",
      "Padding",
      "Dropout",
      "Batch Normalization"
    ],
    "exp": "Attentionは、Decoderの各ステップにおいて、Encoderの各隠れ状態の重み付き和（文脈ベクトル）を動的に計算します。"
  },
  {
    "sid": 14,
    "q": "Attention機構において、Encoderの各隠れ状態 $h_s$ とDecoderの隠れ状態 $h_t$ の関連度を表すスコアを計算した後、重み（Attention Weight）を得るために適用する関数はどれか。",
    "a": [
      "Softmax関数",
      "Sigmoid関数",
      "ReLU関数",
      "Tanh関数"
    ],
    "exp": "スコアを確率分布（総和が1）に変換するためにSoftmax関数を適用し、どの隠れ状態を重視するかを決定します。"
  },
  {
    "sid": 14,
    "q": "RNNを用いた言語モデルの評価指標としてよく用いられる「Perplexity」の説明として正しいものはどれか。",
    "a": [
      "確率の逆数であり、値が小さいほど性能が良い",
      "正解率であり、値が大きいほど性能が良い",
      "二乗誤差であり、値が小さいほど性能が良い",
      "BLEUスコアと同じ意味である"
    ],
    "exp": "Perplexity（混迷度）は、次に出現する単語の分岐数（選択肢の数）の平均と解釈でき、小さいほど予測の確信度が高いことを示します。"
  },
  {
    "sid": 14,
    "q": "RNNの学習時に、前の時刻の「モデルの予測出力」ではなく「正解データ（Ground Truth）」を次の時刻の入力として用いる手法を何と呼ぶか。",
    "a": [
      "Teacher Forcing（教師強制）",
      "Early Stopping",
      "Data Augmentation",
      "Fine-tuning"
    ],
    "exp": "学習の初期段階など、モデルの予測が不安定な場合に、正解を与えることで学習を安定・高速化させる手法です。"
  },
  {
    "sid": 14,
    "q": "LSTMの入力ゲート $i_t$ の計算式として正しい形はどれか（$W, U, b$はパラメータ、$\\sigma$はシグモイド関数）。",
    "a": [
      "$i_t = \\sigma(W_i x_t + U_i h_{t-1} + b_i)$",
      "$i_t = \\tanh(W_i x_t + U_i h_{t-1} + b_i)$",
      "$i_t = \\text{ReLU}(W_i x_t + U_i h_{t-1} + b_i)$",
      "$i_t = W_i x_t + U_i h_{t-1} + b_i$"
    ],
    "exp": "入力ゲートは情報の取り込み具合を0〜1で制御するため、シグモイド関数が使用されます。"
  },
  {
    "sid": 14,
    "q": "長い時系列データを扱う際、計算リソースの制限や勾配消失を防ぐために、時系列を適当な長さで打ち切ってBPTTを行う手法はどれか。",
    "a": [
      "Truncated BPTT",
      "Full BPTT",
      "Mini-batch SGD",
      "Online Learning"
    ],
    "exp": "Truncated BPTTでは、逆伝播のつながりをある一定の長さ（ブロック）で断ち切りますが、順伝播の隠れ状態は次のブロックへ継承されます。"
  },
  {
    "sid": 14,
    "q": "可変長の系列データをミニバッチ学習する際、長さを揃えるために短い系列の末尾などに特別な値を埋める処理を何というか。",
    "a": [
      "Padding",
      "Clipping",
      "Masking",
      "Pooling"
    ],
    "exp": "バッチ内の行列サイズを固定するため、最大長に合わせて0などのパディング文字で埋める処理を行います。"
  },
  {
    "sid": 14,
    "q": "機械翻訳の評価指標として用いられる「BLEUスコア」の特徴はどれか。",
    "a": [
      "生成文と参照文のn-gramの一致率に基づく",
      "生成文の意味的な類似度をベクトルで計算する",
      "人間による主観評価の平均値である",
      "文字単位の編集距離に基づく"
    ],
    "exp": "BLEUは、機械翻訳の出力が正解文（参照訳）とどの程度n-gram（単語の並び）を含んでいるかを評価する指標です。"
  },
  {
    "sid": 14,
    "q": "画像キャプション生成（Image Captioning）において、画像の情報を抽出するために一般的に用いられるネットワークはどれか。",
    "a": [
      "CNN (Convolutional Neural Network)",
      "RNN (Recurrent Neural Network)",
      "GAN (Generative Adversarial Network)",
      "Autoencoder"
    ],
    "exp": "EncoderとしてCNNを用いて画像の特徴ベクトルを抽出し、DecoderであるRNNに入力して説明文を生成します。"
  },
  {
    "sid": 14,
    "q": "RNNにおいて、重み行列を初期化する際、勾配消失や爆発を抑制するために有効とされる直交行列などを用いた初期化手法に関連が深い行列はどれか。",
    "a": [
      "単位行列（Identity Matrix）",
      "ゼロ行列",
      "全要素が1の行列",
      "ランダムな対角行列"
    ],
    "exp": "特にReLUなどを用いるRNNにおいて、重みを単位行列（またはそれに近い直交行列）で初期化することは、長期依存性の学習に有効な場合があります（IRNNなど）。"
  },
  {
    "sid": 14,
    "q": "LSTMの出力ゲート $o_t$ が制御しているものは何か。",
    "a": [
      "現在のメモリセル $c_t$ の内容に $\\tanh$ を適用した値を、隠れ状態 $h_t$ としてどれだけ出力するか",
      "入力 $x_t$ をどれだけメモリセル $c_t$ に反映するか",
      "前回の隠れ状態 $h_{t-1}$ をどれだけ忘れるか",
      "勾配をどれだけクリッピングするか"
    ],
    "exp": "出力ゲートは、更新された内部記憶 $c_t$ をもとに、その時刻の最終的な出力（隠れ状態）を決定します。"
  },
  {
    "sid": 14,
    "q": "自然言語処理における「分散表現（Word Embedding）」の説明として正しいものはどれか。",
    "a": [
      "単語を固定長の密な実数ベクトルで表現し、意味的な関係性をベクトル空間上の距離や方向で捉える",
      "単語を辞書のID（インデックス）で表現する（One-hotベクトル）",
      "単語の出現頻度をカウントして表現する",
      "文法的な役割（品詞など）のみを数値化する"
    ],
    "exp": "RNNへの入力として、One-hot表現よりも次元数が低く意味情報を含む分散表現（Word2Vecなど）がよく用いられます。"
  },
  {
    "sid": 14,
    "q": "Attention機構における「Global Attention」と「Local Attention」の違いについて、正しい記述はどれか。",
    "a": [
      "GlobalはEncoderの全隠れ状態を参照するが、Localは一部の隠れ状態のみを参照する",
      "Globalは画像処理用で、Localは自然言語処理用である",
      "Globalは双方向RNNを使用し、Localは単方向RNNを使用する",
      "GlobalはSoftmaxを使い、LocalはSigmoidを使う"
    ],
    "exp": "Global Attentionは計算コストが高い反面、文全体を見渡せます。Local Attentionは計算効率を重視し、注目点の周辺のみを参照します。"
  },
  {
    "sid": 14,
    "q": "LSTMのCEC（Constant Error Carousel）は、どのゲートの働きによって「記憶の書き換え（リセット）」が行われるか。",
    "a": [
      "忘却ゲート（Forget Gate）",
      "入力ゲート（Input Gate）",
      "出力ゲート（Output Gate）",
      "更新ゲート（Update Gate）"
    ],
    "exp": "元々のCECはリセット機能がありませんでしたが、忘却ゲートの導入によって、不要になった記憶を消去（値を小さく）できるようになりました。"
  },
  {
    "sid": 14,
    "q": "「Peepfile Connections（覗き穴結合）」を持つLSTMの特徴はどれか。",
    "a": [
      "各ゲートの制御に、現在の記憶セル $c_{t-1}$ や $c_t$ の値も直接入力として使用する",
      "隣接する層のLSTMセル同士を直接結合する",
      "EncoderとDecoderを直接結合する",
      "隠れ状態を出力せずに直接記憶セルを出力する"
    ],
    "exp": "通常のLSTMはゲート制御に$h_{t-1}$と$x_t$を使いますが、Peepfileはセル状態$c$自体もゲートの開閉判断に使います。"
  },
  {
    "sid": 14,
    "q": "ディープラーニングのフレームワークでRNNを実装する際、可変長の入力系列において、パディング部分の計算を無効化（無視）するために使用する仕組みはどれか。",
    "a": [
      "Masking",
      "Dropping",
      "Skipping",
      "Pruning"
    ],
    "exp": "Maskingを使用することで、パディング（埋め草）部分が損失関数の計算や学習に影響を与えないように制御します。"
  },
  {
    "sid": 14,
    "q": "リカレントニューラルネットワークにおいて、時刻 $t$ における隠れ状態 $h_t$ の次元数が $D$、入力 $x_t$ の次元数が $M$ の場合、重み行列 $W$（入力から隠れ層へ）の形状（Shape）はどうなるか。バイアスは除く。",
    "a": [
      "$D \\times M$ （または $M \\times D$、実装による）",
      "$D \\times D$",
      "$M \\times M$",
      "$D \\times (D+M)$"
    ],
    "exp": "入力ベクトル（次元$M$）を隠れ層の次元（次元$D$）に変換するため、重み行列は$D \\times M$（あるいは転置の$M \\times D$）のサイズになります。"
  },
  {
    "sid": 14,
    "q": 'RNNの順伝播計算。次時刻の隠れ状態 h_next の計算式は？<br><span style="font-family:monospace; background:#333; padding:2px;">h_next = np.tanh(np.dot(x, Wx) + [ ? ] + b)</span>',
    "a": ['np.dot(h_prev, Wh)', 'h_prev * Wh', 'np.dot(h_next, Wh)', 'np.dot(x, Wh)'],
    "exp": 'RNNは「現在の入力(x)」と「1つ前の隠れ状態(h_prev)」を用いて次の状態を計算します。'
  },
  {
    "sid": 14,
    "q": 'LSTMのゲート計算には通常どの活性化関数が使われるか？（コード内 `f` の部分）<br><span style="font-family:monospace; background:#333; padding:2px;">gate = f(np.dot(x, Wx) + np.dot(h, Wh) + b)</span>',
    "a": ['sigmoid', 'tanh', 'relu', 'softmax'],
    "exp": 'ゲートは情報を「通す(1)か通さない(0)か」を制御するため、0~1を出力するシグモイド関数が使われます。'
  },
  {
    "sid": 14,
    "q": 'LSTM層の定義。batch_first=Trueにする理由は？<br><span style="font-family:monospace; background:#333; padding:2px;">nn.LSTM(input_size, hidden_size, batch_first=True)</span>',
    "a": ['入力を (Batch, Seq, Feature) の順にするため', '入力を (Seq, Batch, Feature) の順にするため', 'バッチ正規化を適用するため', '計算を高速化するため'],
    "exp": 'PyTorchのRNNはデフォルトで (Seq, Batch, Feature) ですが、batch_first=True にすると一般的な (Batch, Seq, Feature) で扱えます。'
  },
  {
    "sid": 14,
    "q": '単語IDを密なベクトルに変換する「Embedding層」の定義は？（語彙数10000、次元数256）<br><span style="font-family:monospace; background:#333; padding:2px;">nn.[ ? ](10000, 256)</span>',
    "a": ['Embedding', 'Word2Vec', 'Vector', 'Lookup'],
    "exp": '「nn.Embedding」は、整数の単語IDを受け取り、対応するベクトルを返す層です。'
  },

    // --- 15: 深層学習を用いた自然言語処理 ---
  {
    "sid": 15,
    "q": 'BERTの事前学習タスクは？',
    "a": ['Masked LM', '翻訳', '画像分類', '要約'],
    "exp": '穴埋め問題を解くことで文脈を理解します。'
  },
  {
    "sid": 15,
    "q": 'TransformerにおけるSelf-Attentionの計算に必要な3つの要素は？',
    "a": ['Query, Key, Value', 'Input, Output, Hidden', 'Forget, Input, Output', 'Encoder, Decoder, Context'],
    "exp": '検索クエリ(Q)とキー(K)の類似度でバリュー(V)を重み付けします。'
  },
  {
    "sid": 15,
    "q": "自然言語処理における『One-hotベクトル』の欠点として、最も適切な記述はどれか。",
    "a": [
      "単語間の意味的な類似性を表現できず、次元数が語彙数に依存して巨大になる。",
      "頻出単語のベクトルが大きくなりすぎ、勾配爆発を引き起こす。",
      "文脈情報を過剰に含んでしまうため、特定タスク以外への汎用性が低い。",
      "計算コストは低いが、未知語（OOV）に対してすべて異なるベクトルを割り当ててしまう。"
    ],
    "exp": "One-hot表現は単語ごとに直交するベクトルを割り当てるため、単語間の類似度（距離）を計算できず、語彙数が増えると次元の呪いの影響を受けます。"
  },
  {
    "sid": 15,
    "q": "Word2Vecの『CBOW（Continuous Bag-of-Words）』モデルの説明として正しいものはどれか。",
    "a": [
      "周辺の文脈（複数の単語）から、中心にあるターゲット単語を予測するモデルである。",
      "中心にある単語から、周辺の文脈単語を予測するモデルである。",
      "文章全体のトピック分布を予測し、それを単語ベクトルとして表現するモデルである。",
      "単語の共起行列を特異値分解（SVD）することで分散表現を得るモデルである。"
    ],
    "exp": "CBOWは『周辺語（文脈）→中心語』を予測します。逆に『中心語→周辺語』を予測するのはSkip-gramです。"
  },
  {
    "sid": 15,
    "q": "Word2Vecの学習において、計算量を削減するために用いられる『ネガティブサンプリング』の説明として正しいものはどれか。",
    "a": [
      "正解の単語と、少数のランダムに選ばれた不正解単語のみを用いて重みを更新する。",
      "頻出単語を確率的に削除して学習データから除外することで、データセットを縮小する。",
      "階層的ソフトマックスを用いて、出力層の計算を2分木の探索問題に置き換える。",
      "勾配が小さいサンプルの学習をスキップすることで、収束を早める手法である。"
    ],
    "exp": "ネガティブサンプリングは、分母の計算量が膨大なソフトマックス関数の代わりに、正例と少数の負例だけでシグモイド関数を用いて近似計算する手法です。"
  },
  {
    "sid": 15,
    "q": "FastTextの特徴として、Word2Vecと比較した際の最大の利点は何か。",
    "a": [
      "単語を文字n-gramの集合として表現するため、未知語や綴りミスに対応しやすい。",
      "文脈を双方向から考慮するため、多義語の意味を文脈に応じて使い分けられる。",
      "Transformer構造を採用しており、長距離の依存関係を捉えることができる。",
      "教師あり学習のみに対応しており、ラベル付きデータが少ない場合に精度が高い。"
    ],
    "exp": "FastTextは単語内部のサブワード（文字n-gram）の情報を利用するため、学習データに含まれない未知語や活用形にも対応可能です。"
  },
  {
    "sid": 15,
    "q": "RNN（Recurrent Neural Network）の学習において用いられる勾配計算アルゴリズムはどれか。",
    "a": [
      "BPTT (Backpropagation Through Time)",
      "Adam (Adaptive Moment Estimation)",
      "SGD (Stochastic Gradient Descent)",
      "Dropout"
    ],
    "exp": "RNNは時間方向に展開したネットワークとみなせるため、時間を遡って誤差逆伝播を行うBPTTが用いられます。"
  },
  {
    "sid": 15,
    "q": "RNNにおいて、長い時系列データを学習する際に勾配が急速に小さくなり、初期の層へ誤差が伝わらなくなる問題を何と呼ぶか。",
    "a": [
      "勾配消失問題",
      "勾配爆発問題",
      "過学習",
      "次元の呪い"
    ],
    "exp": "長期依存関係を学習しようとすると、活性化関数の微分値の連鎖により勾配が0に近づく勾配消失問題が発生します。"
  },
  {
    "sid": 15,
    "q": "LSTM（Long Short-Term Memory）が導入している『CEC（Constant Error Carousel）』の役割として適切なものはどれか。",
    "a": [
      "勾配を1.0としてそのまま過去へ流すことで、勾配消失を防ぐ。",
      "不要な情報を忘れるために、記憶セルの値をリセットする。",
      "入力データを非線形変換し、特徴量を抽出する。",
      "出力ゲートの開閉を制御し、次の層へ渡す情報を決定する。"
    ],
    "exp": "CECは記憶セルにおける情報の保持を担い、誤差逆伝播時に勾配を減衰させずに過去へ伝える役割を持ちます。"
  },
  {
    "sid": 15,
    "q": "GRU（Gated Recurrent Unit）とLSTMを比較した記述として、正しいものはどれか。",
    "a": [
      "GRUはLSTMよりもパラメータ数が少なく、計算コストが低い傾向にある。",
      "GRUは「入力ゲート」「忘却ゲート」「出力ゲート」の3つのゲートを持つ。",
      "GRUはCECを持たないため、LSTMよりも勾配消失問題に弱い。",
      "GRUは自然言語処理には不向きで、主に音声認識で用いられる。"
    ],
    "exp": "GRUはLSTMを簡略化した構造で、更新ゲートとリセットゲートのみを持ち、パラメータ数が少ないのが特徴です。"
  },
  {
    "sid": 15,
    "q": "Seq2Seq（Encoder-Decoder）モデルにおけるEncoderの役割はどれか。",
    "a": [
      "入力系列を固定長のコンテキストベクトルに変換する。",
      "コンテキストベクトルから出力系列を生成する。",
      "入力と出力の間のアライメント（対応関係）を計算する。",
      "入力系列の各単語の重要度（重み）を計算する。"
    ],
    "exp": "Encoderは可変長の入力系列を処理し、その意味情報を固定長のベクトル（コンテキストベクトル/内部状態）に圧縮します。"
  },
  {
    "sid": 15,
    "q": "Seq2Seqモデルに『Attention（注意）機構』を導入する主な目的は何か。",
    "a": [
      "入力文が長くなった際に、固定長ベクトルへの情報圧縮による性能低下を防ぐ。",
      "Decoderの生成速度を向上させるために、並列計算を可能にする。",
      "事前学習済みモデルを利用して、少量のデータでの学習を可能にする。",
      "出力層の活性化関数をSigmoidからSoftmaxに変更し、確率解釈を容易にする。"
    ],
    "exp": "Attentionは、Decoderが各時刻で出力する際に、Encoderの各隠れ状態のどこに注目すべきかを動的に計算し、固定長ベクトルのボトルネックを解消します。"
  },
  {
    "sid": 15,
    "q": "Attentionスコアの計算において、Softmax関数を適用する直前に行う処理として一般的なものはどれか。",
    "a": [
      "クエリ(Query)とキー(Key)の内積（または類似度計算）",
      "クエリ(Query)とバリュー(Value)の加算",
      "キー(Key)とバリュー(Value)の畳み込み演算",
      "隠れ状態ベクトルのL2正規化"
    ],
    "exp": "Attentionスコアは、一般にQueryとKeyの類似度（内積など）によって計算され、それをSoftmaxで正規化して重みとします。"
  },
  {
    "sid": 15,
    "q": "Transformerモデルにおける『Self-Attention』の説明として正しいものはどれか。",
    "a": [
      "同一の入力文内にある単語間の関係性を計算し、文脈表現を獲得する。",
      "入力文と出力文の間の対応関係（アライメント）を学習する。",
      "過去の時刻の隠れ層の状態のみを参照し、未来の情報は見ないようにする。",
      "CNNを用いて局所的な特徴量を抽出する機構である。"
    ],
    "exp": "Self-Attentionは、翻訳元の単語同士（または翻訳先の単語同士）の関連度を計算し、文構造や共参照関係などを捉えます。"
  },
  {
    "sid": 15,
    "q": "Transformerにおいて『Positional Encoding』が必要となる理由は何か。",
    "a": [
      "Transformerは再帰結合や畳み込みを持たず、単語の語順情報を構造的に扱えないため。",
      "単語ベクトルの次元数を削減し、計算効率を上げるため。",
      "Attention機構の重みが発散するのを防ぐための正則化として機能するため。",
      "EncoderとDecoderの間で次元数を合わせる必要があるため。"
    ],
    "exp": "Transformerは並列処理が可能ですが、RNNのように順序情報を暗黙的に保持できないため、明示的に位置情報を埋め込む必要があります。"
  },
  {
    "sid": 15,
    "q": "Transformerの『Scaled Dot-Product Attention』において、内積結果を $\\sqrt{d_k}$ で割る（スケーリングする）理由として正しいものはどれか。",
    "a": [
      "内積の値が大きくなりすぎるとSoftmaxの勾配が極端に小さくなり、学習が停滞するのを防ぐため。",
      "計算結果を0から1の範囲に収め、確率として解釈できるようにするため。",
      "キー(Key)とバリュー(Value)の次元数が異なる場合に、計算を可能にするため。",
      "オーバーフィッティングを防ぐためのドロップアウトの一種として機能させるため。"
    ],
    "exp": "次元数 $d_k$ が大きいと内積和が増大し、Softmaxの微係数が消失する領域に入ってしまうため、スケーリングを行います。"
  },
  {
    "sid": 15,
    "q": "『Multi-Head Attention』の利点として、最も適切な記述はどれか。",
    "a": [
      "複数の異なる部分空間での表現を同時に学習でき、多様な関係性を捉えられる。",
      "単一のAttentionよりも計算コストが低く、メモリ使用量を削減できる。",
      "過去の情報をより長く保持できるため、RNNの代替として優れている。",
      "Decoder側でのマスク処理が不要になり、実装が容易になる。"
    ],
    "exp": "複数のヘッドを持つことで、例えば「誰が」と「誰に」といった異なる種類の依存関係を並列して捉えることが可能になります。"
  },
  {
    "sid": 15,
    "q": "BERT（Bidirectional Encoder Representations from Transformers）のモデル構造の特徴はどれか。",
    "a": [
      "TransformerのEncoder部分を積層した双方向モデルである。",
      "TransformerのDecoder部分を積層した単方向（自己回帰）モデルである。",
      "EncoderとDecoderの両方を使用し、翻訳タスクに特化したモデルである。",
      "LSTMを双方向につなげたBi-LSTMモデルである。"
    ],
    "exp": "BERTはTransformerのEncoderスタックを利用し、文脈を双方向から同時に考慮して深層表現を学習します。"
  },
  {
    "sid": 15,
    "q": "BERTの事前学習タスクの一つである『Masked Language Model (MLM)』の説明として正しいものはどれか。",
    "a": [
      "入力文の一部を隠し（マスクし）、その隠された単語を予測する。",
      "与えられた文の次の文がどれかを予測する。",
      "入力文を別の言語に翻訳し、その精度を最大化する。",
      "文中の単語の品詞を予測する。"
    ],
    "exp": "MLMは入力トークンの約15%を[MASK]などに置き換え、その元の単語を周辺の文脈から予測するタスクです。"
  },
  {
    "sid": 15,
    "q": "BERTの事前学習タスク『Next Sentence Prediction (NSP)』の目的は何か。",
    "a": [
      "2つの文が連続しているかどうかを判定し、文間の関係性を学習する。",
      "文の長さを予測し、生成する文章の長さを制御する。",
      "文法的な誤りを検出し、修正能力を獲得する。",
      "各単語の感情極性（ポジティブ/ネガティブ）を判定する。"
    ],
    "exp": "NSPは、文Aの次に文Bが来る正当なペアか、ランダムに選ばれた無関係なペアかを分類し、文単位の関係性を理解させます。"
  },
  {
    "sid": 15,
    "q": "GPT（Generative Pre-trained Transformer）シリーズのモデル構造の特徴はどれか。",
    "a": [
      "TransformerのDecoder部分を用いた、単方向（自己回帰）モデルである。",
      "TransformerのEncoder部分を用いた、双方向モデルである。",
      "RNNとCNNを組み合わせたハイブリッドモデルである。",
      "Encoder-Decoder構成を持ち、入力と出力を同時に学習する。"
    ],
    "exp": "GPTは文章生成に適したTransformerのDecoderスタックを使用し、前の単語から次の単語を予測する自己回帰モデルです。"
  },
  {
    "sid": 15,
    "q": "ELMo（Embeddings from Language Models）が単語分散表現において革新的だった点は何か。",
    "a": [
      "固定のベクトルではなく、文脈に応じて変化する動的な単語ベクトルを生成した点。",
      "Attention機構のみを用いて、RNNを完全に排除した点。",
      "画像認識の技術を応用し、文字の形状から意味を推測した点。",
      "単語ではなく、文全体のベクトルのみを出力するようにした点。"
    ],
    "exp": "ELMoは双方向LSTM言語モデルの内部状態を利用し、同じ単語でも文脈（使用法）によって異なるベクトルを与えることを可能にしました。"
  },
  {
    "sid": 15,
    "q": "機械翻訳の評価指標として用いられる『BLEUスコア』の説明として正しいものはどれか。",
    "a": [
      "生成文と参照文（正解文）の間で、n-gramがどれだけ一致しているかを測定する指標。",
      "生成された文の流暢さを、言語モデルの確率（Perplexity）で評価する指標。",
      "人間の評価者による主観評価との相関が最も高いとされる意味理解の指標。",
      "誤り訂正の回数（編集距離）に基づいて算出される指標。"
    ],
    "exp": "BLEUは、機械翻訳の結果が参照文とどれくらいn-gramレベルで一致しているかを見る適合率ベースの指標です。"
  },
  {
    "sid": 15,
    "q": "言語モデルの性能評価指標である『Perplexity（パープレキシティ）』に関する記述として正しいものはどれか。",
    "a": [
      "値が小さいほど、言語モデルの予測性能が高い（予測の不確実性が低い）ことを示す。",
      "値が大きいほど、言語モデルの予測性能が高いことを示す。",
      "BLEUスコアと同じ計算式で求められるが、翻訳タスク以外で使われる。",
      "文章の長さには依存せず、常に0から1の間の値をとる。"
    ],
    "exp": "Perplexityは「次にどの単語が出現するか」の分岐数（不確実性）を表す指標であり、値が小さいほど正しく予測できていることを意味します。"
  },
  {
    "sid": 15,
    "q": "Seq2Seqモデルの学習時における『Teacher Forcing』とはどのような手法か。",
    "a": [
      "Decoderの入力として、一つ前の時刻の『モデルの出力』ではなく『正解データ』を与える。",
      "Encoderの重みを固定し、Decoderのみを学習させる。",
      "学習率を教師データ（Loss）の減り具合に応じて動的に変化させる。",
      "間違った予測をした場合に、より大きなペナルティ（重み）を与える。"
    ],
    "exp": "学習初期などモデルの出力が不安定な時期に、自身の出力ではなく正解ラベルを次時刻の入力とすることで学習を安定・高速化させます。"
  },
  {
    "sid": 15,
    "q": "文章生成時のデコーディング手法である『ビームサーチ（Beam Search）』の説明として正しいものはどれか。",
    "a": [
      "各ステップで確率の高い上位k個の候補を保持しながら探索を進める。",
      "常に確率が最も高い1つの単語だけを選んで生成を進める（Greedy探索）。",
      "確率分布に基づいてランダムに単語をサンプリングする。",
      "全ての可能な単語の組み合わせを計算し、最も確率が高い文を選ぶ。"
    ],
    "exp": "Greedy探索は局所最適に陥りやすいため、ビーム幅k個の候補を保持し続けることで、より大域的に尤もらしい文を生成しようとします。"
  },
  {
    "sid": 15,
    "q": "自然言語処理における『トークン化（Tokenization）』において、BPE (Byte Pair Encoding) や SentencePiece が解決しようとする課題は何か。",
    "a": [
      "未知語（OOV）問題を緩和し、語彙サイズを適切に抑制すること。",
      "文法的に誤った文章を自動的に修正すること。",
      "同義語を一つのトークンに統一して学習効率を上げること。",
      "ストップワード（「て」「に」「を」「は」など）を自動的に除去すること。"
    ],
    "exp": "サブワード単位（頻出する文字の並び）で分割することで、未知語を既知のサブワードの組み合わせとして表現でき、レア単語への対応力が向上します。"
  },
  {
    "sid": 15,
    "q": "TransformerのDecoderにおける『Masked Multi-Head Attention』のマスク処理の役割は何か。",
    "a": [
      "未来の単語（カンニング）情報を参照しないようにする。",
      "パディング部分（意味のない埋め合わせ）の計算を無視する。",
      "特定の品詞を持つ単語に注意を向けないようにする。",
      "入力文と出力文の長さの違いを吸収する。"
    ],
    "exp": "自己回帰的な生成を行う際、予測すべき位置より後ろにある単語（正解）が見えてしまうと学習にならないため、未来の情報をマスクします。"
  },
  {
    "sid": 15,
    "q": "自然言語処理における『転移学習（Transfer Learning）』の一般的なプロセスとして正しいものはどれか。",
    "a": [
      "大規模データで事前学習を行い、特定タスクのデータでファインチューニングを行う。",
      "特定タスクのデータで学習した後、大規模データで汎化性能を高める。",
      "画像認識モデルの重みを初期値として、言語モデルを学習する。",
      "複数の異なるタスクを同時に学習し、互いの知識を共有させる（マルチタスク学習）。"
    ],
    "exp": "BERTやGPTのように、大量のテキストで言語の一般的知識を事前学習(Pre-training)し、その後解きたいタスクに合わせて微調整(Fine-tuning)するのが主流です。"
  },
  {
    "sid": 15,
    "q": "ニューラル機械翻訳（NMT）以前の統計的機械翻訳（SMT）と比較した際の、NMTの主な利点は何か。",
    "a": [
      "End-to-Endで学習でき、人手による複雑な特徴量設計が不要である。",
      "学習に必要なデータ量が非常に少なく、計算リソースも少なくて済む。",
      "未知語に対する処理が完璧で、辞書が不要である。",
      "翻訳の根拠（なぜその訳になったか）が人間にとって解釈しやすい。"
    ],
    "exp": "SMTは翻訳モデルや言語モデルなどを個別に最適化していましたが、NMTは入力から出力までを単一のネットワークで直接学習（End-to-End）できます。"
  },
  {
    "sid": 15,
    "q": "RNNの勾配爆発対策として用いられる『Gradient Clipping（勾配クリッピング）』の処理内容はどれか。",
    "a": [
      "勾配のノルムが閾値を超えた場合、勾配ベクトルの向きを保ったままノルムを閾値に収める。",
      "勾配が閾値を超えた場合、そのステップの学習をキャンセルする。",
      "勾配が大きすぎる場合、活性化関数をReLUからSigmoidに変更する。",
      "勾配の値を対数変換して小さくする。"
    ],
    "exp": "勾配のL2ノルムが指定した閾値を超えた場合に、スケーリングして閾値以下に抑え込むことで、パラメータの急激な変化を防ぎます。"
  },
  {
    "sid": 15,
    "q": "以下のモデルのうち、Transformerベースではないものはどれか。",
    "a": [
      "ELMo",
      "BERT",
      "GPT-3",
      "T5 (Text-to-Text Transfer Transformer)"
    ],
    "exp": "ELMoは双方向LSTM（RNNの一種）をベースにしたモデルです。他はすべてTransformerアーキテクチャを採用しています。"
  },
  {
    "sid": 15,
    "q": 'nn.CrossEntropyLoss の特徴として正しいものは？<br><span style="font-family:monospace; background:#333; padding:2px;">criterion = nn.CrossEntropyLoss()</span>',
    "a": ['Softmax計算が含まれているため、モデルの出力は生のスコア（logits）でよい', '入力はOne-hotベクトルである必要がある', '回帰問題に使用される', 'Sigmoid計算が含まれている'],
    "exp": 'PyTorchのCrossEntropyLossは、内部で「LogSoftmax」と「NLLLoss」を行うため、モデルの出力層にSoftmaxをかける必要はありません。'
  },

    // --- 16: 深層学習を用いた生成モデル ---
  {
    "sid": 16,
    "q": 'GANのGeneratorが入力として受け取るのは？',
    "a": ['乱数(ノイズ)', '画像', '正解ラベル', '文章'],
    "exp": '潜在空間の点(ノイズ)から画像を生成します。'
  },
  {
    "sid": 16,
    "q": 'VAE(変分オートエンコーダ)の損失関数に含まれる正則化項は？',
    "a": ['KLダイバージェンス', 'L1ノルム', 'L2ノルム', '交差エントロピー'],
    "exp": '潜在変数の分布を標準正規分布に近づけます。'
  },
  {
    "sid": 16,
    "q": "VAE (Variational Autoencoder) において、エンコーダが学習データから推論するパラメータの組み合わせとして正しいものはどれか。",
    "a": [
      "平均ベクトルと分散（または対数分散）ベクトル",
      "共分散行列と相関係数行列",
      "最大値と最小値",
      "尤度関数と事後確率"
    ],
    "exp": "VAEのエンコーダは、潜在変数の確率分布（通常はガウス分布を仮定）のパラメータである平均 $\\mu$ と分散 $\\sigma^2$ を出力します。"
  },
  {
    "sid": 16,
    "q": "VAEの損失関数（変分下界：ELBO）を構成する2つの項の組み合わせとして正しいものはどれか。",
    "a": [
      "再構成誤差（Reconstruction Error）とKLダイバージェンス（正則化項）",
      "敵対的損失（Adversarial Loss）とサイクル一貫性損失",
      "クロスエントロピー誤差とL2正則化項",
      "ヒンジ損失とL1正則化項"
    ],
    "exp": "VAEの損失関数は、入力データを復元できるかどうかの「再構成誤差」と、潜在変数の分布が標準正規分布に近づくようにする「KLダイバージェンス」の和（負のELBOの最小化）で表されます。"
  },
  {
    "sid": 16,
    "q": "VAEにおいて、確率的なサンプリング操作を含みながら誤差逆伝播法を適用するために用いられる手法はどれか。",
    "a": [
      "Reparameterization Trick",
      "Kernel Trick",
      "Vanishing Gradient Trick",
      "Log-Derivative Trick"
    ],
    "exp": "確率変数 $z$ を直接サンプリングすると微分不可能になるため、$z = \\mu + \\sigma \\odot \\epsilon$ （$\\epsilon$は標準正規分布からのノイズ）と置き換える Reparameterization Trick を用います。"
  },
  {
    "sid": 16,
    "q": "GAN (Generative Adversarial Networks) の基本的な構造において、Generator（生成器）の役割として適切なものはどれか。",
    "a": [
      "Discriminatorを騙すようなデータを生成する",
      "入力データが本物か偽物かを識別する",
      "入力データを潜在空間に圧縮する",
      "入力データのノイズを除去する"
    ],
    "exp": "Generatorは、Discriminatorが「本物」と誤認するような偽データを生成するように学習します。"
  },
  {
    "sid": 16,
    "q": "標準的なGANの目的関数（Minimax Game）において、Discriminator $D$ が最大化しようとする数式の一部として正しいものはどれか。ここで $x$ は実データ、$z$ はノイズである。",
    "a": [
      "$E_{x}[\\log D(x)] + E_{z}[\\log(1 - D(G(z)))]$",
      "$E_{x}[\\log (1-D(x))] + E_{z}[\\log D(G(z))]$",
      "$E_{x}[D(x)] - E_{z}[D(G(z))]$",
      "$E_{x}[\\log D(x)] - E_{z}[\\log D(G(z))]$"
    ],
    "exp": "$D$ は本物 $x$ を正しく判定（$\\log D(x)$ を最大化）し、かつ生成物 $G(z)$ を偽物と判定（$\\log(1 - D(G(z)))$ を最大化）しようとします。"
  },
  {
    "sid": 16,
    "q": "GANの学習において、Generatorが特定の一部のデータしか生成できなくなり、生成画像の多様性が失われる現象を何と呼ぶか。",
    "a": [
      "モード崩壊 (Mode Collapse)",
      "勾配消失 (Vanishing Gradient)",
      "過学習 (Overfitting)",
      "事後崩壊 (Posterior Collapse)"
    ],
    "exp": "GeneratorがDiscriminatorを騙しやすい特定のパターン（モード）のみを生成し続ける状態をモード崩壊と呼びます。"
  },
  {
    "sid": 16,
    "q": "DCGAN (Deep Convolutional GAN) の設計指針として、推奨されていない（避けるべき）事項はどれか。",
    "a": [
      "Generatorの最終層以外で全結合層を使用する",
      "Pooling層の代わりにストライド畳み込みを使用する",
      "GeneratorとDiscriminatorの両方にBatch Normalizationを使用する",
      "Generatorの出力層にTanh関数を使用する"
    ],
    "exp": "DCGANの論文では、全結合層を排除し、代わりにGlobal Average Poolingや畳み込み層のみで構成することが推奨されています。"
  },
  {
    "sid": 16,
    "q": "WGAN (Wasserstein GAN) が導入された主な目的はどれか。",
    "a": [
      "学習の安定化と勾配消失問題の解消",
      "画像生成速度の向上",
      "ラベル付きデータの学習効率化",
      "色の再現性の向上"
    ],
    "exp": "WGANはWasserstein距離（Earth-Mover距離）を導入することで、分布が重なっていない場合でも勾配が発生し、学習が安定するように設計されています。"
  },
  {
    "sid": 16,
    "q": "WGANにおいて、Discriminator（Critic）に課される数学的な制約はどれか。",
    "a": [
      "1-リプシッツ連続性 (1-Lipschitz continuity)",
      "ガウス分布に従うこと",
      "出力が0から1の範囲に収まること",
      "正定値行列であること"
    ],
    "exp": "WGANでは、Wasserstein距離の双対表現を用いるために、Critic関数が1-リプシッツ連続であることを要求します（重みクリッピングやGradient Penaltyで実装）。"
  },
  {
    "sid": 16,
    "q": "条件付きGAN (cGAN) の特徴として正しいものはどれか。",
    "a": [
      "GeneratorとDiscriminatorの両方にラベル情報（条件）を入力する",
      "Generatorのみにラベル情報を入力する",
      "Discriminatorのみにラベル情報を入力する",
      "損失関数にのみラベル情報を含める"
    ],
    "exp": "cGANでは、生成したいクラスのラベルなどを条件 $y$ として、$G$ と $D$ の両方の入力に追加します。"
  },
  {
    "sid": 16,
    "q": "Pix2Pixの特徴的な点として正しいものはどれか。",
    "a": [
      "ペアとなる学習データ（入力画像と正解画像）が必要である",
      "ペアデータなしで画像のスタイル変換が可能である",
      "ノイズ入力のみから画像を生成する",
      "動画生成に特化している"
    ],
    "exp": "Pix2Pixは条件付きGANの一種で、線画と着色画像のような「ペアデータ」を用いて画像変換を学習します。"
  },
  {
    "sid": 16,
    "q": "CycleGANにおいて、変換した画像を元のドメインに戻した際に、元の画像と一致するように課す損失関数を何と呼ぶか。",
    "a": [
      "サイクル一貫性損失 (Cycle Consistency Loss)",
      "知覚的損失 (Perceptual Loss)",
      "スタイル損失 (Style Loss)",
      "ヒンジ損失 (Hinge Loss)"
    ],
    "exp": "$G: X \\to Y$ と $F: Y \\to X$ があるとき、$F(G(x)) \\approx x$ となるように制約するのがサイクル一貫性損失です。これによりペアデータなしでの学習が可能になります。"
  },
  {
    "sid": 16,
    "q": "StyleGANにおいて、画像の「スタイル（画風や大まかな特徴）」を調整するために用いられる正規化手法はどれか。",
    "a": [
      "AdaIN (Adaptive Instance Normalization)",
      "Batch Normalization",
      "Layer Normalization",
      "Spectral Normalization"
    ],
    "exp": "StyleGANでは、Mapping Networkから得たスタイル情報を、各畳み込み層の後のAdaINを通じて注入します。"
  },
  {
    "sid": 16,
    "q": "Flowベース生成モデル（Flow-based models）の最大の特徴はどれか。",
    "a": [
      "可逆な変換を用い、対数尤度を直接計算・最大化できる",
      "敵対的学習を用いて分布を近似する",
      "変分下界（ELBO）を最大化して近似を行う",
      "拡散過程を用いてノイズを除去する"
    ],
    "exp": "Flowベースモデル（RealNVPやGlowなど）は、可逆関数（全単射）を積み重ねることで、変数変換公式を用いて尤度を厳密に計算できます。"
  },
  {
    "sid": 16,
    "q": "Flowベースモデルにおいて、変数変換による確率密度の変化を計算するために必要な数学的要素はどれか。",
    "a": [
      "ヤコビ行列の行列式 (Jacobian Determinant)",
      "ヘッセ行列 (Hessian Matrix)",
      "フィッシャー情報行列",
      "特異値分解 (SVD)"
    ],
    "exp": "変数変換 $x = f(z)$ を行う際、確率密度の変化を補正するためにヤコビ行列の行列式の絶対値（体積変化率）を計算する必要があります。"
  },
  {
    "sid": 16,
    "q": "拡散モデル (Diffusion Model) の「順方向プロセス (Forward Process)」で行われる操作はどれか。",
    "a": [
      "データに徐々にガウシアンノイズを加えて破壊する",
      "ノイズから徐々にデータ構造を復元する",
      "データを潜在空間へ圧縮する",
      "データの特徴量を抽出する"
    ],
    "exp": "順方向プロセスは、マルコフ連鎖に従ってデータに少しずつノイズを加え、最終的に完全なランダムノイズにする過程です。"
  },
  {
    "sid": 16,
    "q": "DDPM (Denoising Diffusion Probabilistic Models) の学習時における目的は何か。",
    "a": [
      "各ステップで加えられたノイズを予測する",
      "最終的な画像を直接生成する",
      "画像が本物か偽物かを判定する",
      "潜在変数の平均と分散を予測する"
    ],
    "exp": "DDPMでは、ある時刻 $t$ のノイズ画像を入力とし、その画像に加えられたノイズ成分 $\\epsilon$ をニューラルネットワークで予測するように学習します（Denoising Score Matchingとの関連）。"
  },
  {
    "sid": 16,
    "q": "Stable Diffusionなどで用いられる「Latent Diffusion Models」の主な利点はどれか。",
    "a": [
      "ピクセル空間ではなく潜在空間で拡散過程を行うため計算コストが低い",
      "GANベースであるため生成速度が非常に速い",
      "音声データの生成に特化している",
      "教師データなしで学習が可能である"
    ],
    "exp": "高解像度のピクセル空間で拡散モデルを動かすのは計算量が膨大になるため、VAE等で圧縮した低次元の潜在空間（Latent Space）で処理を行うことで効率化しています。"
  },
  {
    "sid": 16,
    "q": "生成モデルの評価指標である Inception Score (IS) が高く評価する画像群の状態はどれか。",
    "a": [
      "各画像のクラス分類確信度が高く、かつ生成されるクラスの多様性が高い",
      "各画像のクラス分類確信度が低く、生成されるクラスが偏っている",
      "実データとのピクセル単位の誤差が小さい",
      "人間が見て本物と区別がつかない"
    ],
    "exp": "ISは、生成画像が「何であるか明確（条件付き確率のエントロピーが低い）」かつ「多様な種類が出ている（周辺分布のエントロピーが高い）」場合に高くなります。"
  },
  {
    "sid": 16,
    "q": "生成モデルの評価指標である FID (Fréchet Inception Distance) の説明として正しいものはどれか。",
    "a": [
      "実画像と生成画像の特徴量の分布間距離を測り、値が小さいほど良い",
      "実画像と生成画像の特徴量の分布間距離を測り、値が大きいほど良い",
      "生成画像の鮮明さを測る指標で、値が大きいほど良い",
      "Discriminatorの損失値そのものであり、0に近いほど良い"
    ],
    "exp": "FIDはInception-v3の中間層の特徴量について、実データと生成データの分布（ガウス分布で近似）の距離を計算します。分布が近い（値が小さい）ほど高品質・高多様性とみなされます。"
  },
  {
    "sid": 16,
    "q": "自己回帰モデル (Autoregressive Models) の例として適切なネットワークはどれか。",
    "a": [
      "PixelCNN",
      "DCGAN",
      "RealNVP",
      "CycleGAN"
    ],
    "exp": "PixelCNNやPixelRNNは、画像のピクセルを1つずつ順番に（条件付き確率の積として）生成する自己回帰モデルです。"
  },
  {
    "sid": 16,
    "q": "VQ-VAE (Vector Quantized VAE) の特徴的な構成要素はどれか。",
    "a": [
      "離散的なコードブック (Codebook) を用いた量子化",
      "連続的なガウス分布による潜在変数",
      "敵対的損失のみによる学習",
      "可逆なFlow層の積層"
    ],
    "exp": "VQ-VAEは、エンコーダの出力を最近傍探索によって離散的なベクトル（コードブック）に置き換える量子化処理を行います。"
  },
  {
    "sid": 16,
    "q": "GANにおける Spectral Normalization の主な役割は何か。",
    "a": [
      "Discriminatorの重み行列のスペクトルノルムを制約し、リプシッツ連続性を保つ",
      "Generatorの出力画像の画素値を0から1に正規化する",
      "学習データの周波数スペクトルを正規化する",
      "潜在変数の分散を正規化してモード崩壊を防ぐ"
    ],
    "exp": "Spectral Normalizationは、各層の重み行列をその最大特異値（スペクトルノルム）で割ることで、Discriminator全体のリップシッツ定数を制御し、学習を安定させます。"
  },
  {
    "sid": 16,
    "q": "BigGANにおいて、生成画像の多様性と品質のトレードオフを調整するために用いられるテクニックはどれか。",
    "a": [
      "Truncation Trick (切断正規分布からのサンプリング)",
      "Label Smoothing",
      "Gradient Penalty",
      "Dropout"
    ],
    "exp": "学習時は標準正規分布を使うが、生成時に0に近い範囲（裾を切断した分布）からサンプリングすることで、多様性は減るが品質（破綻の少なさ）を向上させる手法です。"
  },
  {
    "sid": 16,
    "q": "GLOWモデルで採用されている、1x1畳み込みの役割は何か。",
    "a": [
      "チャネル間の置換（Permutation）を学習可能な形で行う",
      "画像の空間サイズを縮小する",
      "特徴量の次元数を削減する",
      "非線形変換を導入する"
    ],
    "exp": "Flowモデルではチャネルの順序を混ぜる操作が必要ですが、GLOWでは固定のシャッフルではなく、可逆な1x1畳み込みを用いることで、混ぜ方自体を学習可能にしました。"
  },
  {
    "sid": 16,
    "q": "Score-based Generative Models (スコアベース生成モデル) において、ニューラルネットワークが推定する「スコア」とは数学的に何を指すか。",
    "a": [
      "対数確率密度の勾配 $\\nabla_x \\log p(x)$",
      "データの存在確率 $p(x)$ そのもの",
      "Discriminatorの出力値",
      "再構成誤差の大きさ"
    ],
    "exp": "スコアベースモデルは、データ分布の対数尤度の入力データに関する勾配（スコア関数）を推定し、ランジュバン・ダイナミクス等を用いてサンプリングを行います。"
  },
  {
    "sid": 16,
    "q": "条件付き画像生成において、文章（テキスト）から画像を生成するタスク（Text-to-Image）でよく用いられる、テキストと画像の特徴量を結びつけるモデルはどれか。",
    "a": [
      "CLIP (Contrastive Language-Image Pre-training)",
      "BERT",
      "ResNet",
      "Word2Vec"
    ],
    "exp": "CLIPは画像とテキストのペアを対照学習し、両者を同じ特徴空間にマッピングできるため、DALL-E 2やStable DiffusionなどのText-to-Imageモデルのガイド役として重要です。"
  },
  {
    "sid": 16,
    "q": "深層生成モデルにおける「事後崩壊 (Posterior Collapse)」とは、VAEにおいてどのような現象を指すか。",
    "a": [
      "デコーダが強力すぎて潜在変数 $z$ を無視してしまい、情報がエンコードされなくなる",
      "エンコーダの学習が進まず、出力が常に0になる",
      "KLダイバージェンスが無限大に発散する",
      "生成画像がノイズのみになる"
    ],
    "exp": "自己回帰的な強力なデコーダを使う場合などに、デコーダが $z$ を見なくてもデータを復元できてしまい、KL項を0にするために事後分布が事前分布と一致してしまう（$z$ が情報を失う）現象です。"
  },
  {
    "sid": 16,
    "q": "GANの評価指標である Precision and Recall において、Recallが高いがPrecisionが低い状態は何を意味するか。",
    "a": [
      "生成画像の多様性は高いが、品質が低い（低品質な画像も多く含まれる）",
      "生成画像は高品質だが、多様性が低い（モード崩壊）",
      "生成画像は実データと完全に一致している",
      "生成画像が真っ黒になっている"
    ],
    "exp": "Recallは「実データ分布をどれだけカバーしているか（多様性）」、Precisionは「生成データが実データ分布の中にどれだけ入っているか（品質）」を測ります。"
  },
  {
    "sid": 16,
    "q": "StarGANの主な特徴はどれか。",
    "a": [
      "単一のGeneratorで複数のドメイン間の変換が可能である",
      "星空の画像を生成することに特化している",
      "各ドメインペアごとに個別のGeneratorを作成する必要がある",
      "3次元データの生成に特化している"
    ],
    "exp": "CycleGANなどは2つのドメイン間変換に特化していますが、StarGANはドメイン情報を条件として入力することで、1つのモデルで多対多の変換（例：髪色変換、表情変換などを一度に）を可能にしました。"
  },

    // --- 17: 深層学習を用いた強化学習 ---
  {
    "sid": 17,
    "q": 'DQN(Deep Q-Network)で使用される「Experience Replay」の目的は？',
    "a": ['データの相関を断ち切り学習を安定させる', '過去の記憶を忘れる', '探索範囲を広げる', '報酬を正規化する'],
    "exp": '過去の経験をランダムに取り出して学習に使います。'
  },
  {
    "sid": 17,
    "q": 'AlphaGoが利用した探索手法は？',
    "a": ['モンテカルロ木探索(MCTS)', 'A*探索', '幅優先探索', '貪欲法'],
    "exp": 'ニューラルネットワークの評価と木探索を組み合わせました。'
  },
  {
    "sid": 17,
    "q": "強化学習において、エージェントが行動を選択し、環境から報酬と次状態を受け取る一連のプロセスをモデル化したものを何と呼ぶか。",
    "a": [
      "マルコフ決定過程 (MDP)",
      "隠れマルコフモデル (HMM)",
      "ガウス過程 (GP)",
      "自己回帰モデル (AR)"
    ],
    "exp": "強化学習の基礎となる数学的枠組みは、状態、行動、遷移確率、報酬、割引率からなるマルコフ決定過程(MDP)として定義される。"
  },
  {
    "sid": 17,
    "q": "DQN (Deep Q-Network) において、学習データの相関を断ち切り、学習を安定させるために導入された、過去の経験をメモリに保存しランダムに取り出して学習する仕組みはどれか。",
    "a": [
      "Experience Replay",
      "Fixed Target Q-Network",
      "Reward Clipping",
      "Gradient Clipping"
    ],
    "exp": "Experience Replayは、エージェントの経験(状態, 行動, 報酬, 次状態)をバッファに保存し、ランダムサンプリングしてミニバッチ学習を行うことで、データの時系列相関を低減させる。"
  },
  {
    "sid": 17,
    "q": "DQNにおいて、Q値の過大評価（Overestimation）を防ぐために提案された手法で、行動の選択とQ値の評価に使用するネットワークを分離する手法はどれか。",
    "a": [
      "Double DQN",
      "Dueling Network",
      "Categorical DQN",
      "Noisy Network"
    ],
    "exp": "Double DQNは、行動選択を行うネットワーク（メイン）と、その行動の価値を評価するネットワーク（ターゲット）を分けることで、Q値の過大評価を抑制する。"
  },
  {
    "sid": 17,
    "q": "Dueling Networkの構造において、最終的にQ値 Q(s,a) を算出するために足し合わされる2つの出力はどれか。",
    "a": [
      "状態価値関数 V(s) と アドバンテージ関数 A(s,a)",
      "状態価値関数 V(s) と 報酬関数 R(s,a)",
      "行動価値関数 Q(s,a) と 誤差関数 L(s)",
      "ポリシー関数 π(s) と 価値関数 V(s)"
    ],
    "exp": "Dueling Networkは、Q値を状態そのものの価値 V(s) と、各行動の相対的価値であるアドバンテージ A(s,a) に分解して学習する構造を持つ。"
  },
  {
    "sid": 17,
    "q": "強化学習における「探索(Exploration)と活用(Exploitation)のトレードオフ」において、ε-greedy法を用いた場合の説明として正しいものはどれか。",
    "a": [
      "確率εでランダムに行動し、確率1-εで現在最適な行動（greedy）をとる",
      "確率εで現在最適な行動をとり、確率1-εでランダムに行動する",
      "学習初期はεを0にし、徐々にεを1に近づける",
      "常に最もQ値が高い行動のみを選択し、探索は行わない"
    ],
    "exp": "ε-greedy法では、確率εで探索（ランダム行動）を行い、それ以外は活用（現時点の最大Q値の行動）を行う。通常、学習が進むにつれてεを減衰させる。"
  },
  {
    "sid": 17,
    "q": "方策勾配法（Policy Gradient）の基本式において、期待報酬を最大化するためにパラメータを更新する際、勾配にかける項として一般的に用いられるものはどれか。",
    "a": [
      "行動の対数確率の勾配 ∇logπ(a|s) に報酬（またはQ値）を掛けたもの",
      "行動の確率そのものの勾配 ∇π(a|s) に状態価値 V(s) を掛けたもの",
      "Q関数の勾配 ∇Q(s,a) のみ",
      "損失関数の二乗誤差"
    ],
    "exp": "方策勾配定理により、方策の勾配は「行動の対数確率の勾配」に「その行動の結果得られたリターン（Q値など）」を乗じた形の期待値となる。"
  },
  {
    "sid": 17,
    "q": "A3C (Asynchronous Advantage Actor-Critic) の特徴として適切でないものはどれか。",
    "a": [
      "単一のエージェントがExperience Replayを用いて学習する",
      "複数のエージェントが並列に環境と相互作用する",
      "各エージェントが非同期にグローバルネットワークのパラメータを更新する",
      "On-policy（方策オン）型の学習アルゴリズムである"
    ],
    "exp": "A3Cは「複数のエージェント」を並列動作させ、非同期に更新を行う手法であり、DQNのようなExperience Replayは通常使用しない（並列化により相関を断つため）。"
  },
  {
    "sid": 17,
    "q": "強化学習において、学習対象の方策（Behavior Policy）と、評価・改善対象の方策（Target Policy）が異なる学習手法を何と呼ぶか。",
    "a": [
      "Off-policy（方策オフ）学習",
      "On-policy（方策オン）学習",
      "Model-based学習",
      "Supervised学習"
    ],
    "exp": "Off-policy学習は、実際に動いてデータを集める方策と、学習して更新する方策が異なる手法（例：Q-learning, DQN）。Experience Replayが使えるのが利点。"
  },
  {
    "sid": 17,
    "q": "連続値の行動空間（Continuous Action Space）を扱うのに適しており、DQNの考え方をActor-Criticに適用したアルゴリズムはどれか。",
    "a": [
      "DDPG (Deep Deterministic Policy Gradient)",
      "DQN (Deep Q-Network)",
      "SARSA",
      "Tabular Q-Learning"
    ],
    "exp": "DDPGは、DQNのExperience ReplayやTarget Networkのアイデアを取り入れつつ、決定論的方策勾配を用いることで連続値制御を可能にしたActor-Critic手法。"
  },
  {
    "sid": 17,
    "q": "AlphaGo（Lee Sedol版）で使用された「バリューネットワーク（Value Network）」の役割として正しいものはどれか。",
    "a": [
      "現在の盤面の勝率（勝つ確率）を予測する",
      "次の一手の確率分布を出力する",
      "ランダムなプレイアウトを最後まで行って勝敗を決める",
      "相手の棋風を学習して模倣する"
    ],
    "exp": "AlphaGoのバリューネットワークは、ある盤面状態sにおいて、その後の対局で勝つ確率（状態価値 V(s)）を評価するために使われる。"
  },
  {
    "sid": 17,
    "q": "モンテカルロ木探索（MCTS）において、未探索のノードを選択する際に用いられる「UCTS (Upper Confidence Tree Search)」あるいは「PUCT」アルゴリズムが考慮する要素はどれか。",
    "a": [
      "ノードの平均価値（Q値）と訪問回数に基づく探索ボーナス",
      "ノードの深さと分岐係数",
      "割引率γと即時報酬R",
      "ニューラルネットワークの重みのL2ノルム"
    ],
    "exp": "MCTSの選択フェーズでは、有望さ（高いQ値）と不確実性（訪問回数が少ないことによる探索ボーナス）のバランスをとるためにUCB1などのスコアを用いる。"
  },
  {
    "sid": 17,
    "q": "Prioritized Experience Replay (PER) の説明として正しいものはどれか。",
    "a": [
      "TD誤差（予測誤差）が大きい経験ほど優先的にサンプリングして学習する",
      "新しい経験ほど優先的にサンプリングして学習する",
      "報酬が正の経験のみを優先的にサンプリングして学習する",
      "ランダムに選んだ経験に重みを付けて学習する"
    ],
    "exp": "PERは、学習にとって重要度が高い（まだうまく予測できていない＝TD誤差の絶対値が大きい）経験を優先的に再生することで、学習効率を向上させる。"
  },
  {
    "sid": 17,
    "q": "Actor-Criticにおいて、Advantage関数 A(s,a) はどのように定義されるか。ここで V(s) は状態価値関数、Q(s,a) は行動価値関数とする。",
    "a": [
      "A(s,a) = Q(s,a) - V(s)",
      "A(s,a) = V(s) - Q(s,a)",
      "A(s,a) = Q(s,a) / V(s)",
      "A(s,a) = Q(s,a) + V(s)"
    ],
    "exp": "アドバンテージ関数は、特定の行動aを取ることが、その状態sの平均的な価値V(s)に比べてどれだけ良いか（または悪いか）を表すため、Q(s,a) - V(s) で定義される。"
  },
  {
    "sid": 17,
    "q": "Noisy Networks for Explorationの説明として正しいものはどれか。",
    "a": [
      "ニューラルネットワークの重みにノイズを加え、パラメータ空間で探索を行う",
      "入力画像にガウシアンノイズを加えてロバスト性を高める",
      "報酬にランダムなノイズを加えて局所解を回避する",
      "行動選択時に常にランダムな行動を選択する"
    ],
    "exp": "Noisy Networksは、重みパラメータに学習可能なノイズパラメータを持たせることで、ε-greedyのような行動空間での摂動ではなく、パラメータ空間での探索を可能にする。"
  },
  {
    "sid": 17,
    "q": "AlphaGo Zeroが、以前のAlphaGo（Fan/Lee/Master版）と大きく異なる点はどれか。",
    "a": [
      "人間の棋譜データを一切使わず、自己対戦のみで学習した",
      "ポリシーネットワークのみを使用し、バリューネットワークを廃止した",
      "モンテカルロ木探索（MCTS）を使用しなくなった",
      "強化学習を行わず、教師あり学習のみで作成された"
    ],
    "exp": "AlphaGo Zeroの最大の特徴は、人間のドメイン知識（棋譜や定石）を入力せず、ルールのみを与えられた状態からの自己対戦（Self-play）のみで超人的な強さに到達した点である。"
  },
  {
    "sid": 17,
    "q": "Distributional RL（C51など）の基本的な考え方はどれか。",
    "a": [
      "期待値としてのQ値ではなく、報酬の確率分布そのものを学習する",
      "複数のエージェントの報酬を分配する",
      "行動の確率分布をガウス分布に限定する",
      "状態空間を離散的な分布として表現する"
    ],
    "exp": "従来のRLは報酬の期待値（平均）を学習するが、Distributional RLは報酬の分布（確率分布）自体を近似・学習することで、よりリッチな情報を活用し性能を向上させる。"
  },
  {
    "sid": 17,
    "q": "REINFORCEアルゴリズムの欠点として最も適切なものはどれか。",
    "a": [
      "エピソードごとの完了を待つ必要があり、勾配の分散（Variance）が大きい",
      "バイアスが大きすぎて学習が進まない",
      "常に局所解（Local Minima）に陥るため大域的最適解が得られない",
      "連続値行動空間には適用できない"
    ],
    "exp": "REINFORCEはモンテカルロ法ベースの方策勾配法であり、エピソード終了まで待ってリターンを計算するため、サンプリングごとのばらつき（分散）が非常に大きくなり学習が不安定になりやすい。"
  },
  {
    "sid": 17,
    "q": "方策勾配法において、分散を減らすために導入される、行動に依存しない関数 b(s) を何と呼ぶか。（一般に状態価値関数 V(s) が使われる）",
    "a": [
      "ベースライン (Baseline)",
      "クリッピング (Clipping)",
      "正則化項 (Regularization term)",
      "バイアス項 (Bias term)"
    ],
    "exp": "勾配の推定量からベースライン b(s) を引くことで、期待値（勾配の方向）を変えずに分散のみを低減させることができる。"
  },
  {
    "sid": 17,
    "q": "部分観測マルコフ決定過程 (POMDP) において、エージェントが観測できる情報 ot は状態 st とどう異なるか。",
    "a": [
      "ot は st の一部または不完全な情報である",
      "ot は st と完全に等価である",
      "ot は st よりも多くの情報を含んでいる",
      "ot は常にノイズを含まない確定的な値である"
    ],
    "exp": "POMDPでは、エージェントは環境の真の状態 st を直接知ることができず、不完全な情報である観測 ot を通じて意思決定を行う必要がある（例：一人称視点のゲーム）。"
  },
  {
    "sid": 17,
    "q": "モデルベース（Model-based）強化学習における「モデル」とは主に何を指すか。",
    "a": [
      "状態遷移確率 T(s'|s,a) と報酬関数 R(s,a)",
      "ニューラルネットワークの重みパラメータ",
      "エージェントのポリシー（方策）",
      "環境の初期状態分布"
    ],
    "exp": "モデルベースRLにおける「モデル」とは、環境のダイナミクス（ある状態で行動した時に、次はどうなり、報酬はどうなるか）を近似したものを指す。"
  },
  {
    "sid": 17,
    "q": "DQNの損失関数において、誤差が大きい場合に勾配爆発を防ぐために、二乗誤差の代わりに用いられることがある関数はどれか。",
    "a": [
      "Huber Loss (Smooth L1 Loss)",
      "Cross Entropy Loss",
      "Hinge Loss",
      "Kullback-Leibler Divergence"
    ],
    "exp": "Huber Lossは、誤差が小さい時は二乗誤差、大きい時は絶対値誤差のように振る舞うため、外れ値による勾配への過度な影響（勾配爆発）を抑える効果がある。"
  },
  {
    "sid": 17,
    "q": "TRPO (Trust Region Policy Optimization) や PPO (Proximal Policy Optimization) が目的としている主な改良点はどれか。",
    "a": [
      "方策の更新ステップが大きくなりすぎて性能が急激に悪化するのを防ぐ",
      "Q学習における過大評価バイアスを除去する",
      "離散的な状態空間を連続的な表現に変換する",
      "探索のためにランダムなノイズを付加する"
    ],
    "exp": "TRPOやPPOは、方策の更新前後の変化を一定範囲内（信頼領域）に制限することで、学習の崩壊を防ぎ、単調増加的な性能向上を目指す手法である。"
  },
  {
    "sid": 17,
    "q": "逆強化学習 (Inverse Reinforcement Learning) の目的はどれか。",
    "a": [
      "熟練者の行動履歴から、その背後にある報酬関数を推定する",
      "報酬関数から最適な方策を導出する",
      "状態遷移モデルを逆算して過去の状態を推定する",
      "強化学習のエージェントに敵対的な行動を取らせる"
    ],
    "exp": "通常の強化学習が「報酬→方策」を求めるのに対し、逆強化学習は「エキスパートの行動（方策）→報酬関数」を推定する。"
  },
  {
    "sid": 17,
    "q": "Rainbowと呼ばれるDQNの拡張手法の組み合わせに含まれないものはどれか。",
    "a": [
      "A3C (Asynchronous Advantage Actor-Critic)",
      "Double DQN",
      "Dueling Network",
      "Noisy Nets"
    ],
    "exp": "Rainbowは、DQNの拡張であるDouble DQN, Dueling, PER, Multi-step learning, Distributional RL, Noisy Netsなどを統合した手法であり、A3Cは含まれない（A3Cは並列化手法であり、DQN系とは異なる）。"
  },
  {
    "sid": 17,
    "q": "Multi-step Learning（N-step Learning）の利点はどれか。",
    "a": [
      "即時報酬だけでなく数ステップ先の報酬も考慮するため、報酬の伝播が早くなる",
      "計算量がO(1)になり非常に高速である",
      "メモリ使用量が大幅に削減される",
      "モデルのパラメータ数が減る"
    ],
    "exp": "1ステップごとの更新ではなく、Nステップ先までの報酬をまとめて更新ターゲットに使用することで、バイアスと分散のトレードオフを調整し、報酬の伝播を早めて学習を加速させる。"
  },
  {
    "sid": 17,
    "q": "GAIL (Generative Adversarial Imitation Learning) は、どのような技術を模倣学習に応用したものか。",
    "a": [
      "GAN (Generative Adversarial Networks)",
      "VAE (Variational Autoencoder)",
      "LSTM (Long Short-Term Memory)",
      "CNN (Convolutional Neural Networks)"
    ],
    "exp": "GAILはGANの敵対的な学習フレームワークを利用し、エキスパートの行動とエージェントの行動を識別器（Discriminator）に判別させ、エージェントはエキスパートに似るように学習する。"
  },
  {
    "sid": 17,
    "q": "TD誤差 (Temporal Difference Error) δt の定義式として正しいものはどれか。ここで γ は割引率とする。",
    "a": [
      "δt = Rt+1 + γV(St+1) - V(St)",
      "δt = V(St) - Rt+1",
      "δt = Rt+1 + V(St+1)",
      "δt = V(St) - γV(St+1)"
    ],
    "exp": "TD誤差は、「実際に得られた報酬 + 次の状態の価値」と「現在の状態の推定価値」との差分を表す。"
  },
  {
    "sid": 17,
    "q": "スパース報酬（Sparse Reward）環境における問題点として最も適切なものはどれか。",
    "a": [
      "報酬が得られる頻度が極端に低いため、学習の手掛かりが得られず探索が困難になる",
      "報酬が多すぎてエージェントが混乱する",
      "報酬の値が大きすぎて勾配爆発を起こす",
      "計算コストが高くなりすぎる"
    ],
    "exp": "ゴールに到達した時だけ報酬が入るようなスパースな環境では、ランダムな探索で報酬にたどり着く確率が極めて低く、学習が始まらないという問題がある。"
  },
  {
    "sid": 17,
    "q": "AlphaGo Zeroにおいて、自己対戦の各手で探索を行い、その結果得られた訪問回数の分布 π を教師データとして、何を学習させるか。",
    "a": [
      "ポリシーネットワークの出力確率 p",
      "バリューネットワークの出力 v",
      "ゲームのルール",
      "敵対的生成ネットワーク"
    ],
    "exp": "AlphaGo Zeroの損失関数は、勝敗 z とバリュー v の誤差、およびMCTSの探索分布 π とポリシー出力 p の誤差を最小化するように設計されている。"
  },
  {
    "sid": 17,
    "q": "強化学習において、DQNなどのTarget Networkのパラメータ θ_target をメインのパラメータ θ から更新する際、急激な変化を避けるために行われる「Soft Update」の式はどれか。（τは小さな係数）",
    "a": [
      "θ_target ← τθ + (1-τ)θ_target",
      "θ_target ← θ",
      "θ_target ← θ_target + τ∇J(θ)",
      "θ_target ← θ / τ"
    ],
    "exp": "Soft Update（Polyak averaging）は、DDPGなどで用いられ、ターゲットネットワークをメインネットワークの値へ徐々に近づけることで学習を安定させる。"
  },
  {
    "sid": 17,
    "q": 'Q学習の更新式の実装。TD誤差を求めるコードは？<br><span style="font-family:monospace; background:#333; padding:2px;">target = reward + gamma * np.max(next_q)<br>td_error = [ ? ] - current_q</span>',
    "a": ['target', 'reward', 'next_q', 'gamma'],
    "exp": 'TD誤差は「目標値(target)」と「現在の推定値(current_q)」の差です。'
  },
  {
    "sid": 17,
    "q": 'Epsilon-Greedy法の実装。<br><span style="font-family:monospace; background:#333; padding:2px;">if np.random.rand() < epsilon:<br>    action = [ A ]<br>else:<br>    action = [ B ]</span><br>Aに入るのは？',
    "a": ['ランダムに行動選択', 'Q値が最大の行動', 'Q値が最小の行動', '何もしない'],
    "exp": 'ε-Greedy法では、確率εで「探索（ランダム行動）」を行い、それ以外で「活用（最大Q値の行動）」を行います。'
  },

    // --- 18: 開発・運用環境 ---
  {
    "sid": 18,
    "q": 'Dockerコンテナの特徴は？',
    "a": ['軽量で環境依存が少ない', 'OSごと仮想化する', 'GPUが使えない', '起動が遅い'],
    "exp": '開発環境の再現性を高めるためによく使われます。'
  },
  {
    "sid": 18,
    "q": 'エッジコンピューティングにおける「モデルの軽量化」手法でないものは？',
    "a": ['データ拡張', '量子化', '蒸留', 'プルーニング(枝刈り)'],
    "exp": 'データ拡張は精度向上のための手法で、モデルサイズは変わりません。'
  },
  {
    "sid": 18,
    "q": "ニューラルネットワークのモデル軽量化技術の一つである『蒸留（Distillation）』の説明として最も適切なものはどれか。",
    "a": [
      "大規模で高精度な教師モデルの知識を、より小規模な生徒モデルに継承させる手法",
      "モデルの重みパラメータの数値を、32bit浮動小数点から8bit整数などに変換してメモリ量を削減する手法",
      "寄与度の低いニューロンや結合を削除することで、計算量を削減する手法",
      "ネットワーク構造自体を探索アルゴリズムによって自動的に最適化する手法"
    ],
    "exp": "蒸留は、複雑な教師モデル（Teacher）の出力を「ソフトターゲット」として、軽量な生徒モデル（Student）に学習させる手法です。"
  },
  {
    "sid": 18,
    "q": "モデルの軽量化手法である『量子化（Quantization）』において、一般的に発生するトレードオフとして正しいものはどれか。",
    "a": [
      "モデルサイズが縮小し推論速度は向上するが、推論精度が低下する可能性がある",
      "推論精度は向上するが、学習にかかる計算コストが大幅に増加する",
      "モデルサイズは変わらないが、消費電力が大幅に増加する",
      "推論速度は低下するが、モデルの汎化性能が大幅に向上する"
    ],
    "exp": "量子化は表現ビット数を減らすため、メモリ削減と高速化が期待できますが、情報落ちにより精度が低下するリスクがあります。"
  },
  {
    "sid": 18,
    "q": "『プルーニング（枝刈り）』の手法において、特定の構造（フィルタやチャネルごとなど）を単位として削除する手法を何と呼ぶか。",
    "a": [
      "構造的プルーニング（Structured Pruning）",
      "非構造的プルーニング（Unstructured Pruning）",
      "重み量子化（Weight Quantization）",
      "知識蒸留（Knowledge Distillation）"
    ],
    "exp": "構造的プルーニングは、フィルタやチャネル単位で削除するため、専用ハードウェアでなくても高速化の恩恵を受けやすい特徴があります。"
  },
  {
    "sid": 18,
    "q": "知識蒸留において、教師モデルのSoftmax出力の分布を滑らかにし、より多くの情報を生徒モデルに伝えるために調整されるパラメータは何か。",
    "a": [
      "温度（Temperature）",
      "学習率（Learning Rate）",
      "運動量（Momentum）",
      "ドロップアウト率（Dropout Rate）"
    ],
    "exp": "温度パラメータ（T）を高く設定することで、Softmaxの出力分布が平坦化（ソフトターゲット化）され、正解クラス以外の情報も学習しやすくなります。"
  },
  {
    "sid": 18,
    "q": "モデルの推論環境として利用される『エッジコンピューティング』の利点として、誤っているものはどれか。",
    "a": [
      "すべてのデータをクラウドに送信するため、通信帯域を圧迫せずプライバシー保護が不要である",
      "データ発生源の近くで処理を行うため、低遅延（リアルタイム性）が実現できる",
      "クラウドへのデータ転送量を減らせるため、通信コストを削減できる",
      "ネットワークが不安定な環境でも、自律的に動作することが可能である"
    ],
    "exp": "エッジコンピューティングはクラウドにデータを送らずローカルで処理することで、プライバシー保護や通信量削減を実現します。誤答は逆のことを言っています。"
  },
  {
    "sid": 18,
    "q": "ディープラーニングのフレームワーク間でモデルを相互運用するための、標準的なフォーマットはどれか。",
    "a": [
      "ONNX (Open Neural Network Exchange)",
      "HDF5",
      "JSON",
      "Protocol Buffers"
    ],
    "exp": "ONNXは、PyTorchやTensorFlowなどで作成したモデルを、異なるフレームワークや推論エンジンで利用するために策定された共通フォーマットです。"
  },
  {
    "sid": 18,
    "q": "NVIDIA製GPU向けの推論最適化ライブラリであり、レイヤーの統合（Fusion）やカーネルの自動チューニングを行うものはどれか。",
    "a": [
      "TensorRT",
      "CUDA",
      "cuDNN",
      "OpenCL"
    ],
    "exp": "TensorRTは、学習済みモデルをNVIDIA GPU上で高速に推論させるために最適化（量子化、レイヤー統合など）を行うSDKです。"
  },
  {
    "sid": 18,
    "q": "分散学習の手法の一つである『データ並列（Data Parallelism）』の説明として正しいものはどれか。",
    "a": [
      "各ワーカーがモデルの複製を持ち、異なるデータを入力して勾配を計算し、同期して重みを更新する",
      "モデルが巨大で1つのGPUに収まらないため、モデルの層や部分ごとに異なるGPUに配置して学習する",
      "学習データを一箇所に集めず、各デバイスで学習したモデルの更新情報のみをサーバーに送る",
      "ハイパーパラメータの探索を複数のマシンで同時に行い、最も精度の高いモデルを選択する"
    ],
    "exp": "データ並列は、モデル全体を各GPUにコピーし、ミニバッチを分割して並列処理を行う最も一般的な分散学習手法です。"
  },
  {
    "sid": 18,
    "q": "分散学習における『モデル並列（Model Parallelism）』が必要となる主なケースはどれか。",
    "a": [
      "モデルのパラメータ数が非常に多く、単一のGPUメモリに収まりきらない場合",
      "学習データが非常に少なく、過学習を防ぐ必要がある場合",
      "推論速度よりも学習速度の向上を最優先したい場合",
      "GPUを持たず、CPUのみで学習を行う必要がある場合"
    ],
    "exp": "モデル並列は、巨大なモデル（GPT-3など）を分割して複数のGPUに配置する手法です。メモリ制約の解消が主な目的です。"
  },
  {
    "sid": 18,
    "q": "Dockerなどのコンテナ技術に関する説明として、仮想マシン（VM）と比較した際の特徴として正しいものはどれか。",
    "a": [
      "ホストOSのカーネルを共有するため、VMよりも起動が速く軽量である",
      "ハードウェアレベルで仮想化を行うため、VMよりもオーバーヘッドが大きい",
      "異なるOS（例: WindowsとLinux）を、カーネルを含めて完全に分離して動作させる",
      "アプリケーションごとに専用のゲストOSが必要となる"
    ],
    "exp": "コンテナはゲストOSを持たずホストOSのカーネルを共有するため、仮想マシンに比べて軽量で起動が高速です。"
  },
  {
    "sid": 18,
    "q": "Dockerfileにおいて、イメージのビルド時にコマンドを実行（パッケージのインストールなど）するための命令はどれか。",
    "a": [
      "RUN",
      "CMD",
      "ENTRYPOINT",
      "EXPOSE"
    ],
    "exp": "RUNは『ビルド時』に実行され、その結果がイメージにコミットされます。CMDやENTRYPOINTは『コンテナ起動時』に実行されます。"
  },
  {
    "sid": 18,
    "q": "Kubernetesにおいて、デプロイの最小単位であり、1つ以上のコンテナを含むグループを何と呼ぶか。",
    "a": [
      "Pod",
      "Node",
      "Cluster",
      "Service"
    ],
    "exp": "PodはKubernetesにおける最小の実行単位で、密接に関連するコンテナ群（共有ストレージやネットワークを持つ）を管理します。"
  },
  {
    "sid": 18,
    "q": "モバイル端末やIoTデバイスでの推論に特化した、Googleが提供する軽量フレームワークはどれか。",
    "a": [
      "TensorFlow Lite",
      "Keras",
      "Scikit-learn",
      "Chainer"
    ],
    "exp": "TensorFlow Liteは、モバイルや組み込みデバイス向けにモデルを変換・最適化し、低遅延で実行するためのフレームワークです。"
  },
  {
    "sid": 18,
    "q": "Googleが開発した、行列演算に特化したASIC（特定用途向け集積回路）であり、TensorFlowの処理を高速化するハードウェアはどれか。",
    "a": [
      "TPU (Tensor Processing Unit)",
      "FPGA",
      "CPU",
      "GPU"
    ],
    "exp": "TPUはディープラーニング（特にTensorFlow）の行列演算を高速かつ低電力で処理するためにGoogleが独自開発したプロセッサです。"
  },
  {
    "sid": 18,
    "q": "『混合精度学習（Mixed Precision Training）』のメリットとして適切なものはどれか。",
    "a": [
      "FP16とFP32を組み合わせることで、メモリ使用量を削減し計算速度を向上させる",
      "すべての計算を64bit（倍精度）で行うことで、計算誤差を極限まで減らす",
      "整数演算のみを使用することで、GPUを使わずにCPUだけで高速学習を行う",
      "学習率を動的に変更することで、局所解へのトラップを防ぐ"
    ],
    "exp": "混合精度学習は、半精度（FP16）と単精度（FP32）を適材適所で使い分け、精度を維持しつつメモリ節約と高速化を実現します。"
  },
  {
    "sid": 18,
    "q": "モデルの軽量化手法において、重みの値を『0』にすることで結合を無効化する処理はどれに分類されるか。",
    "a": [
      "プルーニング",
      "量子化",
      "蒸留",
      "正規化"
    ],
    "exp": "プルーニング（枝刈り）は、重要度の低い重みを0（削除）にしてスパース（疎）なモデルを作る技術です。"
  },
  {
    "sid": 18,
    "q": "分散学習の同期型パラメータ更新において、全ワーカーの勾配を集約して平均化する際によく用いられる通信アルゴリズムはどれか。",
    "a": [
      "Ring All-Reduce",
      "Map Reduce",
      "Gossip Protocol",
      "Peer-to-Peer"
    ],
    "exp": "Ring All-Reduceは、各GPUが隣のGPUとだけデータをやり取りすることで、通信ボトルネックを解消し効率的に勾配を集約する手法です。"
  },
  {
    "sid": 18,
    "q": "『非構造的プルーニング（Unstructured Pruning）』の欠点として考えられるものはどれか。",
    "a": [
      "重み行列が疎行列（スパース）になるため、一般的なハードウェアでは計算の高速化が得にくい",
      "モデルの精度が構造的プルーニングよりも大幅に低下しやすい",
      "プルーニング後の再学習が不可能になる",
      "モデルのファイルサイズが削減されない"
    ],
    "exp": "非構造的プルーニングはランダムに重みを0にするため、専用のスパース行列演算ライブラリやハードウェアがないと、計算速度の向上に繋がりにくいです。"
  },
  {
    "sid": 18,
    "q": "エッジデバイス向けに設計された、Depthwise Separable Convolution（深さ方向分離畳み込み）を採用して計算量を削減したCNNアーキテクチャはどれか。",
    "a": [
      "MobileNet",
      "ResNet",
      "VGG16",
      "Inception"
    ],
    "exp": "MobileNetは、通常の畳み込みをDepthwiseとPointwiseに分割することで、精度を保ちつつ計算量を大幅に削減したモデルです。"
  },
  {
    "sid": 18,
    "q": "MLOpsにおける『推論サービング』の指標で、単位時間あたりに処理できるリクエスト数を指す用語はどれか。",
    "a": [
      "スループット（Throughput）",
      "レイテンシ（Latency）",
      "ジッター（Jitter）",
      "アベイラビリティ（Availability）"
    ],
    "exp": "スループットは処理量（件数/秒など）を指します。レイテンシは1件あたりの処理時間（遅延）を指します。"
  },
  {
    "sid": 18,
    "q": "機械学習モデルの運用において、時間の経過とともに入力データの分布が学習時と変わってしまい、性能が劣化する現象を何と呼ぶか。",
    "a": [
      "データドリフト（Data Drift）",
      "勾配消失",
      "過学習",
      "コールドスタート"
    ],
    "exp": "データドリフト（またはコンセプトドリフト）は、運用環境のデータ傾向が変化することでモデルの精度が下がる現象で、再学習のトリガーとなります。"
  },
  {
    "sid": 18,
    "q": "FPGA（Field Programmable Gate Array）の特徴として、GPUと比較した場合の利点はどれか。",
    "a": [
      "回路構成を製造後に書き換え可能で、特定の処理に対して低遅延・省電力な回路を実装できる",
      "浮動小数点演算の並列処理性能がGPUよりも圧倒的に高い",
      "汎用的なOSを動作させるのに適しており、Pythonコードをそのまま高速実行できる",
      "大規模なデータセンターでのバッチ学習処理に最も適している"
    ],
    "exp": "FPGAはハードウェア回路をプログラム可能であるため、特定の推論処理専用の回路を組むことで、低遅延かつ省電力な処理が可能です。"
  },
  {
    "sid": 18,
    "q": "『Quantization Aware Training (QAT)』の説明として正しいものはどれか。",
    "a": [
      "学習中に量子化による誤差をシミュレートし、推論時の量子化による精度低下を抑える手法",
      "学習が完了した後に、重みを単純に丸め込んで量子化する手法",
      "量子化のビット数を学習の進捗に合わせて自動的に増減させる手法",
      "量子コンピュータを用いてニューラルネットワークを学習させる手法"
    ],
    "exp": "QAT（量子化あり学習）は、学習時に量子化の影響（ノイズ）を考慮して重みを更新するため、Post-training Quantizationよりも高精度を維持しやすいです。"
  },
  {
    "sid": 18,
    "q": "GPUのアーキテクチャにおいて、多数のコアで同じ命令を異なるデータに対して同時に実行する方式を何と呼ぶか。",
    "a": [
      "SIMD (Single Instruction, Multiple Data)",
      "SISD (Single Instruction, Single Data)",
      "MIMD (Multiple Instruction, Multiple Data)",
      "RISC (Reduced Instruction Set Computer)"
    ],
    "exp": "GPUはSIMD（またはSIMT: Single Instruction, Multiple Threads）アーキテクチャを採用しており、大量のデータを並列処理するのに適しています。"
  },
  {
    "sid": 18,
    "q": "Kubernetesにおいて、コンテナの状態を監視し、指定された数（レプリカ数）のPodが常に稼働するように管理する仕組みはどれか。",
    "a": [
      "ReplicaSet",
      "Container Runtime",
      "Kubelet",
      "Ingress"
    ],
    "exp": "ReplicaSet（またはそれを管理するDeployment）は、Podの複製数を維持し、障害時に自動的に再起動やスケジューリングを行います。"
  },
  {
    "sid": 18,
    "q": "学習時に巨大なバッチサイズを使用したいがGPUメモリが足りない場合、数ステップ分の勾配を蓄積してから重みを更新する手法を何と呼ぶか。",
    "a": [
      "Gradient Accumulation（勾配蓄積）",
      "Gradient Clipping",
      "Batch Normalization",
      "Dropout"
    ],
    "exp": "Gradient Accumulationは、ミニバッチをさらに分割して順次計算し、勾配を足し合わせてから一度に更新することで、擬似的に大きなバッチサイズを実現します。"
  },
  {
    "sid": 18,
    "q": "推論エンジンなどがモデルを最適化する際、頻出する演算パターン（畳み込み＋活性化関数など）を一つの処理にまとめる技術を何と呼ぶか。",
    "a": [
      "レイヤー融合（Layer Fusion）",
      "プルーニング",
      "量子化",
      "正則化"
    ],
    "exp": "レイヤー融合は、メモリアクセスの回数を減らし、計算効率を高めるためのコンパイラ最適化技術の一つです（TensorRTなどで使用）。"
  },
  {
    "sid": 18,
    "q": "Dockerコンテナのライフサイクルにおいて、停止しているコンテナを再開させずに削除するコマンドはどれか。",
    "a": [
      "docker rm",
      "docker rmi",
      "docker stop",
      "docker kill"
    ],
    "exp": "`docker rm`はコンテナを削除します。`docker rmi`はイメージを削除します。"
  },
  {
    "sid": 18,
    "q": "ディープラーニングコンパイラ『TVM』の主な役割として適切なものはどれか。",
    "a": [
      "多様なハードウェアバックエンドに対して、モデルの計算グラフを最適化した機械語コードを生成する",
      "学習データを自動的に拡張し、モデルの精度を向上させる",
      "PythonのコードをC++に変換して、開発の生産性を向上させる",
      "クラウド上のGPUリソースを自動的に確保・解放する"
    ],
    "exp": "TVMは、様々なフレームワークのモデルを、CPU、GPU、FPGAなどの多様なハードウェア向けに最適化・コンパイルするスタックです。"
  },
  {
    "sid": 18,
    "q": "分散学習における『パラメータサーバ方式』の説明として正しいものはどれか。",
    "a": [
      "パラメータを管理する専用のサーバと、計算を行うワーカーに役割を分担する方式",
      "すべてのノードが対等な関係で、相互にパラメータを交換する方式",
      "1つのGPU内ですべてのパラメータ更新を完結させる方式",
      "学習データを分割せず、全てのサーバが全データを保持する方式"
    ],
    "exp": "パラメータサーバ方式は、勾配を集約・更新する役割（サーバ）と、勾配を計算する役割（ワーカー）を分離する、非同期更新にも適した構成です。"
  },
  {
    "sid": 18,
    "q": '学習済みモデルの重み（パラメータ）のみを保存する推奨コードは？<br><span style="font-family:monospace; background:#333; padding:2px;">torch.save(model.[ ? ](), "model.pth")</span>',
    "a": ['state_dict', 'parameters', 'weights', 'get_params'],
    "exp": '「model.state_dict()」は、パラメータ名とTensorを対応付けた辞書オブジェクトを返します。'
　},
  {
    "sid": 18,
    "q": '保存した重みをモデルに読み込むコードは？<br><span style="font-family:monospace; background:#333; padding:2px;">model.[ ? ](torch.load("model.pth"))</span>',
    "a": ['load_state_dict', 'load_weights', 'restore', 'set_params'],
    "exp": '「load_state_dict」メソッドを使って、state_dict形式のパラメータをモデルにロードします。'
  },
  {
    "sid": 18,
    "q": 'Datasetクラスを自作する際に実装が必須なメソッドは `__init__`, `__getitem__` と何か？',
    "a": ['__len__', '__size__', '__iter__', '__next__'],
    "exp": 'Map-style datasetでは、データの個数を返す `__len__` と、インデックスからデータを返す `__getitem__` が必須です。'
  },
  {
    "sid": 18,
    "q": 'DataLoaderで、データをシャッフルしてバッチを取り出すための引数は？<br><span style="font-family:monospace; background:#333; padding:2px;">DataLoader(dataset, batch_size=32, [ ? ]=True)</span>',
    "a": ['shuffle', 'random', 'mix', 'sample'],
    "exp": '「shuffle=True」にすると、エポックごとにデータの順序がランダムになります。'
  }
  ];

const LECTURES = {
    1: [
        "【線形代数：行列の基礎】\n行列の積 AB が計算できるのは、「Aの列数」と「Bの行数」が一致する時だけじゃ。\n結果のサイズは (Aの行数 × Bの列数) になるぞ。",
        "【逆行列】\n行列 A に掛けると単位行列 I になる行列のことじゃ。\n「ad - bc = 0」つまり行列式(det)が0の時は、逆行列が存在しない（特異行列という）ぞ。",
        "【固有値と固有ベクトル】\n「Ax = λx」を満たす数λとベクトルxのことじゃ。\n行列を掛けても「向きが変わらず、長さだけがλ倍になる」特別なベクトルなんじゃよ。",
        "【特異値分解 (SVD)】\nどんな行列でも「A = UΣV^T」の形に分解できる最強のツールじゃ。\n画像圧縮や、推薦システム、自然言語処理のLSAなど、応用範囲は無限大じゃ。",
        "【擬似逆行列（ムーア・ペンローズ）】\n正方行列じゃなくても逆行列のような働きをする行列じゃ。\n逆行列がない時の救世主じゃな。",
        "【ノルム】\nベクトルの「大きさ」を表すものじゃ。\nL1ノルムは「絶対値の和」（マンハッタン距離）。\nL2ノルムは「二乗和のルート」（ユークリッド距離）。スパース化したいならL1を使え。",
        "【スカラーとベクトル (Scalar & Vector)】\n数は単体では「スカラー」、縦や横に並べば「ベクトル」と呼ぶ。データの並びを矢印としてイメージするのじゃ。",
        "【行列 (Matrix)】\n数を長方形に並べたものじゃ。画像データもピクセルの並びであるゆえ、AIにとって行列計算は基本中の基本じゃぞ。",
        "【行列の積 (Matrix Multiplication)】\n行列同士の掛け算は「左の行」と「右の列」を順に掛けて足すのじゃ。形が合わねば計算できぬぞ。",
        "【転置行列 (Transpose)】\n行と列を入れ替えた行列じゃ。右上にTと書く。データの向きを変える時によく使う術式じゃな。",
        "【単位行列 (Identity Matrix)】\n掛けても値が変わらぬ不思議な行列じゃ。数字で言う「1」と同じ役割を持つ。対角線だけが1で他は0じゃ。",
        "【逆行列 (Inverse Matrix)】\n掛けると単位行列になる行列じゃ。数字で言う「逆数（割り算）」のようなものだが、必ず存在するとは限らぬぞ。",
        "【行列式 (Determinant)】\n行列の「体積の拡大率」を表す値じゃ。これが0だとペチャンコに潰れておるゆえ、逆行列が存在せぬのじゃ。",
        "【固有値と固有ベクトル (Eigenvalue & Eigenvector)】\n行列を掛けても「向きが変わらず長さだけ変わる」特別なベクトルと、その倍率のことじゃ。",
        "【特異値分解 (SVD)】\n正方形でない行列でも分解できる強力な術じゃ。データの重要な成分だけを取り出す際などに使われるぞ。",
        "【ノルム (Norm)】\nベクトルの「大きさ」や「距離」を測る尺度じゃ。L1ノルム、L2ノルムなど種類があり、正則化で活躍するぞ。",
        "【テンソルの作成】\nNumPy配列から変換するには `torch.from_numpy()` を使うのじゃ。\nGPUに乗せるなら `.to('cuda')` や `.cuda()` を忘れるでないぞ。",
        "【形状変換の基本】\n`reshape` もあるが、PyTorchでは `view` を使うのが伝統じゃ。\nただしメモリが連続していないとエラーになるゆえ、その時は `.contiguous().view()` と唱えるのじゃ。",
        "【行列積】\n行列同士の掛け算は `torch.matmul(A, B)` または `A @ B` と書くのが現代の作法じゃ。\n`A * B` だと要素ごとの掛け算（アダマール積）になってしまうから注意せよ。",
        "【次元の操作】\n次元を増やす `unsqueeze`、減らす `squeeze` は頻出じゃ。\n`unsqueeze(0)` でバッチ次元を追加する技は、画像を1枚だけ推論する時によく使うぞ。"
    ],
    2: [
        "【条件付き確率】\n事象Bが起きた条件下でAが起きる確率は P(A|B) = P(A∩B) / P(B) じゃ。",
        "【ベイズの定理】\n「P(A|B) = P(B|A)P(A) / P(B)」\n結果から原因を探る、AIの根幹をなす式じゃ。\n(事後確率) ∝ (尤度) × (事前確率) と覚えるのじゃ。",
        "【期待値と分散】\n期待値 E[x] は平均的な値。\n分散 V[x] = E[(x - μ)^2] はデータのばらつき具合じゃ。\n「V[x] = E[x^2] - (E[x])^2」という公式は試験によく出るぞ。",
        "【ベルヌーイ分布】\nコイン投げのような「成功か失敗か」の2択の分布じゃ。\n期待値は p、分散は p(1-p) じゃよ。",
        "【二項分布】\nベルヌーイ試行をn回行った時の成功回数の分布じゃ。\nnが大きくpが小さいと「ポアソン分布」に近づき、nが十分大きいと「正規分布」に近づくぞ。",
        "【正規分布（ガウス分布）】\n自然界で最も一般的な、釣り鐘型の分布じゃ。\n平均μと分散σ^2だけで形が決まる。\n標準正規分布は平均0、分散1じゃ。",
        "【確率変数 (Random Variable)】\nサイコロの目のように、確率によって値が決まる変数のことじゃ。大文字Xなどで表されることが多いぞ。",
        "【確率分布 (Probability Distribution)】\nどの値がどのくらいの確率で出るかを表した全体像じゃ。データの癖を見抜く地図のようなものじゃな。",
        "【期待値 (Expectation)】\n確率変数の平均的な値じゃ。「E(X)」と書く。賭け事で言えば、平均していくら儲かるかを示す値じゃ。",
        "【分散と標準偏差 (Variance & Std Dev)】\nデータの「ばらつき具合」を示す値じゃ。分散は2乗しておるゆえ、ルートをとって元の単位に戻したのが標準偏差じゃ。",
        "【ベルヌーイ分布 (Bernoulli Dist.)】\nコイン投げのように「成功か失敗か」の2択しかない場合の分布じゃ。全ての基本となる単純な分布じゃ。",
        "【正規分布 (Normal Dist.)】\n釣鐘型の美しい分布じゃ。自然界の多くのデータ（身長や誤差など）はこの分布に従うと言われておる。",
        "【共分散 (Covariance)】\n2つのデータが「一緒に増えるか、逆の動きをするか」という関係性を表す値じゃ。0ならば関係なし、じゃな。",
        "【相関係数 (Correlation Coefficient)】\n共分散を規格化して -1から+1 の間に収めたものじゃ。+1に近いほど強い正の相関があるぞ。",
        "【ベイズの定理 (Bayes' Theorem)】\n結果から原因の確率を推測する強力な定理じゃ。「事後確率」を求めるために、AIで頻繁に使われるぞ。",
        "【尤度 (Likelihood)】\n「そのデータが得られたもっともらしさ」のことじゃ。確率と似て非なる概念ゆえ、混同するでないぞ。",
        "【乱数の生成】\n標準正規分布（平均0, 分散1）からのサンプリングは `torch.randn()` じゃ。\n一様分布なら `torch.rand()` じゃな。この違い、試験に出るぞ。",
        "【シードの固定】\n再現性を保つには `torch.manual_seed(seed)` を使うのじゃ。\nGPUを使う場合は `torch.cuda.manual_seed()` も必要になることがあるぞ。",
        "【統計量の計算】\n平均は `.mean()`、合計は `.sum()` じゃが、引数に `dim=0` などを渡して\n「どの軸に沿って計算するか」を指定するのがコツじゃ。"
    ],
    3: [
        "【自己情報量】\n「I(x) = -log P(x)」\n確率が低い（珍しい）ことほど、起きた時の情報量（驚き）は大きいのじゃ。",
        "【シャノンエントロピー】\n平均情報量のことじゃ。\n何が起きるか予測できない（ランダムな）時ほど値は大きくなる。\n数式は H(x) = -Σ P(x) log P(x) じゃ。",
        "【KLダイバージェンス】\n2つの確率分布 P と Q の「違い」を測る尺度じゃ。\n距離に似ておるが、P→Q と Q→P の値が違う（非対称）から「距離」とは呼ばないんじゃ。",
        "【交差エントロピー】\n「-Σ P(x) log Q(x)」\n正解分布Pに、予測分布Qを近づけるための損失関数として、分類問題で大活躍するぞ。",
        "【相互情報量】\n「Xを知ることで、Yの不確実性がどれだけ減るか」を表す量じゃ。\nXとYが独立なら0になるぞ。",
        "【情報量 (Information Content)】\n「珍しさ」の度合いじゃ。「太陽が東から昇る」と言われても情報量は低いが、「宇宙人が来た」なら情報量は特大じゃ！",
        "【エントロピー (Entropy)】\n情報の「乱雑さ」や「不確実性」を表す。何が起こるか全くわからぬ状態ほど、エントロピーは高いのじゃ。",
        "【結合エントロピー (Joint Entropy)】\n2つの事象が同時に起こる時の不確実性じゃ。互いに関係があれば、単純な足し算より小さくなるぞ。",
        "【条件付きエントロピー (Conditional Entropy)】\nある事象を知った上で、もう片方の事象がどれくらい不明かを表す値じゃ。",
        "【相互情報量 (Mutual Information)】\n2つの事象がどれだけ情報を共有しているかじゃ。「片方を知ると、もう片方がどれだけ分かるか」の尺度じゃな。",
        "【KLダイバージェンス (KL Divergence)】\n2つの確率分布が「どれくらい似ていないか」を測る距離のようなものじゃ。0ならば完全に一致じゃ。",
        "【交差エントロピー (Cross Entropy)】\n真の分布と、予測した分布のズレを表す。分類問題の損失関数として非常によく使われるぞ。",
        "【シャノンの定理 (Shannon's Theorem)】\n情報理論の父シャノンが定めた、効率よく情報を送るための限界や圧縮の理論じゃ。",
        "【平均情報量】\nエントロピーの別名じゃ。確率分布全体として、平均してどれくらいの情報を持っているかを示す値じゃな。",
        "【最尤推定との関係】\n実は「交差エントロピーを最小化すること」と「尤度を最大化すること」は同じ意味を持つのじゃ。深遠じゃろう？",
        "【対数計算】\n情報量計算に必要な対数は `torch.log()` じゃ。底は $e$ (自然対数) じゃぞ。\n底が2の時は `torch.log2()`、10の時は `torch.log10()` を使い分けるのじゃ。",
        "【微小値の加算】\nlogの中に0が入ると `-inf` になり計算が壊れる。\n`torch.log(x + 1e-10)` のように、微小な値（イプシロン）を足すのが実装の知恵じゃ。"
    ],
    4: [
        "【機械学習の分類】\n・教師あり学習（正解あり：分類・回帰）\n・教師なし学習（正解なし：クラスタリング・次元削減）\n・強化学習（報酬あり：行動最適化）",
        "【過学習 (Overfitting)】\n訓練データに適合しすぎて、未知のデータに対応できない状態じゃ。\nバリアンスが高い状態とも言うぞ。",
        "【未学習 (Underfitting)】\nモデルが単純すぎて、データのパターンを捉えきれていない状態じゃ。\nバイアスが高い状態じゃな。",
        "【バイアス・バリアンス分解】\n誤差は「バイアス（思い込み）の2乗 + バリアンス（変動） + ノイズ」に分解できる。\nこの2つはトレードオフの関係にあるんじゃ。",
        "【交差検証 (Cross Validation)】\nデータをK個に分割して、「学習」と「検証」をK回繰り返す手法じゃ。\nデータが少ない時に、信頼性の高い評価ができるぞ。",
        "【機械学習 (Machine Learning)】\n人間がルールを教えるのではなく、データからコンピュータ自身にルールを学習させる技術じゃ。",
        "【回帰と分類 (Regression & Classification)】\n数値を予測するのが「回帰」、クラス（犬か猫かなど）を当てるのが「分類」じゃ。まずはここを見極めよ。",
        "【汎化性能 (Generalization)】\n未知のデータに対しても正しく答えられる能力じゃ。訓練データだけ100点でも、本番で通用せねば意味がないぞ。",
        "【過学習 (Overfitting)】\n訓練データに適合しすぎて、未知のデータに対応できなくなった状態じゃ。勉強しすぎて応用が利かぬガリ勉状態じゃな。",
        "【バイアスとバリアンス (Bias & Variance)】\nモデルの思い込みの強さ（バイアス）と、データのブレへの過敏さ（バリアンス）のトレードオフ関係じゃ。",
        "【ホールドアウト法 (Hold-out)】\nデータを「訓練用」と「テスト用」に分割する検証法じゃ。カンニングを防ぐための基本じゃぞ。",
        "【k-分割交差検証 (k-fold CV)】\nデータをk個に分け、交代でテストを行う丁寧な検証法じゃ。データが少ない時に特に有効じゃ。",
        "【グリッドサーチ (Grid Search)】\nハイパーパラメータ（設定値）の組み合わせをしらみつぶしに試して、最強の設定を探す力技じゃ。",
        "【正則化 (Regularization)】\nモデルが複雑になりすぎるのを防ぐため、ペナルティを与える術じゃ。過学習を抑える重りをつけるのじゃ。",
        "【ノーフリーランチ定理】\n「あらゆる問題で常に最強のモデルは存在しない」という定理じゃ。状況に合わせて武器（アルゴリズム）を選ぶのじゃ。",
        "【Datasetクラスの継承】\n自作データセットを作るなら `torch.utils.data.Dataset` を継承せよ。\n必須なのは `__len__` (データの個数) と `__getitem__` (データの取り出し) の2つの呪文じゃ。",
        "【DataLoaderの召喚】\nデータをバッチごとに取り出し、シャッフルまでしてくれる `DataLoader` は必須装備じゃ。\n`batch_size` と `shuffle=True` を指定してインスタンス化するのじゃぞ。",
        "【TensorDataset】\n入力データ `x` と正解 `t` が既にTensorとして手元にあるなら、\n`torch.utils.data.TensorDataset(x, t)` を使うと手軽にDataset化できるぞ。"
    ],
    5: [
        "【前処理：欠損値】\nデータが抜けている時は、リストワイズ削除（行ごと消す）や、平均値代入法などで埋めるんじゃ。",
        "【標準化 (Standardization)】\n「(x - 平均) ÷ 標準偏差」で、平均0・分散1に変換する。\n特徴量の単位がバラバラな時に必須じゃ。",
        "【正規化 (Normalization)】\n「(x - 最小) ÷ (最大 - 最小)」で、0〜1の範囲に収める。\n画像データ(0〜255)などでよく使うぞ。",
        "【混同行列】\nTP(真陽性)、TN(真陰性)、FP(偽陽性)、FN(偽陰性)の4つじゃ。\nFPは「狼少年（嘘のアラート）」、FNは「見逃し」じゃな。",
        "【F値 (F1-score)】\n適合率(Precision)と再現率(Recall)の調和平均じゃ。\n「2PR / (P+R)」で計算する。バランスの良いモデルを作りたい時はこれじゃ。",
        "【IoU (Intersection over Union)】\n物体検出などで使う。\n「重なっている面積 ÷ 全体の面積」で、領域のズレを評価するんじゃ。",
        "【欠損値処理 (Missing Values)】\nデータに穴（空欄）がある時、平均値で埋めたり、その行ごと消したりする処置じゃ。ゴミデータはAIの毒じゃ。",
        "【標準化 (Standardization)】\nデータを「平均0、分散1」に整える術じゃ。単位が違うデータ同士を公平に扱うために必須じゃぞ。",
        "【正規化 (Normalization)】\nデータを「0から1の範囲」などに押し込める術じゃ。標準化とは使い分けが必要じゃな。",
        "【One-Hotエンコーディング】\n「赤・青・緑」のようなカテゴリを「1,0,0」「0,1,0」のような0と1の並びに変換する術じゃ。",
        "【白色化 (Whitening)】\nデータ間の相関を無くし、さらにスケールも揃える高度な前処理じゃ。画像処理などで効果を発揮するぞ。",
        "【主成分分析 (PCA)】\nデータの特徴を残しつつ、次元（項目数）を減らす圧縮術じゃ。情報を要約して扱いやすくするのじゃ。",
        "【多重共線性 (Multicollinearity)】\n似たような変数が複数あると計算がおかしくなる現象じゃ。「マルチコ」と略される。相関の高い変数は整理せよ。",
        "【不均衡データ (Imbalanced Data)】\n「正例が極端に少ない」などの偏ったデータじゃ。そのまま学習させると、多数派ばかり答えるAIになるぞ。",
        "【オーバーサンプリング】\n少ない方のデータをコピーして増やす術じゃ。逆に多い方を減らすのをアンダーサンプリングと言うぞ。",
        "【データ拡張 (Data Augmentation)】\n画像を回転させたりずらしたりして、擬似的にデータを水増しする秘術じゃ。深層学習で強力な効果がある。",
        "【Transformsの連結】\n画像の前処理は `torchvision.transforms` を使うのが定石じゃ。\n複数の処理は `transforms.Compose([...])` で鎖のように繋ぐことができるぞ。",
        "【正規化の実装】\n`transforms.Normalize(mean, std)` は、テンソル化した後に使うのじゃ。\nつまり `ToTensor()` の後に書かねばエラーになる。順序を間違えるでないぞ。",
        "【One-Hot化】\nクラスIDをOne-Hotベクトルにするには `F.one_hot(input, num_classes)` が便利じゃ。\nただし、CrossEntropyLossを使うなら、正解ラベルはOne-HotにせずクラスIDのままで良いことが多いぞ。"
    ],
    6: [
        "【正則化】\n損失関数にペナルティ項を加えて、過学習を防ぐ技術じゃ。\nモデルをあえて「単純」にするんじゃよ。",
        "【L1正則化 (Lasso)】\n重みの絶対値を足す。\n不要な重みが「完全に0」になるので、特徴選択（変数を減らす）効果があるぞ。",
        "【L2正則化 (Ridge)】\n重みの二乗を足す（Weight Decay）。\n重みが極端に大きくなるのを防ぎ、滑らかなモデルにするんじゃ。",
        "【グリッドサーチ】\nハイパーパラメータの組み合わせを「しらみつぶし」に全部試す。\n確実じゃが、時間がかかるのが欠点じゃ。",
        "【ランダムサーチ】\nパラメータをランダムに選んで試す。\n実はグリッドサーチより効率が良いことが多いんじゃよ。",
        "【ベイズ最適化】\nこれまでの結果から「次はここを試すべき」と予測しながら探索する、賢い方法じゃ。",
        "【混同行列 (Confusion Matrix)】\n予測の結果を「真陽性・偽陽性・真陰性・偽陰性」の4マスで整理した表じゃ。評価の基本じゃな。",
        "【正解率 (Accuracy)】\n全体のうち、どれだけ正解したかの割合じゃ。データが偏っていると、これだけでは信用できぬぞ。",
        "【適合率 (Precision)】\n「陽性」と予測したもののうち、本当に陽性だった割合じゃ。誤検知を減らしたい時に重視せよ。",
        "【再現率 (Recall)】\n実際の「陽性」のうち、見逃さずに陽性と予測できた割合じゃ。取りこぼしを防ぎたい時に見るのじゃ。",
        "【F値 (F-measure)】\n適合率と再現率はトレードオフゆえ、その調和平均をとった総合的なスコアじゃ。",
        "【ROC曲線とAUC】\n判定の基準を動かした時の性能変化をグラフにしたものじゃ。曲線の下の面積(AUC)が1に近いほど優秀じゃ。",
        "【L1正則化 (Lasso)】\n不要なパラメータをきっぱり「0」にする性質がある。特徴量選択の効果も期待できる鋭いナイフのような術じゃ。",
        "【L2正則化 (Ridge)】\nパラメータが大きくなりすぎるのを防ぐが、0にはせぬ。全体を滑らかに抑え込む、重厚な鎧のような術じゃ。",
        "【ドロップアウト (Dropout)】\n学習中にランダムにニューロンを無効化する術じゃ。わざと過酷な環境で訓練し、過学習を防ぐのじゃ。",
        "【アーリーストップ (Early Stopping)】\n性能が上がらなくなったら、学習を途中で打ち切る術じゃ。やりすぎは過学習の元ゆえ、引き際が肝心じゃ。",
        "【勾配計算の封印】\n評価（推論）時は学習せぬゆえ、メモリ節約のために `with torch.no_grad():` ブロックを作るのじゃ。\nこれを忘れるとメモリ不足で落ちることがあるぞ。",
        "【正解数のカウント】\n予測確率が最大のクラスを知るには `outputs.argmax(dim=1)` を使うのじゃ。\nこれと正解ラベルを `(pred == labels).sum().item()` で比較すれば正解数が求まるぞ。",
        "【item()の使い道】\n損失(Loss)などのTensorから、Pythonの数値(float)を取り出すには `.item()` を使うのじゃ。\nこれをせず累積すると、計算グラフが繋がり続けてメモリを食いつぶすぞ。",
        "【検証時のモード切替 (no_grad)】\n検証（Validation）データの評価中に勾配を計算する必要はない。\n`with torch.no_grad():` で囲って勾配計算を封印せよ。\nこれをせねば、メモリを無駄食いし、評価計算も遅くなる一方じゃぞ。"
    ],
    7: [
        "【ロジスティック回帰】\n線形回帰の結果を「シグモイド関数」に通して、確率(0~1)にする。\n2値分類の基本じゃな。",
        "【SVM (サポートベクターマシン)】\nデータ間の「マージン（隙間）」を最大化する境界線を引く。\nカーネル法を使えば、直線で分けられないデータも分類できるぞ。",
        "【決定木】\n「ジニ不純度」や「エントロピー」が下がるように、条件分岐を作っていく。\n人間にも解釈しやすいが、過学習しやすいのが玉に瑕じゃ。",
        "【ランダムフォレスト】\nバギング（データを変えて学習）と、特徴量のランダム選択を組み合わせた最強クラスのアルゴリズムじゃ。\nたくさんの木の多数決をとるぞ。",
        "【ブースティング (GBDT等)】\n前のモデルが間違えたところを、次のモデルが重点的に直す。\nXGBoostやLightGBMはコンペでも常連じゃな。",
        "【線形回帰 (Linear Regression)】\nデータを最もよく表す「直線」を引く、基本のアルゴリズムじゃ。最小二乗法などを使って解くぞ。",
        "【ロジスティック回帰 (Logistic Regression)】\n名前は回帰じゃが、実は「分類」のための手法じゃ。シグモイド関数を使い、確率を出力するぞ。",
        "【サポートベクターマシン (SVM)】\nデータの間隔（マージン）が最大になるように境界線を引く手法じゃ。カーネル法を使えば曲線も引けるぞ。",
        "【決定木 (Decision Tree)】\n「Yes/No」で条件分岐を繰り返して分類する手法じゃ。中身が解釈しやすいのが利点じゃな。",
        "【ランダムフォレスト (Random Forest)】\nたくさんの決定木を作り、多数決をとる「アンサンブル学習」の代表格じゃ。森は木より賢いのじゃ。",
        "【ブースティング (Boosting)】\n弱点を持ったモデルを次々に強化・修正していく手法じゃ。XGBoostやLightGBMなどが有名で、非常に強力じゃぞ。",
        "【k近傍法 (k-NN)】\n近くにあるk個のデータの多数決で自分のクラスを決める、単純だが直感的な手法じゃ。",
        "【ナイーブベイズ (Naive Bayes)】\nベイズの定理と「変数は互いに独立」という仮定を使った確率的な分類器じゃ。スパムメール判定などで有名じゃ。",
        "【勾配ブースティング決定木 (GBDT)】\n決定木を勾配降下法のように継ぎ足していく強力な手法じゃ。コンペティションでの常勝アルゴリズムじゃ。",
        "【アンサンブル学習 (Ensemble)】\n複数のモデルを組み合わせて性能を上げる総称じゃ。「三人寄れば文殊の知恵」をAIで行うのじゃ。",
        "【全結合層】\n基本の層は `nn.Linear(in_features, out_features)` じゃ。\n入力データの形は `(Batch_Size, in_features)` になっている必要があるぞ。",
        "【パラメータへのアクセス】\n層の重みは `.weight`、バイアスは `.bias` でアクセスできる。\n`.parameters()` を使えば、モデル内の全パラメータをイテレータとして取得できるぞ。"
    ],
    8: [
        "【k-means法】\nデータをk個のクラスタに分ける。\n1. 中心を決める 2. 近いデータを集める 3. 中心を更新する...を繰り返すんじゃ。\n初期値に依存するのが欠点じゃな（k-means++で解決するぞ）。",
        "【主成分分析 (PCA)】\nデータの「分散」が最大になる方向（主成分）を見つけて、次元を減らす。\n「寄与率」を見れば、どれくらい情報を残せたかが分かるぞ。",
        "【白色化】\nデータ間の相関をなくし（無相関化）、さらに分散を1にする処理じゃ。",
        "【t-SNE】\n高次元データの「近さ」を保ったまま、2次元や3次元に圧縮する。\nデータの可視化によく使われるが、距離の意味は保たれないので注意じゃ。",
        "【教師なし学習 (Unsupervised Learning)】\n正解データを与えず、データそのものの構造やパターンをAIに見つけさせる手法じゃ。",
        "【k-means法】\nデータをk個のグループ（クラスタ）に分ける代表的な手法じゃ。中心点を動かしながらグループを最適化するぞ。",
        "【k-means++】\nk-meansの弱点である「最初の中心点の位置」を工夫して決め、安定させる改良版じゃ。",
        "【階層的クラスタリング】\nデータを似たもの同士で順にまとめていき、樹形図（デンドログラム）を作る手法じゃ。分類の過程が見えるぞ。",
        "【t-SNE】\n高次元のデータを2次元や3次元に圧縮して可視化するための手法じゃ。データの「近さ」を保つのが得意じゃ。",
        "【主成分分析 (PCA) の応用】\n教師なし学習の一種として、データの次元圧縮やノイズ除去に使われるぞ。おさらいじゃな。",
        "【特異値分解 (SVD) の応用】\n推薦システムなどで、ユーザーと商品の行列を分解して隠れた好みを見つけるのに使われるぞ。",
        "【アソシエーション分析】\n「おむつを買う人はビールも買う」といった、データ間の意外な関連ルールを見つける手法じゃ。",
        "【ガウス混合モデル (GMM)】\nデータが複数の正規分布の組み合わせでできていると仮定して分類する、確率的なクラスタリングじゃ。",
        "【異常検知 (Anomaly Detection)】\n多数の正常データから外れた「異常」を見つける技術じゃ。教師なし学習が輝く分野の一つじゃな。",
        "【ペアワイズ距離】\nk-meansなどで点同士の距離を一気に計算したいときは `torch.cdist(x1, x2)` が速いぞ。\nfor文で距離を計算するのはPythonが遅くなる原因ゆえ、避けるのが賢者じゃ。",
        "【特異値分解】\nPCAなどを実装する際の特異値分解は `torch.linalg.svd()` を使うのじゃ。\n戻り値は U, S, Vh の3つじゃ。以前は `torch.svd` だったが、今は `linalg` モジュール推奨じゃぞ。"
    ],
    9: [
        "【マルコフ決定過程 (MDP)】\n状態S、行動A、遷移確率P、報酬R、割引率γで定義される世界じゃ。\n次の状態は「今の状態と行動」だけで決まる（マルコフ性）と仮定するぞ。",
        "【ベルマン方程式】\n「今の価値 ＝ 即時報酬 ＋ 割引された未来の価値」\nという再帰的な関係式じゃ。強化学習の魂じゃな。",
        "【価値関数】\n状態価値関数 V(s)：その場所にいることの価値。\n行動価値関数 Q(s,a)：その場所で、ある行動をすることの価値。",
        "【方策勾配法】\n方策（行動の確率）を直接パラメータ化して学習する。\n「REINFORCE」などが有名じゃな。",
        "【Q学習】\nQテーブルを更新していく手法じゃ。\nOff-policy（探索とは別の最適な動きを想定して学習する）なのが特徴じゃ。",
        "【強化学習 (Reinforcement Learning)】\nエージェントが試行錯誤し、報酬を最大化するように行動を学習する仕組みじゃ。",
        "【エージェントと環境 (Agent & Environment)】\n行動する主体が「エージェント」、その舞台が「環境」じゃ。マリオとゲームステージの関係じゃな。",
        "【状態・行動・報酬 (State, Action, Reward)】\n今の状況(S)、何をするか(A)、その結果もらえるご褒美(R)。これが強化学習の3要素じゃ。",
        "【マルコフ決定過程 (MDP)】\n次の状態は「今の状態」と「今の行動」だけで決まる、という仮定じゃ。過去は振り返らぬ、それがMDPじゃ。",
        "【方策 (Policy / π)】\nある状態でどう行動するかを決める戦略のことじゃ。これを最適化するのが最終目標じゃぞ。",
        "【価値関数 (Value Function)】\n「この状態にいると将来どれくらい報酬が貰えそうか」を見積もる関数じゃ。目先の報酬だけでなく未来を見るのじゃ。",
        "【活用と探索 (Exploitation & Exploration)】\n知っている最良の手を使うか(活用)、未知の可能性を試すか(探索)。このバランスが重要じゃ。",
        "【割引率 (Discount Factor)】\n将来の報酬をどれくらい割り引いて評価するかじゃ。今の1万円と1年後の1万円は価値が違うゆえな。",
        "【モンテカルロ法】\nエピソードが終わるまでプレイして、その結果から価値を学習する方法じゃ。習うより慣れろ、じゃな。",
        "【TD学習 (Temporal Difference)】\n行動するたびに、予測と現実のズレを修正していく方法じゃ。ゴールを待たずに学習できるのが強みじゃ。",
        "【カテゴリカル分布】\n方策勾配法などで、確率に基づいて行動を選ぶなら `torch.distributions.Categorical(probs)` じゃ。\n作った分布から `.sample()` すれば、確率に従ったインデックスが得られるぞ。",
        "【勾配の切り離し】\n強化学習では目標値（Target）を固定することがある。\nその時は `.detach()` を使って計算グラフを切るのじゃ。さもなくば意図せぬバックプロパゲーションが走るぞ。"
    ],
    10: [
        "【単純パーセプトロン】\n入力を重み付けして足し合わせ、ステップ関数で0か1を出す。\n線形分離可能な問題しか解けず、XOR問題が解けないことで冬の時代を招いたんじゃ。",
        "【多層パーセプトロン (MLP)】\n隠れ層を増やし、活性化関数を非線形にすることで、どんな関数も近似できるようになった（万能近似定理）。",
        "【活性化関数】\n・Sigmoid：0〜1。勾配消失しやすい。\n・Tanh：-1〜1。中心が0で学習しやすい。\n・ReLU：正ならそのまま、負なら0。現在の主流じゃ。計算が速く勾配消失しにくい。",
        "【ニューロンモデル】\n脳の神経細胞を数式で模したものじゃ。入力を重み付けして足し合わせ、発火するかを決めるのじゃ。",
        "【パーセプトロン (Perceptron)】\n複数の入力を受け取り、0か1を出力する単純な識別器じゃ。ニューラルネットワークの祖先じゃな。",
        "【多層パーセプトロン (MLP)】\n層を重ねることで、より複雑な境界線を引けるようになったモデルじゃ。ここから深層学習が始まったのじゃ。",
        "【活性化関数 (Activation Function)】\nニューロンの出力を調整する関数じゃ。これがないと、いくら層を重ねても単純な計算にしかならぬぞ。",
        "【シグモイド関数 (Sigmoid)】\n入力を0から1の間に滑らかに押し込める関数じゃ。昔は主役だったが、勾配消失の問題がある。",
        "【ReLU (Rectified Linear Unit)】\n入力が0以下なら0、正ならそのまま通す関数じゃ。計算が速く学習しやすい、現代の主役じゃ。",
        "【ソフトマックス関数 (Softmax)】\n出力層で使われ、全出力の合計が1（確率）になるように変換する関数じゃ。分類問題の仕上げに使うぞ。",
        "【万能近似定理】\n「層を深く広くすれば、どんな複雑な関数でも近似できる」という定理じゃ。ニューラルネットの可能性を示す証明じゃ。",
        "【ディープラーニング (Deep Learning)】\n中間層を非常に深くしたニューラルネットワークのことじゃ。特徴量を自動で抽出できるのが革命的だったのじゃ。",
        "【勾配消失問題】\n層が深すぎると、誤差の情報が伝わる途中で消えてしまい、学習が進まなくなる難問じゃ。",
        "【nn.Moduleの継承】\n深層学習モデルを作るなら `nn.Module` を継承するクラスを作るのがPyTorchの流儀じゃ。\n`super().__init__()` を書き忘れると、初期化に失敗してエラーになるから注意せよ。",
        "【forwardメソッド】\n順伝播の処理は必ず `forward(self, x)` という名前のメソッドに書くのじゃ。\nモデルインスタンス `model(x)` を呼ぶと、内部で自動的にこの `forward` が実行される仕組みじゃぞ。",
        "【Sequential】\n複雑な分岐がない一直線のモデルなら、クラス定義せずとも `nn.Sequential` で層を並べるだけで作れるぞ。\n手っ取り早く試したい時に有効じゃ。"
    ],
    11: [
        "【順伝播 (Forward)】\n入力データを行列計算しながら出口まで運ぶ。\n推論時はこれだけでOKじゃ。",
        "【誤差逆伝播法 (Backpropagation)】\n出力の誤差を、入力方向へ逆戻りさせて、各パラメータの責任（勾配）を計算する。\n「連鎖律」が鍵じゃ。",
        "【連鎖律 (Chain Rule)】\n合成関数の微分は、個々の微分の掛け算になる。\n∂L/∂x = ∂L/∂y × ∂y/∂x じゃ。",
        "【勾配消失問題】\n層が深くなると、逆伝播する勾配がどんどん小さくなり、入力層付近で学習が止まってしまう現象じゃ。\nSigmoid関数で起きやすいぞ。",
        "【順伝播 (Forward Propagation)】\n入力から出力に向かってデータを流し、予測値を計算するプロセスじゃ。推論時はこれだけでよい。",
        "【損失関数 (Loss Function)】\n正解と予測が「どれくらいズレているか」を測る関数じゃ。この値を最小にすることが学習の目的じゃ。",
        "【勾配降下法 (Gradient Descent)】\n損失関数の坂道を下るように、パラメータを少しずつ修正する方法じゃ。暗闇で谷底を目指すようなものじゃ。",
        "【誤差逆伝播法 (Backpropagation)】\n出力のズレ（誤差）を入力側へ逆流させ、各パラメータの責任（勾配）を効率よく計算する秘術じゃ。",
        "【連鎖律 (Chain Rule)】\n合成関数の微分を行うための数学的ルールじゃ。逆伝播法は、この連鎖律を応用しているに過ぎぬ。",
        "【計算グラフ (Computational Graph)】\n計算の過程をノードとエッジで図示したものじゃ。これを使うと逆伝播の流れが視覚的に分かるぞ。",
        "【学習率 (Learning Rate)】\n一回の修正でどれくらいパラメータを動かすかの設定値じゃ。大きすぎると発散し、小さすぎると進まぬ。",
        "【イテレーションとエポック】\n重みの更新回数がイテレーション、訓練データを一通り使い切るのが1エポックじゃ。用語を混同するでないぞ。",
        "【バッチサイズ】\n一度の学習に使うデータの数じゃ。まとめて計算することで効率を上げるのじゃ。",
        "【勾配爆発】\n勾配消失とは逆に、計算途中で値が巨大になりすぎて計算不能になる現象じゃ。クリッピングなどで防ぐのじゃ。",
        "【逆伝播の発動】\n損失（スカラー値）に対して `loss.backward()` を唱えると、全パラメータの勾配が計算される。\n計算された勾配は各パラメータの `.grad` 属性に格納されるのじゃ。",
        "【勾配の累積】\nPyTorchはデフォルトで勾配を「足し算」して貯めていく仕様じゃ。\nゆえに、学習ループの最初で必ず勾配をリセットせねばならぬ。これが次のステージの重要ポイントじゃ。",
        "【逆伝播のタイミング (backward)】\n損失 `loss` を計算したら、間髪入れずに `loss.backward()` を唱えるのじゃ。\nこれを行わねばパラメータの更新量（勾配）が計算されぬ。`optimizer.step()` を呼んでも、モデルは一歩も動かぬぞ。",
        "【損失値の記録 (.item)】\n「エポックごとの損失」を記録しようとして `loss_list.append(loss)` などと書いてはおらぬか？\nそれは計算グラフごと保存する自殺行為（メモリリーク）じゃ！\n必ず `loss.item()` を使って、TensorからPythonの数値（float）だけを抽出して保存するのじゃぞ。"
    ],
    12: [
        "【勾配降下法】\nw ← w - η(∂L/∂w)\n勾配の逆方向へ、学習率ηの歩幅で進むんじゃ。",
        "【SGD】\n毎回ランダムに1つのデータだけ見て更新する。\n計算は速いが、ジグザグに進んでしまうぞ。",
        "【Momentum】\n「慣性」項を追加する。過去の移動方向を維持するので、振動を抑えて加速できるんじゃ。",
        "【AdaGrad】\nよく更新されるパラメータの学習率を下げ、あまり更新されないものは上げる。\n学習が進むと学習率が0になりすぎて止まるのが欠点じゃ。",
        "【RMSprop】\nAdaGradの欠点を修正し、過去の情報を徐々に忘れるようにした手法じゃ。",
        "【Adam】\nMomentumとRMSpropのいいとこ取りじゃ。\n迷ったらとりあえずAdamを使っておけば間違いはないぞ。",
        "【SGD (Stochastic Gradient Descent)】\n確率的勾配降下法。データを1つずつランダムに選んで学習する。ふらつくが、局所解に陥りにくいぞ。",
        "【ミニバッチSGD】\nデータを小分け（ミニバッチ）にして学習する、今の主流じゃ。計算効率と安定性のバランスが良いのじゃ。",
        "【モーメンタム (Momentum)】\n「慣性」の概念を取り入れた手法じゃ。坂道を転がるボールのように、勢いをつけて学習を加速させるぞ。",
        "【AdaGrad】\n学習が進んだパラメータの学習率を自動で下げていく手法じゃ。あまり更新されない変数を重視する賢い奴じゃ。",
        "【RMSprop】\nAdaGradの「学習率が下がりすぎて止まる」欠点を改良した手法じゃ。過去の情報を適度に忘れる工夫がある。",
        "【Adam】\nモーメンタムとRMSpropの長所を組み合わせた、現在最強クラスの最適化手法じゃ。まずはこれを使ってみるのが定石じゃ。",
        "【大域的最適解と局所最適解】\n本当の谷底（大域）と、途中にある窪み（局所）。AIは局所解にハマりやすいが、上手く脱出せねばならぬ。",
        "【鞍点 (Saddle Point)】\nある方向から見れば谷だが、別の方向からは山に見える地点じゃ。ここでの停滞が学習の敵となることが多い。",
        "【重みの初期化 (Weight Initialization)】\n学習開始時のパラメータの値じゃ。XavierやHeの初期値など、適切な値で始めないと学習が進まぬぞ。",
        "【バッチ正規化 (Batch Normalization)】\n層の間でデータを正規化して整える技術じゃ。学習が爆速になり、過学習も抑える凄い術じゃ。",
        "【オプティマイザの定義】\n`optimizer = torch.optim.Adam(model.parameters(), lr=0.001)` のように定義する。\n第一引数には「更新したいパラメータ」を渡す必要があるぞ。",
        "【ゼロ・グラドの儀式】\nバックプロパゲーションの前には必ず `optimizer.zero_grad()` を唱えて勾配を0に戻すのじゃ。\nこれを忘れると、過去の勾配が足され続けて学習が破綻するぞ。",
        "【更新の実行】\n勾配計算後、`optimizer.step()` を呼ぶことで、実際にパラメータの値が書き換わる。\n`zero_grad` → `backward` → `step` 。この3ステップが学習の1セットじゃ。",
        "【勾配のリセット (zero_grad)】\nループの先頭で `optimizer.zero_grad()` を書き忘れる者が後を絶たん。\nPyTorchは勾配を「足し合わせる」仕様じゃ。これを忘れると、過去の勾配が全て混ざり合い、学習が暴走してしまうぞ！",
        "【更新の実行 (step)】\n`backward()` で勾配を計算しただけでは、重みは変わらぬぞ。\nトドメに `optimizer.step()` を呼んで初めて、パラメータが更新されるのじゃ。`zero_grad` → `backward` → `step` の三拍子を身体に刻み込め。"
    ],
    13: [
        "【畳み込み層 (Conv)】\nフィルタ（カーネル）をスライドさせて特徴を抽出する。\n「ストライド」はずらす幅、「パディング」は端っこを埋める処理じゃ。",
        "【プーリング層】\nMax Poolingは最大値をとる。\n画像が多少ズレても同じ特徴だと認識できるようにする（移動不変性）効果があるぞ。",
        "【Global Average Pooling (GAP)】\n全結合層の代わりに、各チャンネルの平均値をとる手法じゃ。\nパラメータ数を劇的に減らせるぞ。",
        "【AlexNet】\nディープラーニングブームの火付け役。ReLUやドロップアウトを採用した。",
        "【VGG】\n3×3の小さなフィルタをひたすら重ねて深くしたモデルじゃ。",
        "【ResNet】\n「スキップ接続（入力を出力に足す）」を導入し、100層以上でも学習できるようにした革命的モデルじゃ。",
        "【1x1畳み込み】\n情報の次元（チャンネル数）を圧縮したり、計算量を減らすのによく使われるテクニックじゃ。",
        "【CNN (Convolutional Neural Network)】\n画像認識で圧倒的な力を発揮する構造じゃ。人間の視覚野の仕組みを模していると言われるぞ。",
        "【畳み込み層 (Convolution Layer)】\n画像にフィルタ（カーネル）をスライドさせながら掛け合わせ、特徴をあぶり出す層じゃ。",
        "【カーネル/フィルタ (Kernel/Filter)】\n「縦の線」や「角」など、特定の特徴に反応する小さな窓のようなものじゃ。これを学習で獲得するのじゃ。",
        "【パディング (Padding)】\n画像の周囲に0などを埋めてサイズを調整する処理じゃ。端っこの情報も大事にするために行うぞ。",
        "【ストライド (Stride)】\nフィルタを動かす歩幅のことじゃ。大きくすると出力サイズは小さくなるぞ。",
        "【プーリング層 (Pooling Layer)】\n画像を圧縮して、位置のズレに強くする層じゃ。最大値をとるMaxプーリングがよく使われる。",
        "【全結合層 (Fully Connected Layer)】\nCNNの最後で、抽出された特徴をまとめて最終的な判断（分類）を下す層じゃ。",
        "【AlexNet】\n2012年に圧倒的精度で優勝し、第3次AIブームの火付け役となった伝説のCNNモデルじゃ。",
        "【ResNet】\n「スキップ接続」という抜け道を作ることで、100層以上の超深層学習を可能にした革命的なモデルじゃ。",
        "【転移学習 (Transfer Learning)】\n有名なモデルが学習した知識（重み）を借りて、自分のタスクに合わせて微調整する効率的な術じゃ。",
        "【Conv2dの引数】\n`nn.Conv2d(in_channels, out_channels, kernel_size)` が基本じゃ。\n入力画像のチャンネル数がRGBなら `in_channels=3` になるな。",
        "【入力テンソルの形状】\nPyTorchの画像入力は `(Batch, Channel, Height, Width)` の順序（BCHW）じゃ。\nOpenCVなどは (H, W, C) のことが多いゆえ、`permute` などで入れ替える必要があるぞ。",
        "【プーリング層】\n最大値プーリングは `nn.MaxPool2d(kernel_size)` じゃ。\n画像のサイズを半分にしたいなら `kernel_size=2`、`stride=2` とするのが定石じゃな。"
        "【畳み込み層の定義 (nn.Conv2d)】\n基本は `nn.Conv2d(in_channels, out_channels, kernel_size)` じゃ。\n`in_channels` は入力画像の深さ（RGBなら3）、`out_channels` はフィルタの数じゃ。\nこの順番を逆にすると、次の層で次元が合わずエラーになるぞ。ゆめゆめ間違えるな。",
        "【パディングとストライド (Padding & Stride)】\n画像サイズを変えずに畳み込みたいなら、3x3カーネルに対し `padding=1` を指定せよ。\n逆に画像を小さくしたいなら `stride=2` とすれば、サイズは半分になる。\nプーリングを使わずストライドで縮小するのも、最近の流行りじゃな。",
        "【プーリングの使い分け (Max vs Avg)】\n`nn.MaxPool2d` は領域内の最大値をとる。エッジなどの「強い特徴」を残したい画像認識ではこちらが主流じゃ。\n一方 `nn.AvgPool2d` は平均をとる。全体を滑らかにしたい時や、Global Average Pooling として最後の全結合層の代わりに使うことが多いのう。",
        "【全結合層への接続 (Flatten)】\n畳み込み層の出力は「バッチ×ch×高さ×幅」の4次元じゃが、`nn.Linear` は2次元しか受け付けぬ。\n古くは `x.view(x.size(0), -1)` と書いたが、今は `x.flatten(1)` と書くのがスマートじゃ。\nバッチ次元（先頭）を残して、残りを一直線にする呪文じゃぞ。",
        "【入力サイズの計算】\n全結合層 `nn.Linear(in_features, ...)` の `in_features` に何を入れるか、迷うじゃろう？\nこれは「直前の畳み込み出力の ch数 × 高さ × 幅」じゃ。\n計算が面倒なら、ダミーデータ `torch.randn(1, 3, 224, 224)` などをモデルに通して `.shape` を確認するのが賢者の知恵じゃ。",
        "【モードの切り替え (Train vs Eval)】\nCNNによく使う `Dropout` や `BatchNorm` は、学習時と推論時で挙動が違う。\n必ず学習前には `model.train()`、評価・推論前には `model.eval()` を唱えるのじゃ。\nこれを忘れると、推論なのにドロップアウトしてしまい、精度がガタ落ちするぞ。"
    ],
    14: [
        "【RNN (再帰型NN)】\n隠れ層の状態を、次の時刻の入力として使う。\n過去の情報を記憶できるが、長い系列だと勾配消失で忘れてしまうぞ。",
        "【BPTT】\n時間を遡って誤差を伝える、RNN用の逆伝播法じゃ。\n長すぎると計算できないので、適当な長さで切る（Truncated BPTT）ことが多い。",
        "【LSTM】\n「入力・忘却・出力」の3つのゲートと「セル」を持つ。\n長期記憶を保持できるすごいモデルじゃ。「CEC」が勾配を維持するぞ。",
        "【GRU】\nLSTMを簡略化したものじゃ。「リセットゲート」と「更新ゲート」の2つしかないが、性能はLSTMと同等じゃ。",
        "【双方向RNN】\n過去から未来だけでなく、未来から過去へも学習する。\n文章全体の文脈を読むのに適しているぞ。",
        "【RNN (Recurrent Neural Network)】\n前の時刻のデータを記憶し、次の予測に使う構造じゃ。時系列データや文章など「順番」が大事なデータに強い。",
        "【BPTT (Backpropagation Through Time)】\n時間を遡って誤差を逆伝播させる、RNN専用の学習法じゃ。過去の自分に責任を問うようなものじゃな。",
        "【長期依存性の問題】\nRNNは昔の記憶を忘れてしまいがちじゃ。「文頭の主語」を「文末の動詞」まで覚えておくのが苦手なのじゃ。",
        "【LSTM (Long Short-Term Memory)】\n「忘却ゲート」などの仕組みを持ち、長期記憶を可能にしたRNNの進化系じゃ。時系列の王道じゃな。",
        "【GRU (Gated Recurrent Unit)】\nLSTMを少し簡略化して計算を軽くしたモデルじゃ。性能は拮抗しておるゆえ、使い勝手が良いぞ。",
        "【CEC (Constant Error Carousel)】\nLSTMの中核にある、勾配を消さずに保存しておくメリーゴーランドのような仕組みじゃ。",
        "【双方向RNN (Bidirectional RNN)】\n過去から未来だけでなく、未来から過去へも読み込むRNNじゃ。文脈を読むには前後両方が必要ゆえな。",
        "【Encoder-Decoder】\n入力を符号化（Encode）し、それを復号化（Decode）する構造じゃ。翻訳などで大活躍するぞ。",
        "【勾配クリッピング】\nRNNで起きやすい勾配爆発を防ぐため、勾配が一定以上になったら無理やり切り取る荒療治じゃ。",
        "【Seq2Seq】\nある系列データから別の系列データを生成するモデルじゃ。チャットボットや翻訳の基礎となる技術じゃ。",
        "【LSTMの入出力】\n`nn.LSTM` はデフォルトで入力が `(Sequence, Batch, Feature)` の順じゃ。\n`(Batch, Sequence, ...)` で扱いたいなら、定義時に `batch_first=True` をつけるのを忘れるでないぞ。",
        "【隠れ状態の扱い】\nLSTMの出力は `output, (h_n, c_n)` のタプルじゃ。\n次回の入力に隠れ状態を引き継ぐ場合は、この `h_n` と `c_n` を `.detach()` して渡す必要があるぞ。"
    ],
    15: [
        "【Word2Vec】\n「単語の意味」をベクトルにする技術じゃ。\nCBOW（周りから真ん中を予測）とSkip-gram（真ん中から周りを予測）があるぞ。",
        "【Seq2Seq】\nEncoderで入力をベクトルに圧縮し、Decoderで出力に変換する。\n翻訳やチャットボットの基本形じゃ。",
        "【Attention (注意機構)】\n「入力のどの単語に注目すべきか」を自動で学習する。\n長い文章でも翻訳精度が落ちなくなったぞ。",
        "【Transformer】\nRNNを捨てて、Attentionのみで作られたモデルじゃ。\n並列計算ができるので学習が超高速じゃ。今のAIの主流じゃな。",
        "【BERT】\nTransformerのEncoderを使った事前学習モデルじゃ。\n文章の穴埋め問題（Masked LM）で言葉の意味を深く学習しておる。",
        "【GPT】\nTransformerのDecoderを使ったモデルじゃ。\n次に来る単語をひたすら予測することで、流暢な文章生成を実現したぞ。",
        "【形態素解析】\n文章を単語（意味を持つ最小単位）にバラバラにする処理じゃ。日本語はスペースがないゆえ、これが第一歩じゃ。",
        "【BoW (Bag-of-Words)】\n単語の出現回数だけを数えてベクトルにする手法じゃ。語順を無視して袋に詰め込むゆえ、文脈は失われるぞ。",
        "【TF-IDF】\n「特定の文書にだけ頻出する単語」を重要視する重み付け手法じゃ。「私」のようなありふれた単語の価値を下げるのじゃ。",
        "【Word2Vec】\n単語の意味をベクトル（数値の並び）にする技術じゃ。「王様 - 男 + 女 = 女王」のような計算ができるようになるぞ。",
        "【Attention (注意機構)】\n入力データの「どこに注目すべきか」を重み付けする仕組みじゃ。長い文章の翻訳精度を飛躍的に高めたぞ。",
        "【Transformer】\nRNNを使わず、Attentionだけで構築されたモデルじゃ。並列計算が可能で、今のLLM（大規模言語モデル）の基礎じゃ。",
        "【BERT】\nTransformerを使い、文章の前後から文脈を読むモデルじゃ。事前学習済みモデルとして、様々なタスクで最強を誇ったぞ。",
        "【GPT】\n「次の単語を予測する」ことに特化したモデルじゃ。文章生成において圧倒的な性能を見せる、今のAIブームの立役者じゃ。",
        "【事前学習とファインチューニング】\n大量のデータで汎用的な知識を学び（事前学習）、その後に特定のタスク向けに微調整する（FT）手法じゃ。",
        "【トークナイザ】\n文章をAIが扱える数値（トークン）に変換する辞書のようなものじゃ。これの性能がAIの語彙力を決めるぞ。",
        "【Embedding層】\n単語IDをベクトルにするには `nn.Embedding(num_embeddings, embedding_dim)` を使う。\n`num_embeddings` は語彙数じゃ。パディング用IDを無視する `padding_idx` オプションも便利じゃぞ。",
        "【Transformer】\nPyTorchには `nn.Transformer` や `nn.TransformerEncoder` が用意されておる。\n自力で実装するのも修行じゃが、実戦ではこれらを使うのが早道じゃ。"
    ],
    16: [
        "【VAE (変分オートエンコーダ)】\n入力を「平均と分散」の確率分布に変換する。\nそこからサンプリングして画像を復元するんじゃ。\n潜在変数が連続的になるので、モーフィングなどができるぞ。",
        "【GAN (敵対的生成ネットワーク)】\nGenerator（偽造者）とDiscriminator（警察）のいたちごっこじゃ。\nGeneratorは騙そうとし、Discriminatorは完全に見抜こうとする。",
        "【DCGAN】\nGANにCNNを取り入れたモデルじゃ。\nプーリングをやめてストライド畳み込みを使うなどの工夫がある。",
        "【モード崩壊】\nGANの失敗例。生成器が「この画像さえ出せば騙せる」と学習し、同じ画像しか出さなくなる現象じゃ。",
        "【拡散モデル (Diffusion Model)】\n画像にノイズを加えていき、それを逆再生して「ノイズから画像を復元」するプロセスを学習する。\nStable Diffusionの中身じゃな。",
        "【生成モデル (Generative Model)】\nデータの特徴を学習し、そこから新しいデータを「作り出す」AIじゃ。識別するだけだったAIがクリエイターになったのじゃ。",
        "【VAE (Variational Autoencoder)】\n入力画像を潜在変数（確率分布）に変換し、そこから画像を復元するモデルじゃ。ノイズを混ぜてもそれっぽい画像を生成できるぞ。",
        "【GAN (Generative Adversarial Networks)】\n「偽造者（生成器）」と「鑑定士（識別器）」を戦わせて学習させる手法じゃ。敵対的生成ネットワークと呼ぶ。",
        "【Generator (生成器)】\nGANにおいて、ノイズから偽物データを作り出す側じゃ。鑑定士を騙そうと必死に腕を磨くのじゃ。",
        "【Discriminator (識別器)】\nGANにおいて、本物か偽物かを見破る側じゃ。偽造者の手口を見抜こうと目を凝らすのじゃ。",
        "【モード崩壊 (Mode Collapse)】\nGeneratorが「鑑定士を騙しやすい特定の画像」ばかり作るようになる失敗状態じゃ。多様性が失われてしまうぞ。",
        "【DCGAN】\nGANにCNN（畳み込み）を取り入れたモデルじゃ。画像生成の品質が劇的に安定し、GANブームを巻き起こしたぞ。",
        "【潜在変数 (Latent Variable)】\n目には見えないが、データの特徴を決定づけている裏側の変数のことじゃ。これを操作すれば画像を操れるぞ。",
        "【拡散モデル (Diffusion Model)】\n画像にノイズを徐々に加えて壊し、それを逆再生して復元する過程を学ぶ最新の手法じゃ。画像生成AIの今の主流じゃな。",
        "【リパラメタリゼーション・トリック】\nVAEで確率分布からサンプリングする際に、誤差逆伝播ができるように数式を工夫するテクニックじゃ。",
        "【転置畳み込み】\n画像を拡大（アップサンプリング）するには `nn.ConvTranspose2d` を使うのじゃ。\nGANのGeneratorで、ノイズから画像を生成する際によく使われる術式じゃな。",
        "【Tanhの活用】\n画像生成の出力層では `nn.Tanh()` を使い、値を -1〜1 の範囲に収めることが多い。\nこれに合わせて、正解画像も事前に -1〜1 に正規化しておくのがコツじゃぞ。"
    ],
    17: [
        "【DQN (Deep Q-Network)】\nQ学習のQテーブルをニューラルネットで近似したものじゃ。\nAtariのゲームを人間以上にプレイしたことで有名じゃな。",
        "【Experience Replay】\n経験をメモリに溜めて、ランダムに取り出して学習する。\nデータの相関をなくし、学習を安定させる必須テクニックじゃ。",
        "【Target Network】\n学習の目標となるQ値を計算するネットワークを固定する。\n追いかける背中がブレないようにする工夫じゃ。",
        "【A3C】\n複数のエージェントを並列に動かす。\n非同期にパラメータを更新することで、高速かつ安定した学習ができるぞ。",
        "【AlphaGo】\n「方策関数（どこに打つか）」と「価値関数（勝率はいくつか）」の2つの脳を持つ。\nモンテカルロ木探索で先読みを行うんじゃ。",
        "【深層強化学習 (Deep RL)】\n強化学習の「価値関数」や「方策」の計算に、ディープラーニングを用いたものじゃ。AlphaGoなどが有名じゃな。",
        "【DQN (Deep Q-Network)】\nQ学習（行動価値関数の学習）にニューラルネットを導入し、Atariのゲームを人間以上にプレイした記念碑的モデルじゃ。",
        "【Experience Replay】\nプレイ経験をメモリに保存し、ランダムに取り出して学習するDQNの工夫じゃ。データの相関を消して学習を安定させるぞ。",
        "【Target Network】\n学習の正解となる目標値を計算する専用のネットワークを固定し、たまに更新する工夫じゃ。ゴールが動くと学習しにくいゆえな。",
        "【A3C】\n複数のエージェントを並列に動かして学習させる手法じゃ。学習が速く、ハイスペックなPCでなくとも動くのが魅力じゃ。",
        "【方策勾配法 (Policy Gradient)】\n価値関数を経由せず、方策（戦略）そのものを直接学習して更新する手法じゃ。ロボット制御などで使われるぞ。",
        "【AlphaGo】\n囲碁の世界王者を破ったAIじゃ。DQNやモンテカルロ木探索を組み合わせた、歴史的な勝利じゃったな。",
        "【Actor-Critic】\n行動を決める「役者」と、それを評価する「批評家」の2つのネットワークで学習する、安定した手法じゃ。",
        "【報酬設計 (Reward Shaping)】\nAIが望ましい行動をとるように、報酬の与え方を工夫することじゃ。ここを間違えるとAIはズルをするぞ。",
        "【Sim2Real】\nシミュレーションで育てたAIを、現実世界のロボットなどに移植する際の課題じゃ。現実はゲームより厳しいのじゃ。",
        "【Huber Loss】\nDQNなどの誤差計算では、外れ値に強い `F.smooth_l1_loss` (Huber Loss) が好まれる。\nMSE（二乗誤差）だと学習が不安定になる時こそ試してみるのじゃ。",
        "【モデルのコピー】\nTarget Networkを作る時など、モデルの重みをコピーしたい時は `load_state_dict` を使う。\n`target_net.load_state_dict(policy_net.state_dict())` と唱えれば同期完了じゃ。"
    ],
    18: [
        "【モデルの軽量化】\n・蒸留：巨大な教師モデルの知識を、小さな生徒モデルに教える。\n・量子化：32bitの数値を8bitなどに落としてメモリを節約する。\n・プルーニング：重要でない重みを0にして計算を省く。",
        "【Docker】\nOSやライブラリなどの環境一式を「コンテナ」にパッケージングする技術じゃ。\nどこでも同じ環境で動かせるから、開発・運用に必須じゃぞ。",
        "【エッジAI】\nクラウドではなく、スマホやIoT機器の中で推論を行う。\n通信遅延がなく、プライバシーも守れるのが利点じゃ。",
        "【推論アクセラレータ】\nGPUやTPU、FPGAなど、AIの計算を高速化する専用ハードウェアのことじゃ。",
        "【Docker】\nコンテナと呼ばれる仮想環境を作る技術じゃ。「私の環境では動いたのに」という悲劇を防ぐ、開発者の必須アイテムじゃ。",
        "【エッジコンピューティング】\nクラウドではなく、スマホやIoT機器など現場（エッジ）側でAIを動かすことじゃ。通信遅延がなく、プライバシーも守れるぞ。",
        "【量子化 (Quantization)】\nパラメータの精度（桁数）を落として、モデルを軽量化する術じゃ。多少馬鹿になるが、スマホでも動くようになるぞ。",
        "【プルーニング (Pruning)】\n「枝刈り」じゃ。ニューラルネットの不要な結合をカットしてスカスカにし、計算を速くする軽量化技術じゃ。",
        "【蒸留 (Distillation)】\n巨大な「教師モデル」の知識を、小さな「生徒モデル」に教え込む技術じゃ。性能を保ったまま小型化できるぞ。",
        "【GPUとTPU】\nAIの行列計算を高速処理するためのハードウェアじゃ。これがないと深層学習の学習は何ヶ月もかかってしまうぞ。",
        "【クラウド vs オンプレミス】\nAWSなどを借りるか、自社でサーバーを買うか。コストとセキュリティを天秤にかけて選ぶのじゃ。",
        "【モデルの劣化】\n世の中のトレンドが変わると、AIの精度は落ちていく。「概念ドリフト」とも呼ばれる。定期的な再学習が必要じゃ。",
        "【MLOps】\nAIの開発から運用、監視までをスムーズに回すための仕組み作りじゃ。作って終わりではないのがAIプロジェクトじゃ。",
        "【説明可能AI (XAI)】\n「なぜその判断をしたのか」を人間が理解できるようにする研究じゃ。ブラックボックスのままでは社会で使いにくいゆえな。",
        "【推奨される保存法】\nモデル全体を保存するのではなく、パラメータのみを保存するのが作法じゃ。\n`torch.save(model.state_dict(), 'model.pth')` と書くのじゃ。これで互換性の問題が減るぞ。",
        "【ロードの手順】\nロード時はまずモデルのインスタンスを作り、そこにパラメータを流し込む。\n`model = MyModel()` の後に `model.load_state_dict(torch.load('model.pth'))` じゃ。",
        "【学習モードと推論モード】\nロードした後、学習を再開するなら `model.train()`、推論するだけなら `model.eval()` を呼ぶ。\nDropoutやBatchNormの挙動が変わるゆえ、これを忘れると精度が出ぬぞ。"
    ]
};


const MAP_VILLAGE = [
    [1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],
    [1,3,3,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1],
    [1,3,3,1,0,2,0,0,0,0,0,0,0,0,0,0,0,0,0,1],
    [1,1,2,1,0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,1],
    [1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1],
    [1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1],
    [1,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1],
    [1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1],
    [1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1],
    [1,1,1,1,1,5,5,1,1,1,1,1,1,1,1,1,1,1,1,1]
];

const MAP_FIELD = [
    [1,1,1,1,1,5,5,1,1,1,1,1,1,1,1,1,1,1,1,1],
    [1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1],
    [1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1],
    [1,0,0,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1],
    [1,0,0,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1],
    [1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1],
    [1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,4,0,0,1],
    [1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1],
    [1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1],
    [1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1]
];

const canvas = document.getElementById('gameCanvas');
const ctx = canvas.getContext('2d');
const TILE_SIZE = 48;

const assets = {};
function loadAssets() {
    for (let key in IMAGES) {
        const img = new Image(); img.src = IMAGES[key]; assets[key] = img;
    }
}
loadAssets();

const Sound = {
    ctx: null, osc: null, intervalId: null, isPlaying: false,
    init() { if (!this.ctx) this.ctx = new (window.AudioContext || window.webkitAudioContext)(); },
    playBGM(type) {
        if (!this.ctx) this.init(); if (this.ctx.state === 'suspended') this.ctx.resume();
        this.stopBGM();
        let melody = [], tempo = 150;
        if (type === 'village') { melody = [261, 329, 392, 329, 261, 329, 392, 329, 440, 349, 261, 349, 440, 349, 293, 247]; tempo = 300; }
        else if (type === 'field') { melody = [392, 392, 440, 523, 587, 523, 440, 392, 392, 330, 392, 523]; tempo = 200; }
        else if (type === 'battle') { melody = [110, 110, 130, 110, 146, 110, 130, 110, 164, 110, 146, 110]; tempo = 100; }
        else if (type === 'boss') { melody = [65, 73, 82, 73, 65, 73, 82, 97]; tempo = 120; }
        let noteIndex = 0;
        const playNote = () => {
            const osc = this.ctx.createOscillator(); const gain = this.ctx.createGain();
            osc.connect(gain); gain.connect(this.ctx.destination);
            osc.type = (type === 'boss' || type === 'battle') ? 'sawtooth' : 'triangle';
            osc.frequency.value = melody[noteIndex];
            gain.gain.setValueAtTime(0.1, this.ctx.currentTime);
            gain.gain.linearRampToValueAtTime(0, this.ctx.currentTime + (tempo/1000)*0.9);
            osc.start(); osc.stop(this.ctx.currentTime + (tempo/1000));
            noteIndex = (noteIndex + 1) % melody.length;
        };
        playNote(); this.intervalId = setInterval(playNote, tempo); this.isPlaying = true;
    },
    stopBGM() { if (this.intervalId) clearInterval(this.intervalId); this.isPlaying = false; },
    playSE(type) {
        if (!this.ctx) return;
        const osc = this.ctx.createOscillator(); const gain = this.ctx.createGain();
        osc.connect(gain); gain.connect(this.ctx.destination);
        const now = this.ctx.currentTime;
        if (type === 'decide') {
            osc.frequency.setValueAtTime(880, now); gain.gain.setValueAtTime(0.1, now);
            gain.gain.exponentialRampToValueAtTime(0.01, now + 0.1); osc.start(now); osc.stop(now + 0.1);
        } else if (type === 'damage') {
            osc.type = 'square'; osc.frequency.setValueAtTime(150, now); osc.frequency.linearRampToValueAtTime(50, now + 0.2);
            gain.gain.setValueAtTime(0.2, now); gain.gain.linearRampToValueAtTime(0.01, now + 0.2); osc.start(now); osc.stop(now + 0.2);
        } else if (type === 'win') {
            this.stopBGM();
            [523, 659, 783, 1046].forEach((f, i) => {
                const o = this.ctx.createOscillator(); const g = this.ctx.createGain();
                o.connect(g); g.connect(this.ctx.destination); o.type = 'square'; o.frequency.value = f;
                g.gain.value = 0.1; g.gain.linearRampToValueAtTime(0, now + i*0.1 + 0.3);
                o.start(now + i * 0.1); o.stop(now + i * 0.1 + 0.3);
            });
            setTimeout(() => this.resumeMapBGM(), 2000);
        }
    },
    resumeMapBGM() { if (Game.mapType === 'village') this.playBGM('village'); else this.playBGM('field'); }
};

function startGame() {
    document.getElementById('start-screen').style.display = 'none';
    Sound.init(); Sound.playBGM('village');
}

function drawTile(key, x, y, fallbackColor) {
    const px = x * TILE_SIZE; const py = y * TILE_SIZE; const img = assets[key];
    if (img && img.complete && img.naturalHeight !== 0) ctx.drawImage(img, px, py, TILE_SIZE, TILE_SIZE);
    else { ctx.fillStyle = fallbackColor; ctx.fillRect(px, py, TILE_SIZE, TILE_SIZE); ctx.strokeStyle="rgba(0,0,0,0.3)"; ctx.strokeRect(px, py, TILE_SIZE, TILE_SIZE); }
}

const Game = { mode: 'map', mapData: MAP_VILLAGE, mapType: 'village' };
const Player = {
    x: 10, y: 5, hp: 100, maxHp: 100, dir: 'down',
    move(dx, dy) {
        if (Game.mode !== 'map') return;
        const nextX = this.x + dx; const nextY = this.y + dy;
        // 向き更新
        if(dx>0) this.dir='right'; if(dx<0) this.dir='left'; if(dy>0) this.dir='down'; if(dy<0) this.dir='up';
        
        const tile = getTile(nextX, nextY);
        if (tile === 1) return;
        this.x = nextX; this.y = nextY;
        this.checkStepEvent(tile, nextX, nextY);
    },
    checkStepEvent(tile, x, y) {
        if (tile === 5) {
            if (Game.mapType === 'village') { Game.mapData = MAP_FIELD; Game.mapType = 'field'; this.x = 10; this.y = 1; Sound.playBGM('field'); }
            else { Game.mapData = MAP_VILLAGE; Game.mapType = 'village'; this.x = 10; this.y = 8; Sound.playBGM('village'); }
            return;
        }
        if (tile === 4) { Battle.start('boss'); return; }
        if (Game.mapType === 'field' && Math.random() < 0.15) { Battle.start('slime'); }
    },
    interact() {
        if (Game.mode !== 'map') { if (Game.mode === 'dialogue') Dialogue.next(); return; }
        let tx = this.x, ty = this.y;
        if (this.dir === 'up') ty--; if (this.dir === 'down') ty++; if (this.dir === 'left') tx--; if (this.dir === 'right') tx++;
        const tile = getTile(tx, ty);
        if (tile === 2) { Sound.playSE('decide'); const text = LECTURES[Math.floor(Math.random() * LECTURES.length)]; Dialogue.show("村人", text); }
        else if (tile === 3) { Sound.playSE('decide'); this.hp = this.maxHp; Dialogue.show("宿屋の主人", "よく休めたかい？ HPが全回復したよ！"); }
    }
};

function getTile(x, y) {
    if (y < 0 || y >= Game.mapData.length || x < 0 || x >= Game.mapData[0].length) return 1;
    return Game.mapData[y][x];
}

const Input = {
    moveInterval: null,
    startMove(dx, dy) {
        if(Game.mode !== 'map') return;
        Player.move(dx, dy);
        if (this.moveInterval) clearInterval(this.moveInterval);
        this.moveInterval = setInterval(() => { if(Game.mode === 'map') Player.move(dx, dy); }, 150);
    },
    stopMove() { if (this.moveInterval) clearInterval(this.moveInterval); this.moveInterval = null; },
    triggerAction() { Player.interact(); }
};

window.addEventListener('keydown', e => {
    if (e.repeat) return;
    if (e.key === 'ArrowUp') Input.startMove(0, -1);
    if (e.key === 'ArrowDown') Input.startMove(0, 1);
    if (e.key === 'ArrowLeft') Input.startMove(-1, 0);
    if (e.key === 'ArrowRight') Input.startMove(1, 0);
    if (e.key === ' ' || e.key === 'Enter') Input.triggerAction();
});
window.addEventListener('keyup', () => Input.stopMove());

const Battle = {
    enemy: null, q_list: [],
    start(type) {
        Input.stopMove(); Game.mode = 'battle'; document.getElementById('battle-ui').style.display = 'flex';
        if (type === 'boss') { Sound.playBGM('boss'); this.enemy = { name: "魔王", hp: 100, maxHp: 100, atk: 30, img: IMAGES.boss }; this.q_list = [...DB].sort(() => Math.random() - 0.5); }
        else { Sound.playBGM('battle'); this.enemy = { name: "スライム", hp: 20, maxHp: 20, atk: 10, img: IMAGES.slime }; this.q_list = [DB[Math.floor(Math.random() * DB.length)]]; }
        document.getElementById('enemy-name').innerText = this.enemy.name;
        document.getElementById('battle-enemy-img').src = this.enemy.img;
        this.updateUI(); this.log(`${this.enemy.name} があらわれた！`);
        setTimeout(() => this.nextQuestion(), 1500);
    },
    nextQuestion() {
        if (this.q_list.length === 0) { if (this.enemy.hp > 0) { this.end("勝負はお預けだ。"); Sound.resumeMapBGM(); } return; }
        const q = this.q_list.pop();
        document.getElementById('quiz-area').style.display = 'block'; document.getElementById('battle-next-btn').style.display = 'none';
        document.getElementById('quiz-text').innerText = q.q;
        const optsDiv = document.getElementById('quiz-options'); optsDiv.innerHTML = '';
        const options = q.a.map((txt, i) => ({ txt, isC: i===0 })).sort(() => Math.random() - 0.5);
        options.forEach(opt => {
            const btn = document.createElement('button'); btn.className = 'btn'; btn.innerText = opt.txt;
            btn.onclick = () => this.answer(btn, opt.isC, q.exp); optsDiv.appendChild(btn);
        });
        this.log("どうする？");
    },
    answer(btn, isCorrect, exp) {
        const btns = document.querySelectorAll('#quiz-options button'); btns.forEach(b => b.disabled = true);
        if (isCorrect) { btn.classList.add('correct'); Sound.playSE('decide'); this.log(`正解！ ダメージ！`); this.enemy.hp -= 10; }
        else { btn.classList.add('wrong'); Sound.playSE('damage'); this.log(`不正解... (${exp})`); Player.hp -= this.enemy.atk; }
        this.updateUI();
        setTimeout(() => {
            if (Player.hp <= 0) { this.end("GAME OVER..."); Sound.stopBGM(); Player.hp = 1; Player.x = 10; Player.y = 5; Game.mapData = MAP_VILLAGE; Game.mapType = 'village'; setTimeout(() => Sound.playBGM('village'), 2000); }
            else if (this.enemy.hp <= 0) { this.end(`${this.enemy.name} を倒した！`); Sound.playSE('win'); }
            else { document.getElementById('quiz-area').style.display = 'none'; document.getElementById('battle-next-btn').style.display = 'block'; }
        }, 1500);
    },
    next() { this.nextQuestion(); },
    end(msg) { this.log(msg); setTimeout(() => { document.getElementById('battle-ui').style.display = 'none'; Game.mode = 'map'; }, 2000); },
    updateUI() {
        document.getElementById('enemy-hp').style.width = Math.max(0, (this.enemy.hp / this.enemy.maxHp) * 100) + "%";
        document.getElementById('player-hp').style.width = Math.max(0, (Player.hp / Player.maxHp) * 100) + "%";
        document.getElementById('player-hp-text').innerText = `HP: ${Math.max(0, Player.hp)}`;
    },
    log(text) { document.getElementById('battle-msg').innerText = text; }
};

const Dialogue = {
    show(name, text) { Game.mode = 'dialogue'; document.getElementById('dialogue-box').style.display = 'block'; document.getElementById('dialogue-text').innerHTML = `<strong style="color:#ffd700">${name}</strong><br>${text}`; },
    next() { document.getElementById('dialogue-box').style.display = 'none'; Game.mode = 'map'; }
};

function draw() {
    ctx.fillStyle = '#000'; ctx.fillRect(0, 0, canvas.width, canvas.height);
    const camX = Math.max(0, Math.min(Player.x * TILE_SIZE - canvas.width / 2 + TILE_SIZE/2, Game.mapData[0].length * TILE_SIZE - canvas.width));
    const camY = Math.max(0, Math.min(Player.y * TILE_SIZE - canvas.height / 2 + TILE_SIZE/2, Game.mapData.length * TILE_SIZE - canvas.height));
    ctx.save(); ctx.translate(-camX, -camY);
    for (let y = 0; y < Game.mapData.length; y++) {
        for (let x = 0; x < Game.mapData[0].length; x++) {
            const tile = Game.mapData[y][x];
            if (tile === 0) drawTile('floor', x, y, '#222');
            if (tile === 1) drawTile('wall', x, y, '#555');
            if (tile === 2) drawTile('villager', x, y, '#ff0');
            if (tile === 3) { drawTile('floor', x, y, '#222'); ctx.font="20px sans-serif"; ctx.fillStyle="#fff"; ctx.fillText("INN", x*TILE_SIZE+5, y*TILE_SIZE+30); }
            if (tile === 4) drawTile('boss', x, y, '#90f');
            if (tile === 5) { ctx.fillStyle='#afa'; ctx.fillRect(x*TILE_SIZE, y*TILE_SIZE, TILE_SIZE, TILE_SIZE); }
        }
    }
    const heroKey = `hero_${Player.dir}`;
    drawTile(heroKey, Player.x, Player.y, '#4db8ff');
    ctx.restore();
    requestAnimationFrame(draw);
};
draw();
</script>
</body>

</html>

