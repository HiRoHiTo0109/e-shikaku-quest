<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">
    <title>E資格クエスト RPG</title>
    <style>
        @import url('https://fonts.googleapis.com/css2?family=DotGothic16&display=swap');

        :root {
            --bg-color: #050505;
            --win-bg: #111;
            --text-color: #e0e0e0;
            --accent-color: #4db8ff;
            --danger-color: #ff4444;
            --sage-color: #ffd700;
            --base-font-size: 16px;
            --btn-padding: 12px;
            --window-width: 750px;
            --char-size: 220px;
        }

        @media (max-width: 600px) {
            :root {
                --base-font-size: 14px;
                --btn-padding: 16px;
                --window-width: 100%;
                --char-size: 130px;
            }
            .game-window { height: 100dvh; border-radius: 0 !important; border:none !important;}
            .stage-grid { grid-template-columns: 1fr 1fr !important; }
        }

        body {
            background-color: var(--bg-color); color: var(--text-color);
            font-family: 'DotGothic16', sans-serif; font-size: var(--base-font-size);
            display: flex; flex-direction: column; align-items: center; justify-content: flex-start;
            height: 100vh; margin: 0; overflow: hidden; touch-action: none;
        }

        /* ゲーム画面 */
        #game-wrapper {
            position: relative; width: 100%; max-width: 480px; aspect-ratio: 1 / 1;
            border: 2px solid #fff; background-color: #000; margin-bottom: 10px;
        }
        canvas { display: block; width: 100%; height: 100%; }

        /* コントローラー */
        #controller {
            width: 100%; max-width: 480px; height: 180px;
            display: grid; grid-template-columns: 1fr 1fr; padding: 10px;
            box-sizing: border-box; background: #222; border-top: 2px solid #555;
        }
        .d-pad {
            display: grid; grid-template-areas: ". up ." "left . right" ". down .";
            gap: 5px; width: 150px; height: 150px; justify-self: center; align-self: center;
        }
        .d-btn {
            width: 50px; height: 50px; background: rgba(255, 255, 255, 0.15);
            border: 2px solid rgba(255, 255, 255, 0.5); border-radius: 8px;
            display: flex; justify-content: center; align-items: center;
            font-size: 1.5rem; user-select: none; cursor: pointer;
        }
        .d-btn:active { background: rgba(255, 255, 255, 0.5); }
        .action-pad { display: flex; justify-content: center; align-items: center; }
        .a-btn {
            width: 80px; height: 80px; background: rgba(255, 100, 100, 0.3);
            border: 4px solid rgba(255, 100, 100, 0.8); border-radius: 50%;
            display: flex; justify-content: center; align-items: center;
            font-size: 1.5rem; font-weight: bold; user-select: none; cursor: pointer;
        }
        .a-btn:active { background: rgba(255, 100, 100, 0.6); }

        /* UIオーバーレイ */
        .overlay {
            position: absolute; bottom: 10px; left: 10px; right: 10px;
            background: rgba(0, 0, 0, 0.9); border: 2px solid #fff; border-radius: 8px;
            padding: 15px; display: none; font-size: 1rem; line-height: 1.5; z-index: 10;
        }
        #battle-ui { top: 10px; bottom: 10px; display: none; flex-direction: column; justify-content: space-between; }
        .hp-bar-frame { width: 100%; height: 10px; background: #333; border: 1px solid #fff; margin-bottom: 5px; }
        .hp-bar-fill { height: 100%; width: 100%; transition: width 0.2s; }
        .hp-green { background: #0f0; } .hp-red { background: #f00; }
        .enemy-display { flex-grow: 1; display: flex; flex-direction: column; align-items: center; justify-content: center; }
        .enemy-img-large { width: 120px; height: 120px; object-fit: contain; image-rendering: pixelated; filter: drop-shadow(0 0 10px red); }
        .quiz-options { display: grid; grid-template-columns: 1fr 1fr; gap: 8px; margin-top: 10px; }
        .btn { background: #222; color: white; border: 2px solid #fff; padding: 10px; font-family: inherit; cursor: pointer; text-align: left; }
        .btn.correct { background: #050; border-color: #0f0; } .btn.wrong { background: #500; border-color: #f00; }

        /* スタート画面 */
        #start-screen {
            position: absolute; inset: 0; background: #000; z-index: 100;
            display: flex; flex-direction: column; align-items: center; justify-content: center;
        }
        #start-btn { padding: 20px 40px; font-size: 1.5rem; border: 2px solid #fff; background: #222; color: #fff; cursor: pointer; }

    </style>
</head>
<body>

<div id="game-wrapper">
    <canvas id="gameCanvas" width="480" height="480"></canvas>

    <div id="start-screen">
        <h1 style="color:#4db8ff; margin-bottom:20px;">E資格クエスト</h1>
        <button id="start-btn" onclick="startGame()">GAME START</button>
        <p style="color:#888; margin-top:10px;">(音が出ます)</p>
    </div>

    <div id="dialogue-box" class="overlay">
        <div id="dialogue-text">...</div>
        <div style="text-align: right; font-size: 0.8rem; color: #aaa; margin-top:5px;">▼ 進む(Aボタン)</div>
    </div>

    <div id="battle-ui" class="overlay">
        <div>
            <div id="enemy-name">スライム</div>
            <div class="hp-bar-frame"><div id="enemy-hp" class="hp-bar-fill hp-red"></div></div>
        </div>
        <div class="enemy-display">
            <img id="battle-enemy-img" src="" alt="ENEMY" class="enemy-img-large">
            <div id="battle-msg" style="margin-top: 10px; min-height: 1.5em; text-align: center;">現れた！</div>
        </div>
        <div>
            <div style="display: flex; justify-content: space-between;"><span>勇者</span><span id="player-hp-text">HP: 100</span></div>
            <div class="hp-bar-frame"><div id="player-hp" class="hp-bar-fill hp-green"></div></div>
            <div id="quiz-area" style="display:none; margin-top: 10px;">
                <div id="quiz-text" style="margin-bottom:5px; font-size:0.95rem;">問題</div>
                <div id="quiz-options" class="quiz-options"></div>
            </div>
            <button id="battle-next-btn" class="btn" style="width:100%; display:none; text-align:center;" onclick="Battle.next()">次へ</button>
        </div>
    </div>
</div>

<div id="controller">
    <div class="d-pad">
        <div class="d-btn" style="grid-area: up;" ontouchstart="Input.startMove(0, -1)" onmousedown="Input.startMove(0, -1)" ontouchend="Input.stopMove()" onmouseup="Input.stopMove()">↑</div>
        <div class="d-btn" style="grid-area: left;" ontouchstart="Input.startMove(-1, 0)" onmousedown="Input.startMove(-1, 0)" ontouchend="Input.stopMove()" onmouseup="Input.stopMove()">←</div>
        <div class="d-btn" style="grid-area: right;" ontouchstart="Input.startMove(1, 0)" onmousedown="Input.startMove(1, 0)" ontouchend="Input.stopMove()" onmouseup="Input.stopMove()">→</div>
        <div class="d-btn" style="grid-area: down;" ontouchstart="Input.startMove(0, 1)" onmousedown="Input.startMove(0, 1)" ontouchend="Input.stopMove()" onmouseup="Input.stopMove()">↓</div>
    </div>
    <div class="action-pad">
        <div class="a-btn" onclick="Input.triggerAction()">A</div>
    </div>
</div>

<script>
// --- 画像設定 (4方向に対応) ---
const IMAGES = {
    // 勇者の4方向
    hero_down: "hero_down.png",
    hero_up: "hero_up.png",
    hero_left: "hero_left.png",
    hero_right: "hero_right.png",
    
    // その他
    villager: "sage.png",
    slime: "slime.png",
    boss: "boss.png",
    floor: "floor.png",
    wall: "wall.png"
};

// --- 問題データ (前回のデータをコピペしてください) ---
const DB = [
    { sid: 13, q: 'CNNのプーリング層の役割は？', a: ['位置ズレ不変性の獲得', '特徴強調', 'ch数変更', '非線形変換'], exp: '微小な平行移動を吸収します。' },
    { sid: 1, q: '行列Aの固有値をλ、固有ベクトルをxとした時、成り立つ式は？', a: ['Ax = λx', 'Ax = x + λ', 'A = λx', 'x = Aλ'], exp: '固有値定義の基本です。' }
];

const LECTURES = {
    1: [
        "【線形代数：行列の基礎】\n行列の積 AB が計算できるのは、「Aの列数」と「Bの行数」が一致する時だけじゃ。\n結果のサイズは (Aの行数 × Bの列数) になるぞ。",
        "【逆行列】\n行列 A に掛けると単位行列 I になる行列のことじゃ。\n「ad - bc = 0」つまり行列式(det)が0の時は、逆行列が存在しない（特異行列という）ぞ。",
        "【固有値と固有ベクトル】\n「Ax = λx」を満たす数λとベクトルxのことじゃ。\n行列を掛けても「向きが変わらず、長さだけがλ倍になる」特別なベクトルなんじゃよ。",
        "【特異値分解 (SVD)】\nどんな行列でも「A = UΣV^T」の形に分解できる最強のツールじゃ。\n画像圧縮や、推薦システム、自然言語処理のLSAなど、応用範囲は無限大じゃ。",
        "【擬似逆行列（ムーア・ペンローズ）】\n正方行列じゃなくても逆行列のような働きをする行列じゃ。\n逆行列がない時の救世主じゃな。",
        "【ノルム】\nベクトルの「大きさ」を表すものじゃ。\nL1ノルムは「絶対値の和」（マンハッタン距離）。\nL2ノルムは「二乗和のルート」（ユークリッド距離）。スパース化したいならL1を使え。",
        "【スカラーとベクトル (Scalar & Vector)】\n数は単体では「スカラー」、縦や横に並べば「ベクトル」と呼ぶ。データの並びを矢印としてイメージするのじゃ。",
        "【行列 (Matrix)】\n数を長方形に並べたものじゃ。画像データもピクセルの並びであるゆえ、AIにとって行列計算は基本中の基本じゃぞ。",
        "【行列の積 (Matrix Multiplication)】\n行列同士の掛け算は「左の行」と「右の列」を順に掛けて足すのじゃ。形が合わねば計算できぬぞ。",
        "【転置行列 (Transpose)】\n行と列を入れ替えた行列じゃ。右上にTと書く。データの向きを変える時によく使う術式じゃな。",
        "【単位行列 (Identity Matrix)】\n掛けても値が変わらぬ不思議な行列じゃ。数字で言う「1」と同じ役割を持つ。対角線だけが1で他は0じゃ。",
        "【逆行列 (Inverse Matrix)】\n掛けると単位行列になる行列じゃ。数字で言う「逆数（割り算）」のようなものだが、必ず存在するとは限らぬぞ。",
        "【行列式 (Determinant)】\n行列の「体積の拡大率」を表す値じゃ。これが0だとペチャンコに潰れておるゆえ、逆行列が存在せぬのじゃ。",
        "【固有値と固有ベクトル (Eigenvalue & Eigenvector)】\n行列を掛けても「向きが変わらず長さだけ変わる」特別なベクトルと、その倍率のことじゃ。",
        "【特異値分解 (SVD)】\n正方形でない行列でも分解できる強力な術じゃ。データの重要な成分だけを取り出す際などに使われるぞ。",
        "【ノルム (Norm)】\nベクトルの「大きさ」や「距離」を測る尺度じゃ。L1ノルム、L2ノルムなど種類があり、正則化で活躍するぞ。",
        "【テンソルの作成】\nNumPy配列から変換するには `torch.from_numpy()` を使うのじゃ。\nGPUに乗せるなら `.to('cuda')` や `.cuda()` を忘れるでないぞ。",
        "【形状変換の基本】\n`reshape` もあるが、PyTorchでは `view` を使うのが伝統じゃ。\nただしメモリが連続していないとエラーになるゆえ、その時は `.contiguous().view()` と唱えるのじゃ。",
        "【行列積】\n行列同士の掛け算は `torch.matmul(A, B)` または `A @ B` と書くのが現代の作法じゃ。\n`A * B` だと要素ごとの掛け算（アダマール積）になってしまうから注意せよ。",
        "【次元の操作】\n次元を増やす `unsqueeze`、減らす `squeeze` は頻出じゃ。\n`unsqueeze(0)` でバッチ次元を追加する技は、画像を1枚だけ推論する時によく使うぞ。"
    ],
    2: [
        "【条件付き確率】\n事象Bが起きた条件下でAが起きる確率は P(A|B) = P(A∩B) / P(B) じゃ。",
        "【ベイズの定理】\n「P(A|B) = P(B|A)P(A) / P(B)」\n結果から原因を探る、AIの根幹をなす式じゃ。\n(事後確率) ∝ (尤度) × (事前確率) と覚えるのじゃ。",
        "【期待値と分散】\n期待値 E[x] は平均的な値。\n分散 V[x] = E[(x - μ)^2] はデータのばらつき具合じゃ。\n「V[x] = E[x^2] - (E[x])^2」という公式は試験によく出るぞ。",
        "【ベルヌーイ分布】\nコイン投げのような「成功か失敗か」の2択の分布じゃ。\n期待値は p、分散は p(1-p) じゃよ。",
        "【二項分布】\nベルヌーイ試行をn回行った時の成功回数の分布じゃ。\nnが大きくpが小さいと「ポアソン分布」に近づき、nが十分大きいと「正規分布」に近づくぞ。",
        "【正規分布（ガウス分布）】\n自然界で最も一般的な、釣り鐘型の分布じゃ。\n平均μと分散σ^2だけで形が決まる。\n標準正規分布は平均0、分散1じゃ。",
        "【確率変数 (Random Variable)】\nサイコロの目のように、確率によって値が決まる変数のことじゃ。大文字Xなどで表されることが多いぞ。",
        "【確率分布 (Probability Distribution)】\nどの値がどのくらいの確率で出るかを表した全体像じゃ。データの癖を見抜く地図のようなものじゃな。",
        "【期待値 (Expectation)】\n確率変数の平均的な値じゃ。「E(X)」と書く。賭け事で言えば、平均していくら儲かるかを示す値じゃ。",
        "【分散と標準偏差 (Variance & Std Dev)】\nデータの「ばらつき具合」を示す値じゃ。分散は2乗しておるゆえ、ルートをとって元の単位に戻したのが標準偏差じゃ。",
        "【ベルヌーイ分布 (Bernoulli Dist.)】\nコイン投げのように「成功か失敗か」の2択しかない場合の分布じゃ。全ての基本となる単純な分布じゃ。",
        "【正規分布 (Normal Dist.)】\n釣鐘型の美しい分布じゃ。自然界の多くのデータ（身長や誤差など）はこの分布に従うと言われておる。",
        "【共分散 (Covariance)】\n2つのデータが「一緒に増えるか、逆の動きをするか」という関係性を表す値じゃ。0ならば関係なし、じゃな。",
        "【相関係数 (Correlation Coefficient)】\n共分散を規格化して -1から+1 の間に収めたものじゃ。+1に近いほど強い正の相関があるぞ。",
        "【ベイズの定理 (Bayes' Theorem)】\n結果から原因の確率を推測する強力な定理じゃ。「事後確率」を求めるために、AIで頻繁に使われるぞ。",
        "【尤度 (Likelihood)】\n「そのデータが得られたもっともらしさ」のことじゃ。確率と似て非なる概念ゆえ、混同するでないぞ。",
        "【乱数の生成】\n標準正規分布（平均0, 分散1）からのサンプリングは `torch.randn()` じゃ。\n一様分布なら `torch.rand()` じゃな。この違い、試験に出るぞ。",
        "【シードの固定】\n再現性を保つには `torch.manual_seed(seed)` を使うのじゃ。\nGPUを使う場合は `torch.cuda.manual_seed()` も必要になることがあるぞ。",
        "【統計量の計算】\n平均は `.mean()`、合計は `.sum()` じゃが、引数に `dim=0` などを渡して\n「どの軸に沿って計算するか」を指定するのがコツじゃ。"
    ],
    3: [
        "【自己情報量】\n「I(x) = -log P(x)」\n確率が低い（珍しい）ことほど、起きた時の情報量（驚き）は大きいのじゃ。",
        "【シャノンエントロピー】\n平均情報量のことじゃ。\n何が起きるか予測できない（ランダムな）時ほど値は大きくなる。\n数式は H(x) = -Σ P(x) log P(x) じゃ。",
        "【KLダイバージェンス】\n2つの確率分布 P と Q の「違い」を測る尺度じゃ。\n距離に似ておるが、P→Q と Q→P の値が違う（非対称）から「距離」とは呼ばないんじゃ。",
        "【交差エントロピー】\n「-Σ P(x) log Q(x)」\n正解分布Pに、予測分布Qを近づけるための損失関数として、分類問題で大活躍するぞ。",
        "【相互情報量】\n「Xを知ることで、Yの不確実性がどれだけ減るか」を表す量じゃ。\nXとYが独立なら0になるぞ。",
        "【情報量 (Information Content)】\n「珍しさ」の度合いじゃ。「太陽が東から昇る」と言われても情報量は低いが、「宇宙人が来た」なら情報量は特大じゃ！",
        "【エントロピー (Entropy)】\n情報の「乱雑さ」や「不確実性」を表す。何が起こるか全くわからぬ状態ほど、エントロピーは高いのじゃ。",
        "【結合エントロピー (Joint Entropy)】\n2つの事象が同時に起こる時の不確実性じゃ。互いに関係があれば、単純な足し算より小さくなるぞ。",
        "【条件付きエントロピー (Conditional Entropy)】\nある事象を知った上で、もう片方の事象がどれくらい不明かを表す値じゃ。",
        "【相互情報量 (Mutual Information)】\n2つの事象がどれだけ情報を共有しているかじゃ。「片方を知ると、もう片方がどれだけ分かるか」の尺度じゃな。",
        "【KLダイバージェンス (KL Divergence)】\n2つの確率分布が「どれくらい似ていないか」を測る距離のようなものじゃ。0ならば完全に一致じゃ。",
        "【交差エントロピー (Cross Entropy)】\n真の分布と、予測した分布のズレを表す。分類問題の損失関数として非常によく使われるぞ。",
        "【シャノンの定理 (Shannon's Theorem)】\n情報理論の父シャノンが定めた、効率よく情報を送るための限界や圧縮の理論じゃ。",
        "【平均情報量】\nエントロピーの別名じゃ。確率分布全体として、平均してどれくらいの情報を持っているかを示す値じゃな。",
        "【最尤推定との関係】\n実は「交差エントロピーを最小化すること」と「尤度を最大化すること」は同じ意味を持つのじゃ。深遠じゃろう？",
        "【対数計算】\n情報量計算に必要な対数は `torch.log()` じゃ。底は $e$ (自然対数) じゃぞ。\n底が2の時は `torch.log2()`、10の時は `torch.log10()` を使い分けるのじゃ。",
        "【微小値の加算】\nlogの中に0が入ると `-inf` になり計算が壊れる。\n`torch.log(x + 1e-10)` のように、微小な値（イプシロン）を足すのが実装の知恵じゃ。"
    ],
    4: [
        "【機械学習の分類】\n・教師あり学習（正解あり：分類・回帰）\n・教師なし学習（正解なし：クラスタリング・次元削減）\n・強化学習（報酬あり：行動最適化）",
        "【過学習 (Overfitting)】\n訓練データに適合しすぎて、未知のデータに対応できない状態じゃ。\nバリアンスが高い状態とも言うぞ。",
        "【未学習 (Underfitting)】\nモデルが単純すぎて、データのパターンを捉えきれていない状態じゃ。\nバイアスが高い状態じゃな。",
        "【バイアス・バリアンス分解】\n誤差は「バイアス（思い込み）の2乗 + バリアンス（変動） + ノイズ」に分解できる。\nこの2つはトレードオフの関係にあるんじゃ。",
        "【交差検証 (Cross Validation)】\nデータをK個に分割して、「学習」と「検証」をK回繰り返す手法じゃ。\nデータが少ない時に、信頼性の高い評価ができるぞ。",
        "【機械学習 (Machine Learning)】\n人間がルールを教えるのではなく、データからコンピュータ自身にルールを学習させる技術じゃ。",
        "【回帰と分類 (Regression & Classification)】\n数値を予測するのが「回帰」、クラス（犬か猫かなど）を当てるのが「分類」じゃ。まずはここを見極めよ。",
        "【汎化性能 (Generalization)】\n未知のデータに対しても正しく答えられる能力じゃ。訓練データだけ100点でも、本番で通用せねば意味がないぞ。",
        "【過学習 (Overfitting)】\n訓練データに適合しすぎて、未知のデータに対応できなくなった状態じゃ。勉強しすぎて応用が利かぬガリ勉状態じゃな。",
        "【バイアスとバリアンス (Bias & Variance)】\nモデルの思い込みの強さ（バイアス）と、データのブレへの過敏さ（バリアンス）のトレードオフ関係じゃ。",
        "【ホールドアウト法 (Hold-out)】\nデータを「訓練用」と「テスト用」に分割する検証法じゃ。カンニングを防ぐための基本じゃぞ。",
        "【k-分割交差検証 (k-fold CV)】\nデータをk個に分け、交代でテストを行う丁寧な検証法じゃ。データが少ない時に特に有効じゃ。",
        "【グリッドサーチ (Grid Search)】\nハイパーパラメータ（設定値）の組み合わせをしらみつぶしに試して、最強の設定を探す力技じゃ。",
        "【正則化 (Regularization)】\nモデルが複雑になりすぎるのを防ぐため、ペナルティを与える術じゃ。過学習を抑える重りをつけるのじゃ。",
        "【ノーフリーランチ定理】\n「あらゆる問題で常に最強のモデルは存在しない」という定理じゃ。状況に合わせて武器（アルゴリズム）を選ぶのじゃ。",
        "【Datasetクラスの継承】\n自作データセットを作るなら `torch.utils.data.Dataset` を継承せよ。\n必須なのは `__len__` (データの個数) と `__getitem__` (データの取り出し) の2つの呪文じゃ。",
        "【DataLoaderの召喚】\nデータをバッチごとに取り出し、シャッフルまでしてくれる `DataLoader` は必須装備じゃ。\n`batch_size` と `shuffle=True` を指定してインスタンス化するのじゃぞ。",
        "【TensorDataset】\n入力データ `x` と正解 `t` が既にTensorとして手元にあるなら、\n`torch.utils.data.TensorDataset(x, t)` を使うと手軽にDataset化できるぞ。"
    ],
    5: [
        "【前処理：欠損値】\nデータが抜けている時は、リストワイズ削除（行ごと消す）や、平均値代入法などで埋めるんじゃ。",
        "【標準化 (Standardization)】\n「(x - 平均) ÷ 標準偏差」で、平均0・分散1に変換する。\n特徴量の単位がバラバラな時に必須じゃ。",
        "【正規化 (Normalization)】\n「(x - 最小) ÷ (最大 - 最小)」で、0〜1の範囲に収める。\n画像データ(0〜255)などでよく使うぞ。",
        "【混同行列】\nTP(真陽性)、TN(真陰性)、FP(偽陽性)、FN(偽陰性)の4つじゃ。\nFPは「狼少年（嘘のアラート）」、FNは「見逃し」じゃな。",
        "【F値 (F1-score)】\n適合率(Precision)と再現率(Recall)の調和平均じゃ。\n「2PR / (P+R)」で計算する。バランスの良いモデルを作りたい時はこれじゃ。",
        "【IoU (Intersection over Union)】\n物体検出などで使う。\n「重なっている面積 ÷ 全体の面積」で、領域のズレを評価するんじゃ。",
        "【欠損値処理 (Missing Values)】\nデータに穴（空欄）がある時、平均値で埋めたり、その行ごと消したりする処置じゃ。ゴミデータはAIの毒じゃ。",
        "【標準化 (Standardization)】\nデータを「平均0、分散1」に整える術じゃ。単位が違うデータ同士を公平に扱うために必須じゃぞ。",
        "【正規化 (Normalization)】\nデータを「0から1の範囲」などに押し込める術じゃ。標準化とは使い分けが必要じゃな。",
        "【One-Hotエンコーディング】\n「赤・青・緑」のようなカテゴリを「1,0,0」「0,1,0」のような0と1の並びに変換する術じゃ。",
        "【白色化 (Whitening)】\nデータ間の相関を無くし、さらにスケールも揃える高度な前処理じゃ。画像処理などで効果を発揮するぞ。",
        "【主成分分析 (PCA)】\nデータの特徴を残しつつ、次元（項目数）を減らす圧縮術じゃ。情報を要約して扱いやすくするのじゃ。",
        "【多重共線性 (Multicollinearity)】\n似たような変数が複数あると計算がおかしくなる現象じゃ。「マルチコ」と略される。相関の高い変数は整理せよ。",
        "【不均衡データ (Imbalanced Data)】\n「正例が極端に少ない」などの偏ったデータじゃ。そのまま学習させると、多数派ばかり答えるAIになるぞ。",
        "【オーバーサンプリング】\n少ない方のデータをコピーして増やす術じゃ。逆に多い方を減らすのをアンダーサンプリングと言うぞ。",
        "【データ拡張 (Data Augmentation)】\n画像を回転させたりずらしたりして、擬似的にデータを水増しする秘術じゃ。深層学習で強力な効果がある。",
        "【Transformsの連結】\n画像の前処理は `torchvision.transforms` を使うのが定石じゃ。\n複数の処理は `transforms.Compose([...])` で鎖のように繋ぐことができるぞ。",
        "【正規化の実装】\n`transforms.Normalize(mean, std)` は、テンソル化した後に使うのじゃ。\nつまり `ToTensor()` の後に書かねばエラーになる。順序を間違えるでないぞ。",
        "【One-Hot化】\nクラスIDをOne-Hotベクトルにするには `F.one_hot(input, num_classes)` が便利じゃ。\nただし、CrossEntropyLossを使うなら、正解ラベルはOne-HotにせずクラスIDのままで良いことが多いぞ。"
    ],
    6: [
        "【正則化】\n損失関数にペナルティ項を加えて、過学習を防ぐ技術じゃ。\nモデルをあえて「単純」にするんじゃよ。",
        "【L1正則化 (Lasso)】\n重みの絶対値を足す。\n不要な重みが「完全に0」になるので、特徴選択（変数を減らす）効果があるぞ。",
        "【L2正則化 (Ridge)】\n重みの二乗を足す（Weight Decay）。\n重みが極端に大きくなるのを防ぎ、滑らかなモデルにするんじゃ。",
        "【グリッドサーチ】\nハイパーパラメータの組み合わせを「しらみつぶし」に全部試す。\n確実じゃが、時間がかかるのが欠点じゃ。",
        "【ランダムサーチ】\nパラメータをランダムに選んで試す。\n実はグリッドサーチより効率が良いことが多いんじゃよ。",
        "【ベイズ最適化】\nこれまでの結果から「次はここを試すべき」と予測しながら探索する、賢い方法じゃ。",
        "【混同行列 (Confusion Matrix)】\n予測の結果を「真陽性・偽陽性・真陰性・偽陰性」の4マスで整理した表じゃ。評価の基本じゃな。",
        "【正解率 (Accuracy)】\n全体のうち、どれだけ正解したかの割合じゃ。データが偏っていると、これだけでは信用できぬぞ。",
        "【適合率 (Precision)】\n「陽性」と予測したもののうち、本当に陽性だった割合じゃ。誤検知を減らしたい時に重視せよ。",
        "【再現率 (Recall)】\n実際の「陽性」のうち、見逃さずに陽性と予測できた割合じゃ。取りこぼしを防ぎたい時に見るのじゃ。",
        "【F値 (F-measure)】\n適合率と再現率はトレードオフゆえ、その調和平均をとった総合的なスコアじゃ。",
        "【ROC曲線とAUC】\n判定の基準を動かした時の性能変化をグラフにしたものじゃ。曲線の下の面積(AUC)が1に近いほど優秀じゃ。",
        "【L1正則化 (Lasso)】\n不要なパラメータをきっぱり「0」にする性質がある。特徴量選択の効果も期待できる鋭いナイフのような術じゃ。",
        "【L2正則化 (Ridge)】\nパラメータが大きくなりすぎるのを防ぐが、0にはせぬ。全体を滑らかに抑え込む、重厚な鎧のような術じゃ。",
        "【ドロップアウト (Dropout)】\n学習中にランダムにニューロンを無効化する術じゃ。わざと過酷な環境で訓練し、過学習を防ぐのじゃ。",
        "【アーリーストップ (Early Stopping)】\n性能が上がらなくなったら、学習を途中で打ち切る術じゃ。やりすぎは過学習の元ゆえ、引き際が肝心じゃ。",
        "【勾配計算の封印】\n評価（推論）時は学習せぬゆえ、メモリ節約のために `with torch.no_grad():` ブロックを作るのじゃ。\nこれを忘れるとメモリ不足で落ちることがあるぞ。",
        "【正解数のカウント】\n予測確率が最大のクラスを知るには `outputs.argmax(dim=1)` を使うのじゃ。\nこれと正解ラベルを `(pred == labels).sum().item()` で比較すれば正解数が求まるぞ。",
        "【item()の使い道】\n損失(Loss)などのTensorから、Pythonの数値(float)を取り出すには `.item()` を使うのじゃ。\nこれをせず累積すると、計算グラフが繋がり続けてメモリを食いつぶすぞ。",
        "【検証時のモード切替 (no_grad)】\n検証（Validation）データの評価中に勾配を計算する必要はない。\n`with torch.no_grad():` で囲って勾配計算を封印せよ。\nこれをせねば、メモリを無駄食いし、評価計算も遅くなる一方じゃぞ。"
    ],
    7: [
        "【ロジスティック回帰】\n線形回帰の結果を「シグモイド関数」に通して、確率(0~1)にする。\n2値分類の基本じゃな。",
        "【SVM (サポートベクターマシン)】\nデータ間の「マージン（隙間）」を最大化する境界線を引く。\nカーネル法を使えば、直線で分けられないデータも分類できるぞ。",
        "【決定木】\n「ジニ不純度」や「エントロピー」が下がるように、条件分岐を作っていく。\n人間にも解釈しやすいが、過学習しやすいのが玉に瑕じゃ。",
        "【ランダムフォレスト】\nバギング（データを変えて学習）と、特徴量のランダム選択を組み合わせた最強クラスのアルゴリズムじゃ。\nたくさんの木の多数決をとるぞ。",
        "【ブースティング (GBDT等)】\n前のモデルが間違えたところを、次のモデルが重点的に直す。\nXGBoostやLightGBMはコンペでも常連じゃな。",
        "【線形回帰 (Linear Regression)】\nデータを最もよく表す「直線」を引く、基本のアルゴリズムじゃ。最小二乗法などを使って解くぞ。",
        "【ロジスティック回帰 (Logistic Regression)】\n名前は回帰じゃが、実は「分類」のための手法じゃ。シグモイド関数を使い、確率を出力するぞ。",
        "【サポートベクターマシン (SVM)】\nデータの間隔（マージン）が最大になるように境界線を引く手法じゃ。カーネル法を使えば曲線も引けるぞ。",
        "【決定木 (Decision Tree)】\n「Yes/No」で条件分岐を繰り返して分類する手法じゃ。中身が解釈しやすいのが利点じゃな。",
        "【ランダムフォレスト (Random Forest)】\nたくさんの決定木を作り、多数決をとる「アンサンブル学習」の代表格じゃ。森は木より賢いのじゃ。",
        "【ブースティング (Boosting)】\n弱点を持ったモデルを次々に強化・修正していく手法じゃ。XGBoostやLightGBMなどが有名で、非常に強力じゃぞ。",
        "【k近傍法 (k-NN)】\n近くにあるk個のデータの多数決で自分のクラスを決める、単純だが直感的な手法じゃ。",
        "【ナイーブベイズ (Naive Bayes)】\nベイズの定理と「変数は互いに独立」という仮定を使った確率的な分類器じゃ。スパムメール判定などで有名じゃ。",
        "【勾配ブースティング決定木 (GBDT)】\n決定木を勾配降下法のように継ぎ足していく強力な手法じゃ。コンペティションでの常勝アルゴリズムじゃ。",
        "【アンサンブル学習 (Ensemble)】\n複数のモデルを組み合わせて性能を上げる総称じゃ。「三人寄れば文殊の知恵」をAIで行うのじゃ。",
        "【全結合層】\n基本の層は `nn.Linear(in_features, out_features)` じゃ。\n入力データの形は `(Batch_Size, in_features)` になっている必要があるぞ。",
        "【パラメータへのアクセス】\n層の重みは `.weight`、バイアスは `.bias` でアクセスできる。\n`.parameters()` を使えば、モデル内の全パラメータをイテレータとして取得できるぞ。"
    ],
    8: [
        "【k-means法】\nデータをk個のクラスタに分ける。\n1. 中心を決める 2. 近いデータを集める 3. 中心を更新する...を繰り返すんじゃ。\n初期値に依存するのが欠点じゃな（k-means++で解決するぞ）。",
        "【主成分分析 (PCA)】\nデータの「分散」が最大になる方向（主成分）を見つけて、次元を減らす。\n「寄与率」を見れば、どれくらい情報を残せたかが分かるぞ。",
        "【白色化】\nデータ間の相関をなくし（無相関化）、さらに分散を1にする処理じゃ。",
        "【t-SNE】\n高次元データの「近さ」を保ったまま、2次元や3次元に圧縮する。\nデータの可視化によく使われるが、距離の意味は保たれないので注意じゃ。",
        "【教師なし学習 (Unsupervised Learning)】\n正解データを与えず、データそのものの構造やパターンをAIに見つけさせる手法じゃ。",
        "【k-means法】\nデータをk個のグループ（クラスタ）に分ける代表的な手法じゃ。中心点を動かしながらグループを最適化するぞ。",
        "【k-means++】\nk-meansの弱点である「最初の中心点の位置」を工夫して決め、安定させる改良版じゃ。",
        "【階層的クラスタリング】\nデータを似たもの同士で順にまとめていき、樹形図（デンドログラム）を作る手法じゃ。分類の過程が見えるぞ。",
        "【t-SNE】\n高次元のデータを2次元や3次元に圧縮して可視化するための手法じゃ。データの「近さ」を保つのが得意じゃ。",
        "【主成分分析 (PCA) の応用】\n教師なし学習の一種として、データの次元圧縮やノイズ除去に使われるぞ。おさらいじゃな。",
        "【特異値分解 (SVD) の応用】\n推薦システムなどで、ユーザーと商品の行列を分解して隠れた好みを見つけるのに使われるぞ。",
        "【アソシエーション分析】\n「おむつを買う人はビールも買う」といった、データ間の意外な関連ルールを見つける手法じゃ。",
        "【ガウス混合モデル (GMM)】\nデータが複数の正規分布の組み合わせでできていると仮定して分類する、確率的なクラスタリングじゃ。",
        "【異常検知 (Anomaly Detection)】\n多数の正常データから外れた「異常」を見つける技術じゃ。教師なし学習が輝く分野の一つじゃな。",
        "【ペアワイズ距離】\nk-meansなどで点同士の距離を一気に計算したいときは `torch.cdist(x1, x2)` が速いぞ。\nfor文で距離を計算するのはPythonが遅くなる原因ゆえ、避けるのが賢者じゃ。",
        "【特異値分解】\nPCAなどを実装する際の特異値分解は `torch.linalg.svd()` を使うのじゃ。\n戻り値は U, S, Vh の3つじゃ。以前は `torch.svd` だったが、今は `linalg` モジュール推奨じゃぞ。"
    ],
    9: [
        "【マルコフ決定過程 (MDP)】\n状態S、行動A、遷移確率P、報酬R、割引率γで定義される世界じゃ。\n次の状態は「今の状態と行動」だけで決まる（マルコフ性）と仮定するぞ。",
        "【ベルマン方程式】\n「今の価値 ＝ 即時報酬 ＋ 割引された未来の価値」\nという再帰的な関係式じゃ。強化学習の魂じゃな。",
        "【価値関数】\n状態価値関数 V(s)：その場所にいることの価値。\n行動価値関数 Q(s,a)：その場所で、ある行動をすることの価値。",
        "【方策勾配法】\n方策（行動の確率）を直接パラメータ化して学習する。\n「REINFORCE」などが有名じゃな。",
        "【Q学習】\nQテーブルを更新していく手法じゃ。\nOff-policy（探索とは別の最適な動きを想定して学習する）なのが特徴じゃ。",
        "【強化学習 (Reinforcement Learning)】\nエージェントが試行錯誤し、報酬を最大化するように行動を学習する仕組みじゃ。",
        "【エージェントと環境 (Agent & Environment)】\n行動する主体が「エージェント」、その舞台が「環境」じゃ。マリオとゲームステージの関係じゃな。",
        "【状態・行動・報酬 (State, Action, Reward)】\n今の状況(S)、何をするか(A)、その結果もらえるご褒美(R)。これが強化学習の3要素じゃ。",
        "【マルコフ決定過程 (MDP)】\n次の状態は「今の状態」と「今の行動」だけで決まる、という仮定じゃ。過去は振り返らぬ、それがMDPじゃ。",
        "【方策 (Policy / π)】\nある状態でどう行動するかを決める戦略のことじゃ。これを最適化するのが最終目標じゃぞ。",
        "【価値関数 (Value Function)】\n「この状態にいると将来どれくらい報酬が貰えそうか」を見積もる関数じゃ。目先の報酬だけでなく未来を見るのじゃ。",
        "【活用と探索 (Exploitation & Exploration)】\n知っている最良の手を使うか(活用)、未知の可能性を試すか(探索)。このバランスが重要じゃ。",
        "【割引率 (Discount Factor)】\n将来の報酬をどれくらい割り引いて評価するかじゃ。今の1万円と1年後の1万円は価値が違うゆえな。",
        "【モンテカルロ法】\nエピソードが終わるまでプレイして、その結果から価値を学習する方法じゃ。習うより慣れろ、じゃな。",
        "【TD学習 (Temporal Difference)】\n行動するたびに、予測と現実のズレを修正していく方法じゃ。ゴールを待たずに学習できるのが強みじゃ。",
        "【カテゴリカル分布】\n方策勾配法などで、確率に基づいて行動を選ぶなら `torch.distributions.Categorical(probs)` じゃ。\n作った分布から `.sample()` すれば、確率に従ったインデックスが得られるぞ。",
        "【勾配の切り離し】\n強化学習では目標値（Target）を固定することがある。\nその時は `.detach()` を使って計算グラフを切るのじゃ。さもなくば意図せぬバックプロパゲーションが走るぞ。"
    ],
    10: [
        "【単純パーセプトロン】\n入力を重み付けして足し合わせ、ステップ関数で0か1を出す。\n線形分離可能な問題しか解けず、XOR問題が解けないことで冬の時代を招いたんじゃ。",
        "【多層パーセプトロン (MLP)】\n隠れ層を増やし、活性化関数を非線形にすることで、どんな関数も近似できるようになった（万能近似定理）。",
        "【活性化関数】\n・Sigmoid：0〜1。勾配消失しやすい。\n・Tanh：-1〜1。中心が0で学習しやすい。\n・ReLU：正ならそのまま、負なら0。現在の主流じゃ。計算が速く勾配消失しにくい。",
        "【ニューロンモデル】\n脳の神経細胞を数式で模したものじゃ。入力を重み付けして足し合わせ、発火するかを決めるのじゃ。",
        "【パーセプトロン (Perceptron)】\n複数の入力を受け取り、0か1を出力する単純な識別器じゃ。ニューラルネットワークの祖先じゃな。",
        "【多層パーセプトロン (MLP)】\n層を重ねることで、より複雑な境界線を引けるようになったモデルじゃ。ここから深層学習が始まったのじゃ。",
        "【活性化関数 (Activation Function)】\nニューロンの出力を調整する関数じゃ。これがないと、いくら層を重ねても単純な計算にしかならぬぞ。",
        "【シグモイド関数 (Sigmoid)】\n入力を0から1の間に滑らかに押し込める関数じゃ。昔は主役だったが、勾配消失の問題がある。",
        "【ReLU (Rectified Linear Unit)】\n入力が0以下なら0、正ならそのまま通す関数じゃ。計算が速く学習しやすい、現代の主役じゃ。",
        "【ソフトマックス関数 (Softmax)】\n出力層で使われ、全出力の合計が1（確率）になるように変換する関数じゃ。分類問題の仕上げに使うぞ。",
        "【万能近似定理】\n「層を深く広くすれば、どんな複雑な関数でも近似できる」という定理じゃ。ニューラルネットの可能性を示す証明じゃ。",
        "【ディープラーニング (Deep Learning)】\n中間層を非常に深くしたニューラルネットワークのことじゃ。特徴量を自動で抽出できるのが革命的だったのじゃ。",
        "【勾配消失問題】\n層が深すぎると、誤差の情報が伝わる途中で消えてしまい、学習が進まなくなる難問じゃ。",
        "【nn.Moduleの継承】\n深層学習モデルを作るなら `nn.Module` を継承するクラスを作るのがPyTorchの流儀じゃ。\n`super().__init__()` を書き忘れると、初期化に失敗してエラーになるから注意せよ。",
        "【forwardメソッド】\n順伝播の処理は必ず `forward(self, x)` という名前のメソッドに書くのじゃ。\nモデルインスタンス `model(x)` を呼ぶと、内部で自動的にこの `forward` が実行される仕組みじゃぞ。",
        "【Sequential】\n複雑な分岐がない一直線のモデルなら、クラス定義せずとも `nn.Sequential` で層を並べるだけで作れるぞ。\n手っ取り早く試したい時に有効じゃ。"
    ],
    11: [
        "【順伝播 (Forward)】\n入力データを行列計算しながら出口まで運ぶ。\n推論時はこれだけでOKじゃ。",
        "【誤差逆伝播法 (Backpropagation)】\n出力の誤差を、入力方向へ逆戻りさせて、各パラメータの責任（勾配）を計算する。\n「連鎖律」が鍵じゃ。",
        "【連鎖律 (Chain Rule)】\n合成関数の微分は、個々の微分の掛け算になる。\n∂L/∂x = ∂L/∂y × ∂y/∂x じゃ。",
        "【勾配消失問題】\n層が深くなると、逆伝播する勾配がどんどん小さくなり、入力層付近で学習が止まってしまう現象じゃ。\nSigmoid関数で起きやすいぞ。",
        "【順伝播 (Forward Propagation)】\n入力から出力に向かってデータを流し、予測値を計算するプロセスじゃ。推論時はこれだけでよい。",
        "【損失関数 (Loss Function)】\n正解と予測が「どれくらいズレているか」を測る関数じゃ。この値を最小にすることが学習の目的じゃ。",
        "【勾配降下法 (Gradient Descent)】\n損失関数の坂道を下るように、パラメータを少しずつ修正する方法じゃ。暗闇で谷底を目指すようなものじゃ。",
        "【誤差逆伝播法 (Backpropagation)】\n出力のズレ（誤差）を入力側へ逆流させ、各パラメータの責任（勾配）を効率よく計算する秘術じゃ。",
        "【連鎖律 (Chain Rule)】\n合成関数の微分を行うための数学的ルールじゃ。逆伝播法は、この連鎖律を応用しているに過ぎぬ。",
        "【計算グラフ (Computational Graph)】\n計算の過程をノードとエッジで図示したものじゃ。これを使うと逆伝播の流れが視覚的に分かるぞ。",
        "【学習率 (Learning Rate)】\n一回の修正でどれくらいパラメータを動かすかの設定値じゃ。大きすぎると発散し、小さすぎると進まぬ。",
        "【イテレーションとエポック】\n重みの更新回数がイテレーション、訓練データを一通り使い切るのが1エポックじゃ。用語を混同するでないぞ。",
        "【バッチサイズ】\n一度の学習に使うデータの数じゃ。まとめて計算することで効率を上げるのじゃ。",
        "【勾配爆発】\n勾配消失とは逆に、計算途中で値が巨大になりすぎて計算不能になる現象じゃ。クリッピングなどで防ぐのじゃ。",
        "【逆伝播の発動】\n損失（スカラー値）に対して `loss.backward()` を唱えると、全パラメータの勾配が計算される。\n計算された勾配は各パラメータの `.grad` 属性に格納されるのじゃ。",
        "【勾配の累積】\nPyTorchはデフォルトで勾配を「足し算」して貯めていく仕様じゃ。\nゆえに、学習ループの最初で必ず勾配をリセットせねばならぬ。これが次のステージの重要ポイントじゃ。",
        "【逆伝播のタイミング (backward)】\n損失 `loss` を計算したら、間髪入れずに `loss.backward()` を唱えるのじゃ。\nこれを行わねばパラメータの更新量（勾配）が計算されぬ。`optimizer.step()` を呼んでも、モデルは一歩も動かぬぞ。",
        "【損失値の記録 (.item)】\n「エポックごとの損失」を記録しようとして `loss_list.append(loss)` などと書いてはおらぬか？\nそれは計算グラフごと保存する自殺行為（メモリリーク）じゃ！\n必ず `loss.item()` を使って、TensorからPythonの数値（float）だけを抽出して保存するのじゃぞ。"
    ],
    12: [
        "【勾配降下法】\nw ← w - η(∂L/∂w)\n勾配の逆方向へ、学習率ηの歩幅で進むんじゃ。",
        "【SGD】\n毎回ランダムに1つのデータだけ見て更新する。\n計算は速いが、ジグザグに進んでしまうぞ。",
        "【Momentum】\n「慣性」項を追加する。過去の移動方向を維持するので、振動を抑えて加速できるんじゃ。",
        "【AdaGrad】\nよく更新されるパラメータの学習率を下げ、あまり更新されないものは上げる。\n学習が進むと学習率が0になりすぎて止まるのが欠点じゃ。",
        "【RMSprop】\nAdaGradの欠点を修正し、過去の情報を徐々に忘れるようにした手法じゃ。",
        "【Adam】\nMomentumとRMSpropのいいとこ取りじゃ。\n迷ったらとりあえずAdamを使っておけば間違いはないぞ。",
        "【SGD (Stochastic Gradient Descent)】\n確率的勾配降下法。データを1つずつランダムに選んで学習する。ふらつくが、局所解に陥りにくいぞ。",
        "【ミニバッチSGD】\nデータを小分け（ミニバッチ）にして学習する、今の主流じゃ。計算効率と安定性のバランスが良いのじゃ。",
        "【モーメンタム (Momentum)】\n「慣性」の概念を取り入れた手法じゃ。坂道を転がるボールのように、勢いをつけて学習を加速させるぞ。",
        "【AdaGrad】\n学習が進んだパラメータの学習率を自動で下げていく手法じゃ。あまり更新されない変数を重視する賢い奴じゃ。",
        "【RMSprop】\nAdaGradの「学習率が下がりすぎて止まる」欠点を改良した手法じゃ。過去の情報を適度に忘れる工夫がある。",
        "【Adam】\nモーメンタムとRMSpropの長所を組み合わせた、現在最強クラスの最適化手法じゃ。まずはこれを使ってみるのが定石じゃ。",
        "【大域的最適解と局所最適解】\n本当の谷底（大域）と、途中にある窪み（局所）。AIは局所解にハマりやすいが、上手く脱出せねばならぬ。",
        "【鞍点 (Saddle Point)】\nある方向から見れば谷だが、別の方向からは山に見える地点じゃ。ここでの停滞が学習の敵となることが多い。",
        "【重みの初期化 (Weight Initialization)】\n学習開始時のパラメータの値じゃ。XavierやHeの初期値など、適切な値で始めないと学習が進まぬぞ。",
        "【バッチ正規化 (Batch Normalization)】\n層の間でデータを正規化して整える技術じゃ。学習が爆速になり、過学習も抑える凄い術じゃ。",
        "【オプティマイザの定義】\n`optimizer = torch.optim.Adam(model.parameters(), lr=0.001)` のように定義する。\n第一引数には「更新したいパラメータ」を渡す必要があるぞ。",
        "【ゼロ・グラドの儀式】\nバックプロパゲーションの前には必ず `optimizer.zero_grad()` を唱えて勾配を0に戻すのじゃ。\nこれを忘れると、過去の勾配が足され続けて学習が破綻するぞ。",
        "【更新の実行】\n勾配計算後、`optimizer.step()` を呼ぶことで、実際にパラメータの値が書き換わる。\n`zero_grad` → `backward` → `step` 。この3ステップが学習の1セットじゃ。",
        "【勾配のリセット (zero_grad)】\nループの先頭で `optimizer.zero_grad()` を書き忘れる者が後を絶たん。\nPyTorchは勾配を「足し合わせる」仕様じゃ。これを忘れると、過去の勾配が全て混ざり合い、学習が暴走してしまうぞ！",
        "【更新の実行 (step)】\n`backward()` で勾配を計算しただけでは、重みは変わらぬぞ。\nトドメに `optimizer.step()` を呼んで初めて、パラメータが更新されるのじゃ。`zero_grad` → `backward` → `step` の三拍子を身体に刻み込め。"
    ],
    13: [
        "【畳み込み層 (Conv)】\nフィルタ（カーネル）をスライドさせて特徴を抽出する。\n「ストライド」はずらす幅、「パディング」は端っこを埋める処理じゃ。",
        "【プーリング層】\nMax Poolingは最大値をとる。\n画像が多少ズレても同じ特徴だと認識できるようにする（移動不変性）効果があるぞ。",
        "【Global Average Pooling (GAP)】\n全結合層の代わりに、各チャンネルの平均値をとる手法じゃ。\nパラメータ数を劇的に減らせるぞ。",
        "【AlexNet】\nディープラーニングブームの火付け役。ReLUやドロップアウトを採用した。",
        "【VGG】\n3×3の小さなフィルタをひたすら重ねて深くしたモデルじゃ。",
        "【ResNet】\n「スキップ接続（入力を出力に足す）」を導入し、100層以上でも学習できるようにした革命的モデルじゃ。",
        "【1x1畳み込み】\n情報の次元（チャンネル数）を圧縮したり、計算量を減らすのによく使われるテクニックじゃ。",
        "【CNN (Convolutional Neural Network)】\n画像認識で圧倒的な力を発揮する構造じゃ。人間の視覚野の仕組みを模していると言われるぞ。",
        "【畳み込み層 (Convolution Layer)】\n画像にフィルタ（カーネル）をスライドさせながら掛け合わせ、特徴をあぶり出す層じゃ。",
        "【カーネル/フィルタ (Kernel/Filter)】\n「縦の線」や「角」など、特定の特徴に反応する小さな窓のようなものじゃ。これを学習で獲得するのじゃ。",
        "【パディング (Padding)】\n画像の周囲に0などを埋めてサイズを調整する処理じゃ。端っこの情報も大事にするために行うぞ。",
        "【ストライド (Stride)】\nフィルタを動かす歩幅のことじゃ。大きくすると出力サイズは小さくなるぞ。",
        "【プーリング層 (Pooling Layer)】\n画像を圧縮して、位置のズレに強くする層じゃ。最大値をとるMaxプーリングがよく使われる。",
        "【全結合層 (Fully Connected Layer)】\nCNNの最後で、抽出された特徴をまとめて最終的な判断（分類）を下す層じゃ。",
        "【AlexNet】\n2012年に圧倒的精度で優勝し、第3次AIブームの火付け役となった伝説のCNNモデルじゃ。",
        "【ResNet】\n「スキップ接続」という抜け道を作ることで、100層以上の超深層学習を可能にした革命的なモデルじゃ。",
        "【転移学習 (Transfer Learning)】\n有名なモデルが学習した知識（重み）を借りて、自分のタスクに合わせて微調整する効率的な術じゃ。",
        "【Conv2dの引数】\n`nn.Conv2d(in_channels, out_channels, kernel_size)` が基本じゃ。\n入力画像のチャンネル数がRGBなら `in_channels=3` になるな。",
        "【入力テンソルの形状】\nPyTorchの画像入力は `(Batch, Channel, Height, Width)` の順序（BCHW）じゃ。\nOpenCVなどは (H, W, C) のことが多いゆえ、`permute` などで入れ替える必要があるぞ。",
        "【プーリング層】\n最大値プーリングは `nn.MaxPool2d(kernel_size)` じゃ。\n画像のサイズを半分にしたいなら `kernel_size=2`、`stride=2` とするのが定石じゃな。"
        "【畳み込み層の定義 (nn.Conv2d)】\n基本は `nn.Conv2d(in_channels, out_channels, kernel_size)` じゃ。\n`in_channels` は入力画像の深さ（RGBなら3）、`out_channels` はフィルタの数じゃ。\nこの順番を逆にすると、次の層で次元が合わずエラーになるぞ。ゆめゆめ間違えるな。",
        "【パディングとストライド (Padding & Stride)】\n画像サイズを変えずに畳み込みたいなら、3x3カーネルに対し `padding=1` を指定せよ。\n逆に画像を小さくしたいなら `stride=2` とすれば、サイズは半分になる。\nプーリングを使わずストライドで縮小するのも、最近の流行りじゃな。",
        "【プーリングの使い分け (Max vs Avg)】\n`nn.MaxPool2d` は領域内の最大値をとる。エッジなどの「強い特徴」を残したい画像認識ではこちらが主流じゃ。\n一方 `nn.AvgPool2d` は平均をとる。全体を滑らかにしたい時や、Global Average Pooling として最後の全結合層の代わりに使うことが多いのう。",
        "【全結合層への接続 (Flatten)】\n畳み込み層の出力は「バッチ×ch×高さ×幅」の4次元じゃが、`nn.Linear` は2次元しか受け付けぬ。\n古くは `x.view(x.size(0), -1)` と書いたが、今は `x.flatten(1)` と書くのがスマートじゃ。\nバッチ次元（先頭）を残して、残りを一直線にする呪文じゃぞ。",
        "【入力サイズの計算】\n全結合層 `nn.Linear(in_features, ...)` の `in_features` に何を入れるか、迷うじゃろう？\nこれは「直前の畳み込み出力の ch数 × 高さ × 幅」じゃ。\n計算が面倒なら、ダミーデータ `torch.randn(1, 3, 224, 224)` などをモデルに通して `.shape` を確認するのが賢者の知恵じゃ。",
        "【モードの切り替え (Train vs Eval)】\nCNNによく使う `Dropout` や `BatchNorm` は、学習時と推論時で挙動が違う。\n必ず学習前には `model.train()`、評価・推論前には `model.eval()` を唱えるのじゃ。\nこれを忘れると、推論なのにドロップアウトしてしまい、精度がガタ落ちするぞ。"
    ],
    14: [
        "【RNN (再帰型NN)】\n隠れ層の状態を、次の時刻の入力として使う。\n過去の情報を記憶できるが、長い系列だと勾配消失で忘れてしまうぞ。",
        "【BPTT】\n時間を遡って誤差を伝える、RNN用の逆伝播法じゃ。\n長すぎると計算できないので、適当な長さで切る（Truncated BPTT）ことが多い。",
        "【LSTM】\n「入力・忘却・出力」の3つのゲートと「セル」を持つ。\n長期記憶を保持できるすごいモデルじゃ。「CEC」が勾配を維持するぞ。",
        "【GRU】\nLSTMを簡略化したものじゃ。「リセットゲート」と「更新ゲート」の2つしかないが、性能はLSTMと同等じゃ。",
        "【双方向RNN】\n過去から未来だけでなく、未来から過去へも学習する。\n文章全体の文脈を読むのに適しているぞ。",
        "【RNN (Recurrent Neural Network)】\n前の時刻のデータを記憶し、次の予測に使う構造じゃ。時系列データや文章など「順番」が大事なデータに強い。",
        "【BPTT (Backpropagation Through Time)】\n時間を遡って誤差を逆伝播させる、RNN専用の学習法じゃ。過去の自分に責任を問うようなものじゃな。",
        "【長期依存性の問題】\nRNNは昔の記憶を忘れてしまいがちじゃ。「文頭の主語」を「文末の動詞」まで覚えておくのが苦手なのじゃ。",
        "【LSTM (Long Short-Term Memory)】\n「忘却ゲート」などの仕組みを持ち、長期記憶を可能にしたRNNの進化系じゃ。時系列の王道じゃな。",
        "【GRU (Gated Recurrent Unit)】\nLSTMを少し簡略化して計算を軽くしたモデルじゃ。性能は拮抗しておるゆえ、使い勝手が良いぞ。",
        "【CEC (Constant Error Carousel)】\nLSTMの中核にある、勾配を消さずに保存しておくメリーゴーランドのような仕組みじゃ。",
        "【双方向RNN (Bidirectional RNN)】\n過去から未来だけでなく、未来から過去へも読み込むRNNじゃ。文脈を読むには前後両方が必要ゆえな。",
        "【Encoder-Decoder】\n入力を符号化（Encode）し、それを復号化（Decode）する構造じゃ。翻訳などで大活躍するぞ。",
        "【勾配クリッピング】\nRNNで起きやすい勾配爆発を防ぐため、勾配が一定以上になったら無理やり切り取る荒療治じゃ。",
        "【Seq2Seq】\nある系列データから別の系列データを生成するモデルじゃ。チャットボットや翻訳の基礎となる技術じゃ。",
        "【LSTMの入出力】\n`nn.LSTM` はデフォルトで入力が `(Sequence, Batch, Feature)` の順じゃ。\n`(Batch, Sequence, ...)` で扱いたいなら、定義時に `batch_first=True` をつけるのを忘れるでないぞ。",
        "【隠れ状態の扱い】\nLSTMの出力は `output, (h_n, c_n)` のタプルじゃ。\n次回の入力に隠れ状態を引き継ぐ場合は、この `h_n` と `c_n` を `.detach()` して渡す必要があるぞ。"
    ],
    15: [
        "【Word2Vec】\n「単語の意味」をベクトルにする技術じゃ。\nCBOW（周りから真ん中を予測）とSkip-gram（真ん中から周りを予測）があるぞ。",
        "【Seq2Seq】\nEncoderで入力をベクトルに圧縮し、Decoderで出力に変換する。\n翻訳やチャットボットの基本形じゃ。",
        "【Attention (注意機構)】\n「入力のどの単語に注目すべきか」を自動で学習する。\n長い文章でも翻訳精度が落ちなくなったぞ。",
        "【Transformer】\nRNNを捨てて、Attentionのみで作られたモデルじゃ。\n並列計算ができるので学習が超高速じゃ。今のAIの主流じゃな。",
        "【BERT】\nTransformerのEncoderを使った事前学習モデルじゃ。\n文章の穴埋め問題（Masked LM）で言葉の意味を深く学習しておる。",
        "【GPT】\nTransformerのDecoderを使ったモデルじゃ。\n次に来る単語をひたすら予測することで、流暢な文章生成を実現したぞ。",
        "【形態素解析】\n文章を単語（意味を持つ最小単位）にバラバラにする処理じゃ。日本語はスペースがないゆえ、これが第一歩じゃ。",
        "【BoW (Bag-of-Words)】\n単語の出現回数だけを数えてベクトルにする手法じゃ。語順を無視して袋に詰め込むゆえ、文脈は失われるぞ。",
        "【TF-IDF】\n「特定の文書にだけ頻出する単語」を重要視する重み付け手法じゃ。「私」のようなありふれた単語の価値を下げるのじゃ。",
        "【Word2Vec】\n単語の意味をベクトル（数値の並び）にする技術じゃ。「王様 - 男 + 女 = 女王」のような計算ができるようになるぞ。",
        "【Attention (注意機構)】\n入力データの「どこに注目すべきか」を重み付けする仕組みじゃ。長い文章の翻訳精度を飛躍的に高めたぞ。",
        "【Transformer】\nRNNを使わず、Attentionだけで構築されたモデルじゃ。並列計算が可能で、今のLLM（大規模言語モデル）の基礎じゃ。",
        "【BERT】\nTransformerを使い、文章の前後から文脈を読むモデルじゃ。事前学習済みモデルとして、様々なタスクで最強を誇ったぞ。",
        "【GPT】\n「次の単語を予測する」ことに特化したモデルじゃ。文章生成において圧倒的な性能を見せる、今のAIブームの立役者じゃ。",
        "【事前学習とファインチューニング】\n大量のデータで汎用的な知識を学び（事前学習）、その後に特定のタスク向けに微調整する（FT）手法じゃ。",
        "【トークナイザ】\n文章をAIが扱える数値（トークン）に変換する辞書のようなものじゃ。これの性能がAIの語彙力を決めるぞ。",
        "【Embedding層】\n単語IDをベクトルにするには `nn.Embedding(num_embeddings, embedding_dim)` を使う。\n`num_embeddings` は語彙数じゃ。パディング用IDを無視する `padding_idx` オプションも便利じゃぞ。",
        "【Transformer】\nPyTorchには `nn.Transformer` や `nn.TransformerEncoder` が用意されておる。\n自力で実装するのも修行じゃが、実戦ではこれらを使うのが早道じゃ。"
    ],
    16: [
        "【VAE (変分オートエンコーダ)】\n入力を「平均と分散」の確率分布に変換する。\nそこからサンプリングして画像を復元するんじゃ。\n潜在変数が連続的になるので、モーフィングなどができるぞ。",
        "【GAN (敵対的生成ネットワーク)】\nGenerator（偽造者）とDiscriminator（警察）のいたちごっこじゃ。\nGeneratorは騙そうとし、Discriminatorは完全に見抜こうとする。",
        "【DCGAN】\nGANにCNNを取り入れたモデルじゃ。\nプーリングをやめてストライド畳み込みを使うなどの工夫がある。",
        "【モード崩壊】\nGANの失敗例。生成器が「この画像さえ出せば騙せる」と学習し、同じ画像しか出さなくなる現象じゃ。",
        "【拡散モデル (Diffusion Model)】\n画像にノイズを加えていき、それを逆再生して「ノイズから画像を復元」するプロセスを学習する。\nStable Diffusionの中身じゃな。",
        "【生成モデル (Generative Model)】\nデータの特徴を学習し、そこから新しいデータを「作り出す」AIじゃ。識別するだけだったAIがクリエイターになったのじゃ。",
        "【VAE (Variational Autoencoder)】\n入力画像を潜在変数（確率分布）に変換し、そこから画像を復元するモデルじゃ。ノイズを混ぜてもそれっぽい画像を生成できるぞ。",
        "【GAN (Generative Adversarial Networks)】\n「偽造者（生成器）」と「鑑定士（識別器）」を戦わせて学習させる手法じゃ。敵対的生成ネットワークと呼ぶ。",
        "【Generator (生成器)】\nGANにおいて、ノイズから偽物データを作り出す側じゃ。鑑定士を騙そうと必死に腕を磨くのじゃ。",
        "【Discriminator (識別器)】\nGANにおいて、本物か偽物かを見破る側じゃ。偽造者の手口を見抜こうと目を凝らすのじゃ。",
        "【モード崩壊 (Mode Collapse)】\nGeneratorが「鑑定士を騙しやすい特定の画像」ばかり作るようになる失敗状態じゃ。多様性が失われてしまうぞ。",
        "【DCGAN】\nGANにCNN（畳み込み）を取り入れたモデルじゃ。画像生成の品質が劇的に安定し、GANブームを巻き起こしたぞ。",
        "【潜在変数 (Latent Variable)】\n目には見えないが、データの特徴を決定づけている裏側の変数のことじゃ。これを操作すれば画像を操れるぞ。",
        "【拡散モデル (Diffusion Model)】\n画像にノイズを徐々に加えて壊し、それを逆再生して復元する過程を学ぶ最新の手法じゃ。画像生成AIの今の主流じゃな。",
        "【リパラメタリゼーション・トリック】\nVAEで確率分布からサンプリングする際に、誤差逆伝播ができるように数式を工夫するテクニックじゃ。",
        "【転置畳み込み】\n画像を拡大（アップサンプリング）するには `nn.ConvTranspose2d` を使うのじゃ。\nGANのGeneratorで、ノイズから画像を生成する際によく使われる術式じゃな。",
        "【Tanhの活用】\n画像生成の出力層では `nn.Tanh()` を使い、値を -1〜1 の範囲に収めることが多い。\nこれに合わせて、正解画像も事前に -1〜1 に正規化しておくのがコツじゃぞ。"
    ],
    17: [
        "【DQN (Deep Q-Network)】\nQ学習のQテーブルをニューラルネットで近似したものじゃ。\nAtariのゲームを人間以上にプレイしたことで有名じゃな。",
        "【Experience Replay】\n経験をメモリに溜めて、ランダムに取り出して学習する。\nデータの相関をなくし、学習を安定させる必須テクニックじゃ。",
        "【Target Network】\n学習の目標となるQ値を計算するネットワークを固定する。\n追いかける背中がブレないようにする工夫じゃ。",
        "【A3C】\n複数のエージェントを並列に動かす。\n非同期にパラメータを更新することで、高速かつ安定した学習ができるぞ。",
        "【AlphaGo】\n「方策関数（どこに打つか）」と「価値関数（勝率はいくつか）」の2つの脳を持つ。\nモンテカルロ木探索で先読みを行うんじゃ。",
        "【深層強化学習 (Deep RL)】\n強化学習の「価値関数」や「方策」の計算に、ディープラーニングを用いたものじゃ。AlphaGoなどが有名じゃな。",
        "【DQN (Deep Q-Network)】\nQ学習（行動価値関数の学習）にニューラルネットを導入し、Atariのゲームを人間以上にプレイした記念碑的モデルじゃ。",
        "【Experience Replay】\nプレイ経験をメモリに保存し、ランダムに取り出して学習するDQNの工夫じゃ。データの相関を消して学習を安定させるぞ。",
        "【Target Network】\n学習の正解となる目標値を計算する専用のネットワークを固定し、たまに更新する工夫じゃ。ゴールが動くと学習しにくいゆえな。",
        "【A3C】\n複数のエージェントを並列に動かして学習させる手法じゃ。学習が速く、ハイスペックなPCでなくとも動くのが魅力じゃ。",
        "【方策勾配法 (Policy Gradient)】\n価値関数を経由せず、方策（戦略）そのものを直接学習して更新する手法じゃ。ロボット制御などで使われるぞ。",
        "【AlphaGo】\n囲碁の世界王者を破ったAIじゃ。DQNやモンテカルロ木探索を組み合わせた、歴史的な勝利じゃったな。",
        "【Actor-Critic】\n行動を決める「役者」と、それを評価する「批評家」の2つのネットワークで学習する、安定した手法じゃ。",
        "【報酬設計 (Reward Shaping)】\nAIが望ましい行動をとるように、報酬の与え方を工夫することじゃ。ここを間違えるとAIはズルをするぞ。",
        "【Sim2Real】\nシミュレーションで育てたAIを、現実世界のロボットなどに移植する際の課題じゃ。現実はゲームより厳しいのじゃ。",
        "【Huber Loss】\nDQNなどの誤差計算では、外れ値に強い `F.smooth_l1_loss` (Huber Loss) が好まれる。\nMSE（二乗誤差）だと学習が不安定になる時こそ試してみるのじゃ。",
        "【モデルのコピー】\nTarget Networkを作る時など、モデルの重みをコピーしたい時は `load_state_dict` を使う。\n`target_net.load_state_dict(policy_net.state_dict())` と唱えれば同期完了じゃ。"
    ],
    18: [
        "【モデルの軽量化】\n・蒸留：巨大な教師モデルの知識を、小さな生徒モデルに教える。\n・量子化：32bitの数値を8bitなどに落としてメモリを節約する。\n・プルーニング：重要でない重みを0にして計算を省く。",
        "【Docker】\nOSやライブラリなどの環境一式を「コンテナ」にパッケージングする技術じゃ。\nどこでも同じ環境で動かせるから、開発・運用に必須じゃぞ。",
        "【エッジAI】\nクラウドではなく、スマホやIoT機器の中で推論を行う。\n通信遅延がなく、プライバシーも守れるのが利点じゃ。",
        "【推論アクセラレータ】\nGPUやTPU、FPGAなど、AIの計算を高速化する専用ハードウェアのことじゃ。",
        "【Docker】\nコンテナと呼ばれる仮想環境を作る技術じゃ。「私の環境では動いたのに」という悲劇を防ぐ、開発者の必須アイテムじゃ。",
        "【エッジコンピューティング】\nクラウドではなく、スマホやIoT機器など現場（エッジ）側でAIを動かすことじゃ。通信遅延がなく、プライバシーも守れるぞ。",
        "【量子化 (Quantization)】\nパラメータの精度（桁数）を落として、モデルを軽量化する術じゃ。多少馬鹿になるが、スマホでも動くようになるぞ。",
        "【プルーニング (Pruning)】\n「枝刈り」じゃ。ニューラルネットの不要な結合をカットしてスカスカにし、計算を速くする軽量化技術じゃ。",
        "【蒸留 (Distillation)】\n巨大な「教師モデル」の知識を、小さな「生徒モデル」に教え込む技術じゃ。性能を保ったまま小型化できるぞ。",
        "【GPUとTPU】\nAIの行列計算を高速処理するためのハードウェアじゃ。これがないと深層学習の学習は何ヶ月もかかってしまうぞ。",
        "【クラウド vs オンプレミス】\nAWSなどを借りるか、自社でサーバーを買うか。コストとセキュリティを天秤にかけて選ぶのじゃ。",
        "【モデルの劣化】\n世の中のトレンドが変わると、AIの精度は落ちていく。「概念ドリフト」とも呼ばれる。定期的な再学習が必要じゃ。",
        "【MLOps】\nAIの開発から運用、監視までをスムーズに回すための仕組み作りじゃ。作って終わりではないのがAIプロジェクトじゃ。",
        "【説明可能AI (XAI)】\n「なぜその判断をしたのか」を人間が理解できるようにする研究じゃ。ブラックボックスのままでは社会で使いにくいゆえな。",
        "【推奨される保存法】\nモデル全体を保存するのではなく、パラメータのみを保存するのが作法じゃ。\n`torch.save(model.state_dict(), 'model.pth')` と書くのじゃ。これで互換性の問題が減るぞ。",
        "【ロードの手順】\nロード時はまずモデルのインスタンスを作り、そこにパラメータを流し込む。\n`model = MyModel()` の後に `model.load_state_dict(torch.load('model.pth'))` じゃ。",
        "【学習モードと推論モード】\nロードした後、学習を再開するなら `model.train()`、推論するだけなら `model.eval()` を呼ぶ。\nDropoutやBatchNormの挙動が変わるゆえ、これを忘れると精度が出ぬぞ。"
    ]
};


const MAP_VILLAGE = [
    [1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],
    [1,3,3,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1],
    [1,3,3,1,0,2,0,0,0,0,0,0,0,0,0,0,0,0,0,1],
    [1,1,2,1,0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,1],
    [1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1],
    [1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1],
    [1,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1],
    [1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1],
    [1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1],
    [1,1,1,1,1,5,5,1,1,1,1,1,1,1,1,1,1,1,1,1]
];

const MAP_FIELD = [
    [1,1,1,1,1,5,5,1,1,1,1,1,1,1,1,1,1,1,1,1],
    [1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1],
    [1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1],
    [1,0,0,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1],
    [1,0,0,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1],
    [1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1],
    [1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,4,0,0,1],
    [1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1],
    [1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1],
    [1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1]
];

const canvas = document.getElementById('gameCanvas');
const ctx = canvas.getContext('2d');
const TILE_SIZE = 48;

const assets = {};
function loadAssets() {
    for (let key in IMAGES) {
        const img = new Image(); img.src = IMAGES[key]; assets[key] = img;
    }
}
loadAssets();

const Sound = {
    ctx: null, osc: null, intervalId: null, isPlaying: false,
    init() { if (!this.ctx) this.ctx = new (window.AudioContext || window.webkitAudioContext)(); },
    playBGM(type) {
        if (!this.ctx) this.init(); if (this.ctx.state === 'suspended') this.ctx.resume();
        this.stopBGM();
        let melody = [], tempo = 150;
        if (type === 'village') { melody = [261, 329, 392, 329, 261, 329, 392, 329, 440, 349, 261, 349, 440, 349, 293, 247]; tempo = 300; }
        else if (type === 'field') { melody = [392, 392, 440, 523, 587, 523, 440, 392, 392, 330, 392, 523]; tempo = 200; }
        else if (type === 'battle') { melody = [110, 110, 130, 110, 146, 110, 130, 110, 164, 110, 146, 110]; tempo = 100; }
        else if (type === 'boss') { melody = [65, 73, 82, 73, 65, 73, 82, 97]; tempo = 120; }
        let noteIndex = 0;
        const playNote = () => {
            const osc = this.ctx.createOscillator(); const gain = this.ctx.createGain();
            osc.connect(gain); gain.connect(this.ctx.destination);
            osc.type = (type === 'boss' || type === 'battle') ? 'sawtooth' : 'triangle';
            osc.frequency.value = melody[noteIndex];
            gain.gain.setValueAtTime(0.1, this.ctx.currentTime);
            gain.gain.linearRampToValueAtTime(0, this.ctx.currentTime + (tempo/1000)*0.9);
            osc.start(); osc.stop(this.ctx.currentTime + (tempo/1000));
            noteIndex = (noteIndex + 1) % melody.length;
        };
        playNote(); this.intervalId = setInterval(playNote, tempo); this.isPlaying = true;
    },
    stopBGM() { if (this.intervalId) clearInterval(this.intervalId); this.isPlaying = false; },
    playSE(type) {
        if (!this.ctx) return;
        const osc = this.ctx.createOscillator(); const gain = this.ctx.createGain();
        osc.connect(gain); gain.connect(this.ctx.destination);
        const now = this.ctx.currentTime;
        if (type === 'decide') {
            osc.frequency.setValueAtTime(880, now); gain.gain.setValueAtTime(0.1, now);
            gain.gain.exponentialRampToValueAtTime(0.01, now + 0.1); osc.start(now); osc.stop(now + 0.1);
        } else if (type === 'damage') {
            osc.type = 'square'; osc.frequency.setValueAtTime(150, now); osc.frequency.linearRampToValueAtTime(50, now + 0.2);
            gain.gain.setValueAtTime(0.2, now); gain.gain.linearRampToValueAtTime(0.01, now + 0.2); osc.start(now); osc.stop(now + 0.2);
        } else if (type === 'win') {
            this.stopBGM();
            [523, 659, 783, 1046].forEach((f, i) => {
                const o = this.ctx.createOscillator(); const g = this.ctx.createGain();
                o.connect(g); g.connect(this.ctx.destination); o.type = 'square'; o.frequency.value = f;
                g.gain.value = 0.1; g.gain.linearRampToValueAtTime(0, now + i*0.1 + 0.3);
                o.start(now + i * 0.1); o.stop(now + i * 0.1 + 0.3);
            });
            setTimeout(() => this.resumeMapBGM(), 2000);
        }
    },
    resumeMapBGM() { if (Game.mapType === 'village') this.playBGM('village'); else this.playBGM('field'); }
};

function startGame() {
    document.getElementById('start-screen').style.display = 'none';
    Sound.init(); Sound.playBGM('village');
}

function drawTile(key, x, y, fallbackColor) {
    const px = x * TILE_SIZE; const py = y * TILE_SIZE; const img = assets[key];
    if (img && img.complete && img.naturalHeight !== 0) ctx.drawImage(img, px, py, TILE_SIZE, TILE_SIZE);
    else { ctx.fillStyle = fallbackColor; ctx.fillRect(px, py, TILE_SIZE, TILE_SIZE); ctx.strokeStyle="rgba(0,0,0,0.3)"; ctx.strokeRect(px, py, TILE_SIZE, TILE_SIZE); }
}

const Game = { mode: 'map', mapData: MAP_VILLAGE, mapType: 'village' };
const Player = {
    x: 10, y: 5, hp: 100, maxHp: 100, dir: 'down',
    move(dx, dy) {
        if (Game.mode !== 'map') return;
        const nextX = this.x + dx; const nextY = this.y + dy;
        // 向き更新
        if(dx>0) this.dir='right'; if(dx<0) this.dir='left'; if(dy>0) this.dir='down'; if(dy<0) this.dir='up';
        
        const tile = getTile(nextX, nextY);
        if (tile === 1) return;
        this.x = nextX; this.y = nextY;
        this.checkStepEvent(tile, nextX, nextY);
    },
    checkStepEvent(tile, x, y) {
        if (tile === 5) {
            if (Game.mapType === 'village') { Game.mapData = MAP_FIELD; Game.mapType = 'field'; this.x = 10; this.y = 1; Sound.playBGM('field'); }
            else { Game.mapData = MAP_VILLAGE; Game.mapType = 'village'; this.x = 10; this.y = 8; Sound.playBGM('village'); }
            return;
        }
        if (tile === 4) { Battle.start('boss'); return; }
        if (Game.mapType === 'field' && Math.random() < 0.15) { Battle.start('slime'); }
    },
    interact() {
        if (Game.mode !== 'map') { if (Game.mode === 'dialogue') Dialogue.next(); return; }
        let tx = this.x, ty = this.y;
        if (this.dir === 'up') ty--; if (this.dir === 'down') ty++; if (this.dir === 'left') tx--; if (this.dir === 'right') tx++;
        const tile = getTile(tx, ty);
        if (tile === 2) { Sound.playSE('decide'); const text = LECTURES[Math.floor(Math.random() * LECTURES.length)]; Dialogue.show("村人", text); }
        else if (tile === 3) { Sound.playSE('decide'); this.hp = this.maxHp; Dialogue.show("宿屋の主人", "よく休めたかい？ HPが全回復したよ！"); }
    }
};

function getTile(x, y) {
    if (y < 0 || y >= Game.mapData.length || x < 0 || x >= Game.mapData[0].length) return 1;
    return Game.mapData[y][x];
}

const Input = {
    moveInterval: null,
    startMove(dx, dy) {
        if(Game.mode !== 'map') return;
        Player.move(dx, dy);
        if (this.moveInterval) clearInterval(this.moveInterval);
        this.moveInterval = setInterval(() => { if(Game.mode === 'map') Player.move(dx, dy); }, 150);
    },
    stopMove() { if (this.moveInterval) clearInterval(this.moveInterval); this.moveInterval = null; },
    triggerAction() { Player.interact(); }
};

window.addEventListener('keydown', e => {
    if (e.repeat) return;
    if (e.key === 'ArrowUp') Input.startMove(0, -1);
    if (e.key === 'ArrowDown') Input.startMove(0, 1);
    if (e.key === 'ArrowLeft') Input.startMove(-1, 0);
    if (e.key === 'ArrowRight') Input.startMove(1, 0);
    if (e.key === ' ' || e.key === 'Enter') Input.triggerAction();
});
window.addEventListener('keyup', () => Input.stopMove());

const Battle = {
    enemy: null, q_list: [],
    start(type) {
        Input.stopMove(); Game.mode = 'battle'; document.getElementById('battle-ui').style.display = 'flex';
        if (type === 'boss') { Sound.playBGM('boss'); this.enemy = { name: "魔王", hp: 100, maxHp: 100, atk: 30, img: IMAGES.boss }; this.q_list = [...DB].sort(() => Math.random() - 0.5); }
        else { Sound.playBGM('battle'); this.enemy = { name: "スライム", hp: 20, maxHp: 20, atk: 10, img: IMAGES.slime }; this.q_list = [DB[Math.floor(Math.random() * DB.length)]]; }
        document.getElementById('enemy-name').innerText = this.enemy.name;
        document.getElementById('battle-enemy-img').src = this.enemy.img;
        this.updateUI(); this.log(`${this.enemy.name} があらわれた！`);
        setTimeout(() => this.nextQuestion(), 1500);
    },
    nextQuestion() {
        if (this.q_list.length === 0) { if (this.enemy.hp > 0) { this.end("勝負はお預けだ。"); Sound.resumeMapBGM(); } return; }
        const q = this.q_list.pop();
        document.getElementById('quiz-area').style.display = 'block'; document.getElementById('battle-next-btn').style.display = 'none';
        document.getElementById('quiz-text').innerText = q.q;
        const optsDiv = document.getElementById('quiz-options'); optsDiv.innerHTML = '';
        const options = q.a.map((txt, i) => ({ txt, isC: i===0 })).sort(() => Math.random() - 0.5);
        options.forEach(opt => {
            const btn = document.createElement('button'); btn.className = 'btn'; btn.innerText = opt.txt;
            btn.onclick = () => this.answer(btn, opt.isC, q.exp); optsDiv.appendChild(btn);
        });
        this.log("どうする？");
    },
    answer(btn, isCorrect, exp) {
        const btns = document.querySelectorAll('#quiz-options button'); btns.forEach(b => b.disabled = true);
        if (isCorrect) { btn.classList.add('correct'); Sound.playSE('decide'); this.log(`正解！ ダメージ！`); this.enemy.hp -= 10; }
        else { btn.classList.add('wrong'); Sound.playSE('damage'); this.log(`不正解... (${exp})`); Player.hp -= this.enemy.atk; }
        this.updateUI();
        setTimeout(() => {
            if (Player.hp <= 0) { this.end("GAME OVER..."); Sound.stopBGM(); Player.hp = 1; Player.x = 10; Player.y = 5; Game.mapData = MAP_VILLAGE; Game.mapType = 'village'; setTimeout(() => Sound.playBGM('village'), 2000); }
            else if (this.enemy.hp <= 0) { this.end(`${this.enemy.name} を倒した！`); Sound.playSE('win'); }
            else { document.getElementById('quiz-area').style.display = 'none'; document.getElementById('battle-next-btn').style.display = 'block'; }
        }, 1500);
    },
    next() { this.nextQuestion(); },
    end(msg) { this.log(msg); setTimeout(() => { document.getElementById('battle-ui').style.display = 'none'; Game.mode = 'map'; }, 2000); },
    updateUI() {
        document.getElementById('enemy-hp').style.width = Math.max(0, (this.enemy.hp / this.enemy.maxHp) * 100) + "%";
        document.getElementById('player-hp').style.width = Math.max(0, (Player.hp / Player.maxHp) * 100) + "%";
        document.getElementById('player-hp-text').innerText = `HP: ${Math.max(0, Player.hp)}`;
    },
    log(text) { document.getElementById('battle-msg').innerText = text; }
};

const Dialogue = {
    show(name, text) { Game.mode = 'dialogue'; document.getElementById('dialogue-box').style.display = 'block'; document.getElementById('dialogue-text').innerHTML = `<strong style="color:#ffd700">${name}</strong><br>${text}`; },
    next() { document.getElementById('dialogue-box').style.display = 'none'; Game.mode = 'map'; }
};

function draw() {
    ctx.fillStyle = '#000'; ctx.fillRect(0, 0, canvas.width, canvas.height);
    const camX = Math.max(0, Math.min(Player.x * TILE_SIZE - canvas.width / 2 + TILE_SIZE/2, Game.mapData[0].length * TILE_SIZE - canvas.width));
    const camY = Math.max(0, Math.min(Player.y * TILE_SIZE - canvas.height / 2 + TILE_SIZE/2, Game.mapData.length * TILE_SIZE - canvas.height));
    ctx.save(); ctx.translate(-camX, -camY);
    for (let y = 0; y < Game.mapData.length; y++) {
        for (let x = 0; x < Game.mapData[0].length; x++) {
            const tile = Game.mapData[y][x];
            if (tile === 0) drawTile('floor', x, y, '#222');
            if (tile === 1) drawTile('wall', x, y, '#555');
            if (tile === 2) drawTile('villager', x, y, '#ff0');
            if (tile === 3) { drawTile('floor', x, y, '#222'); ctx.font="20px sans-serif"; ctx.fillStyle="#fff"; ctx.fillText("INN", x*TILE_SIZE+5, y*TILE_SIZE+30); }
            if (tile === 4) drawTile('boss', x, y, '#90f');
            if (tile === 5) { ctx.fillStyle='#afa'; ctx.fillRect(x*TILE_SIZE, y*TILE_SIZE, TILE_SIZE, TILE_SIZE); }
        }
    }
    // 【変更点】プレイヤーの向きに応じた画像を描画
    const heroKey = `hero_${Player.dir}`;
    drawTile(heroKey, Player.x, Player.y, '#4db8ff');
    ctx.restore();
    requestAnimationFrame(draw);
}
draw();
</script>
</body>

</html>
